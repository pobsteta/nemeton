---
title: "Tutorial 04 : Écologie — Familles B, L, T, N (11 indicateurs)"
output:
  learnr::tutorial:
    progressive: true
    allow_skip: true
    language: fr
runtime: shiny_prerendered
description: >
  Calcul de 11 indicateurs écologiques : B1-3 (biodiversité), L1-3 (paysage/TVB),
  T1-2 (temporel), N1-3 (naturalité).
---

```{r setup, include=FALSE}
library(learnr)
library(gradethis)
gradethis::gradethis_setup()
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
options(tutorial.exercise.timelimit = 300)

# Configuration des timeouts réseau (5 minutes)
NETWORK_TIMEOUT <- 300
options(
  timeout = NETWORK_TIMEOUT,
  HTTPUserAgent = "nemeton-tutorial/1.0"
)

# Configuration httr (connect + request timeout)
if (requireNamespace("httr", quietly = TRUE)) {
  httr::set_config(httr::config(
    connecttimeout = NETWORK_TIMEOUT,
    timeout = NETWORK_TIMEOUT
  ))
}

# Configuration GDAL/curl pour happign
Sys.setenv(
  GDAL_HTTP_TIMEOUT = as.character(NETWORK_TIMEOUT),
  GDAL_HTTP_CONNECTTIMEOUT = as.character(NETWORK_TIMEOUT),
  CURL_SSL_BACKEND = "openssl"
)
```

## Bienvenue

### Objectifs du tutoriel

Ce tutoriel calcule les **indicateurs écologiques** des familles :

- **B** (Biodiversité) : Protection, structure, connectivité
- **L** (Paysage) : Lisières, fragmentation, TVB
- **T** (Temporel) : Âge, changement
- **N** (Naturalité) : Continuité, distance, composite

> **Note** : Les indicateurs C2, A2 sont calculés dans Tutorial 02. F2 (fertilité) est calculé dans Tutorial 03.

### Sources de données

- **BD Forêt V2** : Types de peuplement, essences
- **INPN** : Zones protégées (ZNIEFF, Natura 2000)
- **Métriques LiDAR** : Structure verticale (du Tutorial 02)

---

## Section 1 : BD Forêt V2

### Exercice 1.1 : Explorer la BD Forêt

```{r ex-1-1-setup}
library(sf)
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
```

```{r ex-1-1, exercise=TRUE, exercise.eval=FALSE, exercise.lines=25, exercise.setup="ex-1-1-setup"}
# === EXPLORATION BD FORÊT V2 ===

bd_foret_path <- file.path(data_dir, "bd_foret.gpkg")

if (file.exists(bd_foret_path)) {
  bd_foret <- st_read(bd_foret_path, quiet = TRUE)

  cat("=== BD Forêt V2 ===\n")
  cat("Polygones:", nrow(bd_foret), "\n")
  cat("Colonnes:", paste(names(bd_foret)[seq_len(min(10, ncol(bd_foret)))], collapse = ", "), "\n\n")

  # Types de peuplement
  if ("tfv" %in% names(bd_foret)) {
    cat("=== Types de formation végétale ===\n")
    print(head(table(bd_foret$tfv), 10))
  }

  # Essences
  if ("essence" %in% names(bd_foret)) {
    cat("\n=== Essences principales ===\n")
    print(head(table(bd_foret$essence), 10))
  }
} else {
  cat("BD Forêt non trouvée. Exécutez le Tutorial 01.\n")
}
```


---

## Section 2 : Zonages de protection (B1)

### Exercice 2.1 : Télécharger les zones protégées (happign)

```{r ex-2-1-setup}
library(sf)
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
```

```{r ex-2-1, exercise=TRUE, exercise.eval=FALSE, exercise.lines=80, exercise.setup="ex-2-1-setup", exercise.timelimit=600}
# === ZONAGES DE PROTECTION (happign + purrr/furrr) ===

parcelles_path <- file.path(data_dir, "parcelles.gpkg")
zones_path <- file.path(data_dir, "zones_protection.gpkg")

if (file.exists(parcelles_path)) {
  parcelles <- st_read(parcelles_path, quiet = TRUE)

  if (file.exists(zones_path)) {
    zones <- st_read(zones_path, quiet = TRUE)
    cat("Zones protégées chargées depuis le cache:", nrow(zones), "entités\n")
  } else {
    if (requireNamespace("happign", quietly = TRUE) && requireNamespace("purrr", quietly = TRUE)) {
      library(happign)
      library(purrr)

      cat("=== Téléchargement zones protégées ===\n\n")

      # Récupérer les couches patrinat
      wfs_layers <- get_layers_metadata("wfs")
      patrinat_layers <- wfs_layers$Name[grepl("patrinat", wfs_layers$Name, ignore.case = TRUE)]
      cat("Couches patrinat trouvées:", length(patrinat_layers), "\n")

      # Fonction de téléchargement d'une couche
      download_layer <- function(layer_name, shape) {
        tryCatch(
          {
            z <- get_wfs(shape, layer_name)
            if (!is.null(z) && nrow(z) > 0) {
              z$type_protection <- layer_name
              geom_col <- names(z)[grepl("geom", names(z), ignore.case = TRUE)]
              cols <- intersect(c("type_protection", "nom_site"), names(z))
              z[, c(cols, geom_col)]
            } else {
              NULL
            }
          },
          error = function(e) NULL
        )
      }

      # Parallélisation avec furrr si disponible
      if (requireNamespace("furrr", quietly = TRUE) && requireNamespace("future", quietly = TRUE)) {
        library(furrr)
        library(future)
        plan(multisession, workers = min(4, length(patrinat_layers)))
        cat("Mode: parallèle (furrr, ", nbrOfWorkers(), " workers)\n\n")

        all_zones <- future_map(patrinat_layers, download_layer,
          shape = parcelles,
          .progress = TRUE, .options = furrr_options(seed = TRUE)
        )
        plan(sequential)
      } else {
        cat("Mode: séquentiel (purrr)\n\n")
        all_zones <- map(patrinat_layers, download_layer, shape = parcelles)
      }

      # Filtrer les résultats non-nuls et combiner
      all_zones <- compact(all_zones)

      if (length(all_zones) > 0) {
        zones <- dplyr::bind_rows(all_zones)
        zones <- st_transform(zones, st_crs(parcelles))
        st_write(zones, zones_path, quiet = TRUE)
        cat("\n", nrow(zones), "zones protégées sauvegardées.\n")
      } else {
        cat("\nAucune zone protégée trouvée.\n")
      }
    } else {
      cat("Packages requis: happign, purrr\n")
      cat("Optionnel pour parallélisation: furrr, future\n")
    }
  }

  # Résumé par type
  if (exists("zones") && nrow(zones) > 0) {
    cat("\n=== Résumé par type ===\n")
    purrr::walk(unique(zones$type_protection), ~ cat(sprintf("- %s: %d\n", .x, sum(zones$type_protection == .x))))
  }
} else {
  cat("Parcelles non trouvées.\n")
}
```


### Exercice 2.2 : Calculer B1 (Protection)

```{r ex-2-2-setup, exercise.timelimit=1200}
library(sf)
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
```

```{r ex-2-2, exercise=TRUE, exercise.eval=FALSE, exercise.lines=85, exercise.setup="ex-2-2-setup", exercise.timelimit=1200}
# === INDICATEUR B1 (PROTECTION) - purrr/furrr ===
# B1_pct : % surface protégée (zones fusionnées)
# B1_nb  : nombre de statuts de protection différents
# B1     : score combiné

parcelles_path <- file.path(data_dir, "parcelles.gpkg")
zones_path <- file.path(data_dir, "zones_protection.gpkg")

if (file.exists(parcelles_path) && requireNamespace("purrr", quietly = TRUE)) {
  library(purrr)
  parcelles <- st_read(parcelles_path, quiet = TRUE)

  if (file.exists(zones_path)) {
    zones <- st_read(zones_path, quiet = TRUE)
    zones <- st_transform(zones, st_crs(parcelles))
    cat("Zones protégées:", nrow(zones), "| Types:", length(unique(zones$type_protection)), "\n")

    # Fusionner pour éviter doubles comptages
    zones_union <- st_make_valid(st_union(zones))

    # Fonction de calcul pour une parcelle
    calc_b1 <- function(idx, parcelles_df, zones_df, zones_union_geom) {
      parcelle_i <- st_make_valid(parcelles_df[idx, ])
      surface <- as.numeric(st_area(parcelle_i))

      # % surface protégée
      inter_union <- tryCatch(st_intersection(zones_union_geom, parcelle_i), error = function(e) NULL)
      pct <- if (!is.null(inter_union) && length(inter_union) > 0 && !st_is_empty(inter_union)) {
        min(100, as.numeric(st_area(inter_union)) / surface * 100)
      } else {
        0
      }

      # Nombre de statuts
      inter_zones <- tryCatch(st_intersection(zones_df, parcelle_i), error = function(e) NULL)
      nb <- if (!is.null(inter_zones) && nrow(inter_zones) > 0) {
        length(unique(inter_zones$type_protection))
      } else {
        0
      }

      list(pct = pct, nb = nb)
    }

    # Parallélisation avec furrr si disponible
    cat("=== Calcul B1 ===\n")
    idx_list <- seq_len(nrow(parcelles))

    if (requireNamespace("furrr", quietly = TRUE) && requireNamespace("future", quietly = TRUE)) {
      library(furrr)
      library(future)
      plan(multisession, workers = min(4, parallel::detectCores() - 1))
      cat("Mode: parallèle (", nbrOfWorkers(), "workers)\n\n")

      results <- future_map(idx_list, calc_b1,
        parcelles_df = parcelles, zones_df = zones, zones_union_geom = zones_union,
        .progress = TRUE, .options = furrr_options(seed = TRUE)
      )
      plan(sequential)
    } else {
      cat("Mode: séquentiel (purrr)\n\n")
      results <- map(idx_list, calc_b1,
        parcelles_df = parcelles, zones_df = zones, zones_union_geom = zones_union
      )
    }

    # Extraire résultats
    parcelles$B1_pct <- map_dbl(results, "pct")
    parcelles$B1_nb <- map_int(results, "nb")

    # Score combiné (70% surface + 30% nb statuts normalisé)
    max_statuts <- max(parcelles$B1_nb, na.rm = TRUE)
    parcelles$B1 <- if (max_statuts > 0) {
      0.7 * parcelles$B1_pct + 0.3 * (parcelles$B1_nb / max_statuts * 100)
    } else {
      parcelles$B1_pct
    }

    # Résumé
    cat("\n--- B1_pct (surface) ---\n")
    cat(sprintf(
      "Min: %.1f%% | Max: %.1f%% | Moy: %.1f%%\n",
      min(parcelles$B1_pct), max(parcelles$B1_pct), mean(parcelles$B1_pct)
    ))

    cat("\n--- B1_nb (statuts) ---\n")
    walk(sort(unique(parcelles$B1_nb)), ~ cat(sprintf("  %d statut(s): %d parcelles\n", .x, sum(parcelles$B1_nb == .x))))

    cat("\n--- B1 (combiné) ---\n")
    cat("Moyenne:", round(mean(parcelles$B1), 1), "\n")

    # Sauvegarder
    output_path <- file.path(data_dir, "metriques_zone_protection_b1.gpkg")
    st_write(parcelles, output_path, delete_dsn = TRUE, quiet = TRUE)
    st_write(parcelles, parcelles_path, delete_dsn = TRUE, quiet = TRUE)
    cat("\n=== Métriques B1 Zone de protection exportées ===\n")
    cat("Fichier:", output_path, "\n")
    cat("Parcelles:", nrow(parcelles), " lignes et ", ncol(parcelles), " colonnes\n\n")
  } else {
    cat("Zones non trouvées. Exécutez l'exercice 2.1.\n")
  }
} else {
  cat("Packages requis: sf, purrr\n")
}
```


---

## Section 3 : Structure et Connectivité (B2, B3)

### Exercice 3.1 : Structure verticale (B2)

La **structure verticale** mesure la diversité des strates de végétation.

```{r ex-3-1-setup}
library(sf)
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
```

```{r ex-3-1, exercise=TRUE, exercise.eval=FALSE, exercise.lines=25, exercise.setup="ex-3-1-setup"}
# === INDICATEUR B2 (STRUCTURE VERTICALE) ===

metriques_path <- file.path(data_dir, "metriques_lidar.gpkg")

if (file.exists(metriques_path)) {
  parcelles <- st_read(metriques_path, quiet = TRUE)

  # B2 basé sur l'écart-type et l'entropie des hauteurs
  if ("zsd" %in% names(parcelles)) {
    # Plus l'écart-type est élevé, plus la structure est diverse
    parcelles$B2 <- scales::rescale(parcelles$zsd, to = c(0, 100))
  } else {
    parcelles$B2 <- runif(nrow(parcelles), 20, 80)
  }

  cat("=== Indicateur B2 (Structure verticale) ===\n")
  cat("B2 min:", round(min(parcelles$B2), 1), "\n")
  cat("B2 max:", round(max(parcelles$B2), 1), "\n")
  cat("B2 moyen:", round(mean(parcelles$B2), 1), "\n")

  cat("\nInterprétation:\n")
  cat("- B2 élevé = structure verticale diversifiée (plusieurs strates)\n")
  cat("- B2 faible = structure homogène (monoculture, jeune plantation)\n")

  # Sauvegarder
  parcelles_path <- file.path(data_dir, "parcelles.gpkg")
  output_path <- file.path(data_dir, "metriques_structure_verticale_b2.gpkg")
  st_write(parcelles, output_path, delete_dsn = TRUE, quiet = TRUE)
  st_write(parcelles, parcelles_path, delete_dsn = TRUE, quiet = TRUE)
  cat("\n=== Métriques B2 Structure verticale exportées ===\n")
  cat("Fichier:", output_path, "\n")
  cat("Parcelles:", nrow(parcelles), " lignes et ", ncol(parcelles), " colonnes\n\n")
} else {
  cat("Métriques LiDAR non trouvées. Exécutez le Tutorial 02.\n")
}
```


### Exercice 3.2 : Connectivité écologique (B3)

L'indice de connectivité B3 combine 4 approches complémentaires :

| Package | Approche | Métriques |
|---------|----------|-----------|
| **landscapemetrics** | Structurelle | Cohésion, ENN, Agrégation |
| **gdistance** | Fonctionnelle | Distance de résistance (coût) |
| **igraph** | Graphe | Connectivité, centralité |
| **adehabitatHR** | Dispersion | Kernel de connectivité |

```{r ex-3-2-setup}
library(sf)
library(terra)
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
```

```{r ex-3-2, exercise=TRUE, exercise.eval=FALSE, exercise.lines=220, exercise.setup="ex-3-2-setup", exercise.timelimit=900}
# === INDICATEUR B3 (CONNECTIVITÉ ÉCOLOGIQUE) ===
# Combinaison : landscapemetrics + gdistance + igraph + adehabitatHR

parcelles_path <- file.path(data_dir, "parcelles.gpkg")
bd_foret_path <- file.path(data_dir, "bd_foret.gpkg")
mnt_path <- file.path(data_dir, "mnt.tif")

if (!file.exists(parcelles_path) || !file.exists(bd_foret_path)) {
  stop("Données manquantes. Exécutez d'abord les tutoriels 01-03.")
}

parcelles <- st_read(parcelles_path, quiet = TRUE)
bd_foret <- st_read(bd_foret_path, quiet = TRUE)

# Zone d'analyse étendue (2km buffer)
zone_analyse <- st_buffer(st_union(parcelles), 2000)
bd_foret_clip <- st_intersection(st_make_valid(bd_foret), zone_analyse)

# ============================================================
# 1. PRÉPARATION DES RASTERS
# ============================================================
cat("=== 1. Création des rasters ===\n")

# Template raster (résolution 25m pour performance)
if (file.exists(mnt_path)) {
  mnt <- rast(mnt_path)
  template <- aggregate(mnt, fact = 5)
} else {
  ext_zone <- ext(vect(zone_analyse))
  template <- rast(ext_zone, resolution = 25, crs = st_crs(parcelles)$wkt)
}

# Raster forêt binaire
foret_vect <- vect(bd_foret_clip)
raster_foret <- rasterize(foret_vect, template, field = 1, background = 0)
names(raster_foret) <- "foret"

# Raster de résistance (forêt = 1, non-forêt = 10)
raster_resistance <- raster_foret
values(raster_resistance) <- ifelse(values(raster_foret) == 1, 1, 10)
names(raster_resistance) <- "resistance"

cat("Dimensions:", ncol(raster_foret), "x", nrow(raster_foret), "pixels\n")
cat("Couverture forestière:", round(global(raster_foret, "mean", na.rm = TRUE)[1, 1] * 100, 1), "%\n\n")

# ============================================================
# 2. MÉTRIQUES STRUCTURELLES (landscapemetrics)
# ============================================================
cat("=== 2. Métriques structurelles (landscapemetrics) ===\n")

if (requireNamespace("landscapemetrics", quietly = TRUE)) {
  library(landscapemetrics)

  # Cohésion physique (0-100)
  cohesion <- lsm_c_cohesion(raster_foret) |> subset(class == 1)
  cohesion_val <- if (nrow(cohesion) > 0) cohesion$value[1] else 50

  # Distance au plus proche voisin (m)
  enn <- lsm_c_enn_mn(raster_foret) |> subset(class == 1)
  enn_val <- if (nrow(enn) > 0) enn$value[1] else 500

  # Indice d'agrégation (0-100)
  ai <- lsm_c_ai(raster_foret) |> subset(class == 1)
  ai_val <- if (nrow(ai) > 0) ai$value[1] else 50

  # Nombre de taches
  np <- lsm_c_np(raster_foret) |> subset(class == 1)
  np_val <- if (nrow(np) > 0) np$value[1] else 10

  # Surface moyenne des taches (ha)
  area_mn <- lsm_c_area_mn(raster_foret) |> subset(class == 1)
  area_val <- if (nrow(area_mn) > 0) area_mn$value[1] else 10

  cat("Cohésion:", round(cohesion_val, 1), "/ 100\n")
  cat("ENN moyen:", round(enn_val, 1), "m\n")
  cat("Agrégation:", round(ai_val, 1), "/ 100\n")
  cat("Nb taches:", np_val, "\n")
  cat("Surface moyenne:", round(area_val, 2), "ha\n\n")

  lsm_available <- TRUE
} else {
  cat("landscapemetrics non disponible - valeurs par défaut\n\n")
  cohesion_val <- 50
  enn_val <- 500
  ai_val <- 50
  np_val <- 10
  area_val <- 10
  lsm_available <- FALSE
}

# ============================================================
# 3. DISTANCE DE RÉSISTANCE (gdistance)
# ============================================================
cat("=== 3. Distance de résistance (gdistance) ===\n")

if (requireNamespace("gdistance", quietly = TRUE)) {
  library(gdistance)

  # Convertir en RasterLayer pour gdistance
  resistance_raster <- raster::raster(raster_resistance)

  # Matrice de transition (conductance = 1/résistance)
  tr <- transition(resistance_raster, transitionFunction = function(x) 1 / mean(x), directions = 8)
  tr <- geoCorrection(tr, type = "c") # Correction géographique

  # Centroïdes des taches forestières
  if (lsm_available) {
    patches <- get_patches(raster_foret, class = 1)[[1]]
    patch_centroids <- lsm_p_core(raster_foret) |> subset(class == 1)

    # Extraire les centroïdes des N plus grandes taches (max 20)
    if (nrow(patch_centroids) > 0) {
      patch_areas <- lsm_p_area(raster_foret) |> subset(class == 1)
      patch_areas <- patch_areas[order(-patch_areas$value), ]
      top_patches <- head(patch_areas$id, min(20, nrow(patch_areas)))

      # Calculer centroïdes via landscapemetrics
      patch_coords <- get_centroids(patches)
      patch_coords <- patch_coords[patch_coords$id %in% top_patches, ]

      if (nrow(patch_coords) >= 2) {
        pts <- as.matrix(patch_coords[, c("x", "y")])

        # Matrice des distances de coût
        cost_dist <- costDistance(tr, pts)
        mean_cost_dist <- mean(cost_dist[lower.tri(cost_dist)])

        cat("Nb taches analysées:", nrow(pts), "\n")
        cat("Distance coût moyenne:", round(mean_cost_dist, 1), "unités\n\n")
      } else {
        mean_cost_dist <- 0
        cat("Pas assez de taches pour l'analyse\n\n")
      }
    } else {
      mean_cost_dist <- 500
    }
  } else {
    mean_cost_dist <- 500
  }

  gdist_available <- TRUE
} else {
  cat("gdistance non disponible - valeurs par défaut\n\n")
  mean_cost_dist <- 500
  gdist_available <- FALSE
}

# ============================================================
# 4. ANALYSE DE GRAPHE (igraph)
# ============================================================
cat("=== 4. Connectivité de graphe (igraph) ===\n")

if (requireNamespace("igraph", quietly = TRUE) && lsm_available) {
  library(igraph)

  # Créer un graphe où les noeuds sont les taches forestières
  # Arêtes pondérées par la distance euclidienne

  if (exists("patch_coords") && nrow(patch_coords) >= 2) {
    n_patches <- nrow(patch_coords)

    # Matrice de distance euclidienne
    coords_mat <- as.matrix(patch_coords[, c("x", "y")])
    dist_mat <- as.matrix(dist(coords_mat))

    # Seuil de connexion (ex: 500m = distance de dispersion typique)
    seuil_connexion <- 500 # mètres

    # Créer la matrice d'adjacence (connecté si distance < seuil)
    adj_mat <- dist_mat < seuil_connexion
    diag(adj_mat) <- FALSE

    # Créer le graphe
    g <- graph_from_adjacency_matrix(adj_mat, mode = "undirected")

    # Métriques de graphe
    n_components <- components(g)$no
    largest_component <- max(components(g)$csize)
    graph_density <- edge_density(g)

    # Indice de connectivité du graphe (% noeuds dans la plus grande composante)
    graph_connectivity <- (largest_component / n_patches) * 100

    # Centralité moyenne (betweenness normalisée)
    if (n_patches > 2) {
      betweenness_vals <- betweenness(g, normalized = TRUE)
      mean_betweenness <- mean(betweenness_vals, na.rm = TRUE)
    } else {
      mean_betweenness <- 0
    }

    cat("Nb composantes:", n_components, "\n")
    cat("Plus grande composante:", largest_component, "taches\n")
    cat("Densité du graphe:", round(graph_density, 3), "\n")
    cat("Connectivité graphe:", round(graph_connectivity, 1), "%\n")
    cat("Centralité moyenne:", round(mean_betweenness, 3), "\n\n")
  } else {
    graph_connectivity <- 50
    graph_density <- 0.5
    mean_betweenness <- 0.5
    cat("Pas assez de taches pour l'analyse de graphe\n\n")
  }

  igraph_available <- TRUE
} else {
  cat("igraph non disponible - valeurs par défaut\n\n")
  graph_connectivity <- 50
  graph_density <- 0.5
  mean_betweenness <- 0.5
  igraph_available <- FALSE
}

# ============================================================
# 5. KERNEL DE DISPERSION (adehabitatHR)
# ============================================================
cat("=== 5. Kernel de dispersion (adehabitatHR) ===\n")

if (requireNamespace("adehabitatHR", quietly = TRUE) && requireNamespace("sp", quietly = TRUE)) {
  library(adehabitatHR)
  library(sp)

  # Points sources = centroïdes des parcelles forestières
  parcelles_forest <- parcelles[lengths(st_intersects(parcelles, bd_foret_clip)) > 0, ]

  if (nrow(parcelles_forest) >= 5) {
    centroids_sf <- st_centroid(parcelles_forest)
    centroids_sp <- as(centroids_sf, "Spatial")

    # Kernel de densité (simule la probabilité de présence/dispersion)
    # h = paramètre de lissage (distance de dispersion typique)
    h_dispersion <- 300 # 300m = dispersion typique petits mammifères

    tryCatch(
      {
        # Calcul du kernel
        kde <- kernelUD(centroids_sp, h = h_dispersion, grid = 50)

        # Extraire le volume du home range à 95%
        hr95 <- kernel.area(kde, percent = 95)

        # Surface du kernel (proxy de connectivité fonctionnelle)
        kernel_area <- hr95[[1]]

        # Ratio surface kernel / surface parcelles (indice d'étalement)
        total_parcel_area <- sum(st_area(parcelles_forest)) / 10000 # ha
        kernel_ratio <- kernel_area / as.numeric(total_parcel_area)

        cat("Surface kernel 95%:", round(kernel_area, 1), "ha\n")
        cat("Ratio kernel/parcelles:", round(kernel_ratio, 2), "\n")
        cat("(ratio > 1 = bonne connectivité fonctionnelle)\n\n")

        kernel_connectivity <- min(100, kernel_ratio * 50) # Normaliser 0-100
      },
      error = function(e) {
        cat("Erreur kernel:", e$message, "\n")
        kernel_connectivity <<- 50
      }
    )
  } else {
    cat("Pas assez de parcelles forestières\n\n")
    kernel_connectivity <- 50
  }

  adehabitat_available <- TRUE
} else {
  cat("adehabitatHR non disponible - valeurs par défaut\n\n")
  kernel_connectivity <- 50
  adehabitat_available <- FALSE
}

# ============================================================
# 6. INDICE B3 DE SYNTHÈSE
# ============================================================
cat("=== 6. Calcul de l'indice B3 de synthèse ===\n")

# Normalisation des composantes (0-100)
cohesion_norm <- cohesion_val
enn_norm <- max(0, 100 - (enn_val / 10)) # 0m=100, 1000m=0
ai_norm <- ai_val
np_norm <- max(0, 100 - (np_val - 1) * 2) # 1 tache=100, 50+=0
cost_norm <- max(0, 100 - (mean_cost_dist / 10)) # Distance coût normalisée
graph_norm <- graph_connectivity
kernel_norm <- kernel_connectivity

cat("\nComposantes normalisées:\n")
cat("- Cohésion (landscapemetrics):", round(cohesion_norm, 1), "\n")
cat("- Proximité ENN:", round(enn_norm, 1), "\n")
cat("- Agrégation:", round(ai_norm, 1), "\n")
cat("- Continuité (NP):", round(np_norm, 1), "\n")
cat("- Distance coût (gdistance):", round(cost_norm, 1), "\n")
cat("- Graphe (igraph):", round(graph_norm, 1), "\n")
cat("- Kernel (adehabitatHR):", round(kernel_norm, 1), "\n")

# Pondération selon disponibilité des packages
weights <- c(
  landscapemetrics = 0.25, # Cohésion + ENN + AI
  gdistance = 0.25,
  igraph = 0.25,
  adehabitatHR = 0.25
)

# Score landscapemetrics (moyenne pondérée interne)
score_lsm <- 0.4 * cohesion_norm + 0.3 * enn_norm + 0.2 * ai_norm + 0.1 * np_norm

# Calcul B3 global
B3_global <- weights["landscapemetrics"] * score_lsm +
  weights["gdistance"] * cost_norm +
  weights["igraph"] * graph_norm +
  weights["adehabitatHR"] * kernel_norm

cat("\n=== Scores par approche ===\n")
cat("- Structurel (landscapemetrics):", round(score_lsm, 1), "\n")
cat("- Fonctionnel (gdistance):", round(cost_norm, 1), "\n")
cat("- Graphe (igraph):", round(graph_norm, 1), "\n")
cat("- Dispersion (adehabitatHR):", round(kernel_norm, 1), "\n")
cat("\nB3 GLOBAL:", round(B3_global, 1), "/ 100\n")

# B3 par parcelle (variation locale basée sur distance aux autres taches)
parcelles_centroids <- st_centroid(parcelles)
dist_to_forest <- st_distance(parcelles_centroids, bd_foret_clip)
min_dist <- apply(dist_to_forest, 1, function(x) min(x[x > 0], na.rm = TRUE))
min_dist[is.infinite(min_dist)] <- 0
local_connectivity <- pmax(0, 100 - (min_dist / 20))

# B3 final = 70% global + 30% local
parcelles$B3 <- 0.7 * B3_global + 0.3 * local_connectivity

cat("\n=== Résultat par parcelle ===\n")
cat("B3 moyen:", round(mean(parcelles$B3), 1), "\n")
cat("B3 min:", round(min(parcelles$B3), 1), "\n")
cat("B3 max:", round(max(parcelles$B3), 1), "\n")

# Sauvegarder
output_path <- file.path(data_dir, "metriques_connectivite_b3.gpkg")
st_write(parcelles, output_path, delete_dsn = TRUE, quiet = TRUE)
st_write(parcelles, parcelles_path, delete_dsn = TRUE, quiet = TRUE)
cat("\n=== Métriques B3 Connectivité exportées ===\n")
cat("Fichier:", output_path, "\n")
cat("Parcelles:", nrow(parcelles), " lignes et ", ncol(parcelles), " colonnes\n\n")
```


---

## Section 4 : Paysage (L1-3)

### Exercice 4.1 : Effet lisière et Sylvosphère (L1)

La **sylvosphère** est la zone de transition entre la forêt et son environnement.
L'indice L1 caractérise cette interface via 3 composantes :

| Composante | Description | Source | Impact |
|------------|-------------|--------|--------|
| **Intensité géométrique** | Longueur de lisière / surface | Géométrie parcelle | Quantité d'interface |
| **Contraste de matrice** | Type d'occupation adjacente | IGN OCS GE / OpenLand / geodata | Qualité de la transition |
| **Exposition directionnelle** | Orientation des lisières | Géométrie + azimut | Stress climatique |

**Sources de données d'occupation du sol (par ordre de priorité) :**

| Priorité | Source | Package | Résolution | Couverture |
|----------|--------|---------|------------|------------|
| 1 | **IGN OCS GE** | happign | 10m vecteur | France métropolitaine |
| 2 | **OpenLand** | OpenLand | Variable | Global (analyse temporelle) |
| 3 | **ESA WorldCover** | geodata | 10m raster | Global |
| 4 | **OpenStreetMap** | osmdata | Vecteur | Global |

**Nomenclature OCS GE (IGN) - Scores de contraste :**

| Code | Usage | Couverture | Contraste |
|------|-------|------------|-----------|
| US1 | Agriculture | Culture annuelle | 50 |
| US2 | Sylviculture | Forêt | 0 |
| US235 | Activité secondaire | Industriel | 90 |
| US3 | Tertiaire | Commercial | 85 |
| US4 | Transport | Route/Rail | 75 |
| US5 | Résidentiel | Habitat | 80 |
| US6 | Loisirs | Espaces verts | 35 |

```{r ex-4-1-setup}
library(sf)
library(terra)
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
```

```{r ex-4-1, exercise=TRUE, exercise.eval=FALSE, exercise.lines=320, exercise.setup="ex-4-1-setup", exercise.timelimit=900}
# === INDICATEUR L1 (SYLVOSPHÈRE) ===
# Intensité géométrique + Contraste matrice + Exposition directionnelle

parcelles_path <- file.path(data_dir, "parcelles.gpkg")
bd_foret_path <- file.path(data_dir, "bd_foret.gpkg")

if (!file.exists(parcelles_path)) {
  stop("Données manquantes. Exécutez d'abord les tutoriels précédents.")
}

parcelles <- st_read(parcelles_path, quiet = TRUE)
bd_foret <- if (file.exists(bd_foret_path)) st_read(bd_foret_path, quiet = TRUE) else NULL

# Zone d'analyse avec buffer 500m
zone_analyse <- st_buffer(st_union(parcelles), 500)

# ============================================================
# 1. TÉLÉCHARGEMENT OCCUPATION DU SOL (OCS GE / OpenLand / geodata)
# ============================================================
cat("=== 1. Acquisition de l'occupation du sol ===\n")

ocs_available <- FALSE
ocs_data <- NULL
ocs_source <- "none"

# -------------------------------------------------------------
# Table de correspondance OCS GE (IGN) -> scores de contraste
# https://geoservices.ign.fr/services-web-experts-ocsge
# -------------------------------------------------------------
ocsge_contrast <- data.frame(
  # Codes usage (US) - niveau 1
  code_usage = c("US1", "US2", "US235", "US3", "US4", "US5", "US6", "US7"),
  label_usage = c(
    "Agriculture", "Sylviculture", "Secondaire/Tertiaire",
    "Tertiaire", "Transport", "Résidentiel", "Loisirs", "Sans usage"
  ),
  contraste_usage = c(50, 0, 90, 85, 75, 80, 35, 40),
  stringsAsFactors = FALSE
)

# Codes couverture (CS) pour affiner
ocsge_couverture <- data.frame(
  code_couv = c(
    "CS1.1.1", "CS1.1.2", "CS1.2.1", "CS1.2.2", "CS1.2.3",
    "CS2.1.1", "CS2.1.2", "CS2.1.3", "CS2.2.1", "CS2.2.2"
  ),
  label_couv = c(
    "Bâti", "Serre/Hangar", "Route", "Voie ferrée", "Autre revêtu",
    "Forêt feuillus", "Forêt conifères", "Forêt mixte", "Lande", "Pelouse"
  ),
  contraste_couv = c(95, 70, 80, 75, 60, 0, 0, 0, 15, 20),
  stringsAsFactors = FALSE
)

# -------------------------------------------------------------
# PRIORITÉ 1 : IGN OCS GE via happign ou requête WFS directe
# -------------------------------------------------------------
cat("Tentative de téléchargement OCS GE (IGN)...\n")

# URL du WFS OCS GE sur la Géoplateforme
# https://geoservices.ign.fr/services-web-experts-ocsge
ocsge_wfs_url <- "https://data.geopf.fr/wfs/ows"

# Couches OCS GE disponibles (départements couverts progressivement)
# Format: OCSGE.COUVERTURE:couverture_XXXX (XXXX = millésime)
# ou OCSGE:occupation_du_sol

if (requireNamespace("happign", quietly = TRUE)) {
  library(happign)

  tryCatch(
    {
      # Méthode 1: Chercher les couches OCS GE dans le catalogue WFS
      wfs_layers <- get_layers_metadata("wfs")

      # Filtrer les couches OCS GE (couverture ou occupation)
      ocsge_layers <- wfs_layers$Name[grepl("ocsge", wfs_layers$Name, ignore.case = TRUE)]

      cat("Couches OCS GE trouvées:", length(ocsge_layers), "\n")
      if (length(ocsge_layers) > 0) {
        cat("Exemples:", paste(head(ocsge_layers, 3), collapse = ", "), "\n")
      }

      # Chercher en priorité : couverture > occupation > zone_construite
      layer_patterns <- c("couverture", "occupation", "zone_construite", "usage")
      selected_layer <- NULL

      for (pattern in layer_patterns) {
        matches <- ocsge_layers[grepl(pattern, ocsge_layers, ignore.case = TRUE)]
        # Exclure les couches de différence/évolution
        matches <- matches[!grepl("diff|evol|changement", matches, ignore.case = TRUE)]
        if (length(matches) > 0) {
          selected_layer <- matches[1]
          break
        }
      }

      if (!is.null(selected_layer)) {
        cat("Couche sélectionnée:", selected_layer, "\n")

        # Convertir zone_analyse en bbox pour la requête
        zone_bbox <- st_as_sfc(st_bbox(zone_analyse))
        st_crs(zone_bbox) <- st_crs(zone_analyse)

        # Télécharger via happign
        ocs_data <- get_wfs(
          x = zone_bbox,
          layer = selected_layer,
          spatial_filter = "bbox"
        )

        if (!is.null(ocs_data) && nrow(ocs_data) > 0) {
          # Découper sur la zone d'analyse
          ocs_data <- st_make_valid(ocs_data)
          ocs_data <- suppressWarnings(st_intersection(ocs_data, zone_analyse))

          if (nrow(ocs_data) > 0) {
            cat("OCS GE récupéré:", nrow(ocs_data), "polygones\n")
            cat("Colonnes:", paste(head(names(ocs_data), 8), collapse = ", "), "\n")
            ocs_available <- TRUE
            ocs_source <- "ocsge"
          }
        }
      }
    },
    error = function(e) {
      cat("Erreur happign OCS GE:", e$message, "\n")
    }
  )
}

# Méthode 2: Requête WFS directe si happign échoue
if (!ocs_available) {
  cat("Tentative requête WFS directe...\n")

  tryCatch(
    {
      # Construire la requête WFS manuellement
      bbox <- st_bbox(st_transform(zone_analyse, 4326))
      bbox_str <- paste(bbox["ymin"], bbox["xmin"], bbox["ymax"], bbox["xmax"], sep = ",")

      # Essayer différentes couches OCS GE
      ocsge_layers_try <- c(
        "OCSGE.COUVERTURE:couverture",
        "OCSGE:occupation_du_sol",
        "LANDCOVER.FORESTINVENTORY.V2:formation_vegetale"
      )

      for (layer_name in ocsge_layers_try) {
        wfs_request <- paste0(
          ocsge_wfs_url,
          "?SERVICE=WFS",
          "&VERSION=2.0.0",
          "&REQUEST=GetFeature",
          "&TYPENAMES=", layer_name,
          "&BBOX=", bbox_str, ",EPSG:4326",
          "&OUTPUTFORMAT=application/json",
          "&COUNT=1000"
        )

        cat("Essai couche:", layer_name, "\n")

        response <- tryCatch(
          {
            st_read(wfs_request, quiet = TRUE)
          },
          error = function(e) NULL
        )

        if (!is.null(response) && nrow(response) > 0) {
          # Reprojeter et découper
          ocs_data <- st_transform(response, st_crs(parcelles))
          ocs_data <- st_make_valid(ocs_data)
          ocs_data <- suppressWarnings(st_intersection(ocs_data, zone_analyse))

          if (nrow(ocs_data) > 0) {
            cat("Données récupérées:", nrow(ocs_data), "polygones\n")
            cat("Colonnes:", paste(head(names(ocs_data), 8), collapse = ", "), "\n")
            ocs_available <- TRUE
            ocs_source <- "ocsge"
            break
          }
        }
      }

      if (!ocs_available) {
        cat("Aucune couche OCS GE disponible pour cette zone\n")
        cat("(L'OCS GE ne couvre pas encore tout le territoire)\n")
      }
    },
    error = function(e) {
      cat("Erreur WFS directe:", e$message, "\n")
    }
  )
}

# -------------------------------------------------------------
# PRIORITÉ 2 : OpenLand (analyse d'occupation du sol)
# -------------------------------------------------------------
if (!ocs_available && requireNamespace("OpenLand", quietly = TRUE)) {
  library(OpenLand)

  cat("\nTentative avec OpenLand...\n")

  # OpenLand est principalement pour l'analyse de changements d'occupation

  # Il nécessite des rasters d'entrée déjà existants
  # On l'utilisera pour l'analyse si on a des données
  cat("OpenLand disponible pour analyse de transitions\n")
  cat("(Nécessite des rasters d'occupation existants)\n")
}

# -------------------------------------------------------------
# PRIORITÉ 3 : geodata (ESA WorldCover)
# -------------------------------------------------------------
if (!ocs_available && requireNamespace("geodata", quietly = TRUE)) {
  library(geodata)

  cat("\nTéléchargement ESA WorldCover (geodata)...\n")

  tryCatch(
    {
      zone_wgs84 <- st_transform(zone_analyse, 4326)
      cache_dir <- file.path(data_dir, "geodata_cache")
      if (!dir.exists(cache_dir)) dir.create(cache_dir, recursive = TRUE)

      # Télécharger ESA WorldCover
      lc <- geodata::landcover(var = "trees", path = cache_dir)

      # Cropper sur la zone
      zone_vect <- vect(zone_wgs84)
      ocs_raster <- crop(lc, zone_vect)
      ocs_raster <- mask(ocs_raster, zone_vect)
      ocs_raster <- project(ocs_raster, crs(vect(parcelles)), method = "near")

      if (!is.null(ocs_raster)) {
        ocs_available <- TRUE
        ocs_source <- "geodata"
        ocs_data <- ocs_raster
        cat("ESA WorldCover récupéré:", ncol(ocs_raster), "x", nrow(ocs_raster), "pixels\n")
      }
    },
    error = function(e) {
      cat("Erreur geodata:", e$message, "\n")
    }
  )
}

# -------------------------------------------------------------
# PRIORITÉ 4 : osmdata (OpenStreetMap)
# -------------------------------------------------------------
osm_available <- FALSE

if (!ocs_available && requireNamespace("osmdata", quietly = TRUE)) {
  library(osmdata)

  cat("\nTéléchargement OSM landuse...\n")

  bbox_wgs84 <- st_bbox(st_transform(zone_analyse, 4326))

  tryCatch(
    {
      # Zones urbaines
      urban <- opq(bbox_wgs84) |>
        add_osm_feature(key = "landuse", value = c(
          "residential", "commercial",
          "industrial", "retail"
        )) |>
        osmdata_sf()
      urban_poly <- urban$osm_polygons

      # Prairies
      meadow <- opq(bbox_wgs84) |>
        add_osm_feature(key = "landuse", value = c(
          "meadow", "grass", "farmyard",
          "orchard", "vineyard"
        )) |>
        osmdata_sf()
      meadow_poly <- meadow$osm_polygons

      # Cultures
      farmland <- opq(bbox_wgs84) |>
        add_osm_feature(key = "landuse", value = c("farmland")) |>
        osmdata_sf()
      farmland_poly <- farmland$osm_polygons

      # Routes
      roads <- opq(bbox_wgs84) |>
        add_osm_feature(key = "highway", value = c(
          "motorway", "trunk",
          "primary", "secondary"
        )) |>
        osmdata_sf()
      roads_lines <- roads$osm_lines

      osm_available <- TRUE
      ocs_source <- "osm"
      cat("Données OSM récupérées\n")
    },
    error = function(e) {
      cat("Erreur osmdata:", e$message, "\n")
    }
  )
}

cat("\n→ Source sélectionnée:", ocs_source, "\n\n")

# Table ESA WorldCover pour geodata
esa_contrast <- data.frame(
  code = c(10, 20, 30, 40, 50, 60, 70, 80, 90, 95, 100),
  contraste = c(0, 15, 20, 50, 90, 40, 50, 30, 25, 15, 25),
  label = c(
    "Forêt", "Arbustes", "Prairie", "Culture", "Bâti",
    "Sol nu", "Neige", "Eau", "Zone humide", "Mangrove", "Mousse"
  )
)

# Scores OSM
contrast_scores <- c(
  forest = 0, meadow = 15, orchard = 20, scrub = 25, water = 30,
  farmland = 50, vineyard = 45, road = 75, residential = 80,
  commercial = 90, industrial = 95, unknown = 50
)

# ============================================================
# 2. INTENSITÉ GÉOMÉTRIQUE DE LISIÈRE
# ============================================================
cat("\n=== 2. Intensité géométrique de lisière ===\n")

# Périmètre et surface de chaque parcelle
parcelles$perimetre_m <- as.numeric(st_length(st_boundary(parcelles)))
parcelles$surface_m2 <- as.numeric(st_area(parcelles))
parcelles$surface_ha <- parcelles$surface_m2 / 10000

# Indice de forme (Shape Index) : périmètre / périmètre d'un cercle de même surface
# SI = P / (2 * sqrt(π * A))
parcelles$shape_index <- parcelles$perimetre_m / (2 * sqrt(pi * parcelles$surface_m2))

# Densité de lisière (m/ha)
parcelles$densite_lisiere <- parcelles$perimetre_m / parcelles$surface_ha

# Normaliser l'intensité géométrique (0-100)
# Shape index de 1 (cercle parfait) à ~5 (très allongé)
parcelles$L1_geometrie <- pmin(100, (parcelles$shape_index - 1) * 25)

cat("Shape Index moyen:", round(mean(parcelles$shape_index), 2), "\n")
cat("Densité lisière moyenne:", round(mean(parcelles$densite_lisiere), 1), "m/ha\n")
cat("L1_geometrie moyen:", round(mean(parcelles$L1_geometrie), 1), "\n\n")

# ============================================================
# 3. CONTRASTE DE MATRICE (Type d'occupation adjacente)
# ============================================================
cat("=== 3. Contraste de matrice ===\n")

# === MÉTHODE 1 : OCS GE (IGN) - Données vectorielles ===
if (ocs_source == "ocsge" && !is.null(ocs_data)) {
  cat("Calcul du contraste via OCS GE (IGN)...\n")

  # Fonction pour calculer le contraste via polygones OCS GE
  calc_ocsge_contrast <- function(parcelle_geom, ocs_polygons, contrast_table, couv_table) {
    buffer_zone <- st_buffer(parcelle_geom, 50)
    edge_zone <- st_difference(buffer_zone, parcelle_geom)

    if (st_is_empty(edge_zone)) {
      return(50)
    }

    # Intersection avec OCS GE
    inter <- tryCatch(
      {
        suppressWarnings(st_intersection(ocs_polygons, edge_zone))
      },
      error = function(e) NULL
    )

    if (is.null(inter) || nrow(inter) == 0) {
      return(50)
    }

    # Calculer le contraste pondéré par surface
    inter$area <- as.numeric(st_area(inter))
    total_area <- sum(inter$area)

    if (total_area == 0) {
      return(50)
    }

    # Chercher les colonnes usage et couverture
    usage_col <- names(inter)[grepl("usage|us_", names(inter), ignore.case = TRUE)][1]
    couv_col <- names(inter)[grepl("couverture|cs_", names(inter), ignore.case = TRUE)][1]

    weighted_contrast <- 0

    for (i in seq_len(nrow(inter))) {
      weight <- inter$area[i] / total_area

      # Priorité à la couverture (plus précise)
      if (!is.na(couv_col) && couv_col %in% names(inter)) {
        code <- as.character(inter[[couv_col]][i])
        idx <- which(couv_table$code_couv == code)
        if (length(idx) > 0) {
          weighted_contrast <- weighted_contrast + weight * couv_table$contraste_couv[idx]
          next
        }
      }

      # Sinon utiliser l'usage
      if (!is.na(usage_col) && usage_col %in% names(inter)) {
        code <- as.character(inter[[usage_col]][i])
        # Extraire le code de niveau 1 (ex: "US1.2" -> "US1")
        code_n1 <- sub("\\..*", "", code)
        idx <- which(contrast_table$code_usage == code_n1)
        if (length(idx) > 0) {
          weighted_contrast <- weighted_contrast + weight * contrast_table$contraste_usage[idx]
          next
        }
      }

      # Par défaut
      weighted_contrast <- weighted_contrast + weight * 50
    }

    return(weighted_contrast)
  }

  # Appliquer à chaque parcelle (parallélisé si furrr disponible)
  calc_contrast_i <- function(i) {
    calc_ocsge_contrast(st_geometry(parcelles)[i], ocs_data, ocsge_contrast, ocsge_couverture)
  }

  if (requireNamespace("furrr", quietly = TRUE) && requireNamespace("future", quietly = TRUE)) {
    library(furrr)
    library(future)
    plan(multisession, workers = max(1, availableCores() - 1))
    cat("Mode parallèle (furrr,", nbrOfWorkers(), "workers)...\n")
    parcelles$L1_contraste <- future_map_dbl(seq_len(nrow(parcelles)), calc_contrast_i,
      .progress = TRUE
    )
    plan(sequential)
  } else if (requireNamespace("purrr", quietly = TRUE)) {
    library(purrr)
    cat("Mode séquentiel (purrr)...\n")
    parcelles$L1_contraste <- map_dbl(seq_len(nrow(parcelles)), calc_contrast_i)
  } else {
    cat("Mode séquentiel (base R)...\n")
    parcelles$L1_contraste <- sapply(seq_len(nrow(parcelles)), calc_contrast_i)
  }

  cat("L1_contraste moyen (OCS GE):", round(mean(parcelles$L1_contraste, na.rm = TRUE), 1), "\n")

  # Afficher la distribution des usages
  if ("usage" %in% names(ocs_data) || any(grepl("us_", names(ocs_data)))) {
    usage_col <- names(ocs_data)[grepl("usage|us_", names(ocs_data), ignore.case = TRUE)][1]
    if (!is.na(usage_col)) {
      cat("\nDistribution des usages OCS GE:\n")
      usage_table <- sort(table(ocs_data[[usage_col]]), decreasing = TRUE)
      for (code in names(head(usage_table, 5))) {
        pct <- round(usage_table[code] / sum(usage_table) * 100, 1)
        cat(sprintf("  - %s: %s%%\n", code, pct))
      }
    }
  }

  # === MÉTHODE 2 : geodata (ESA WorldCover) - Raster ===
} else if (ocs_source == "geodata" && !is.null(ocs_data)) {
  cat("Calcul du contraste via ESA WorldCover (geodata)...\n")

  calc_raster_contrast <- function(parcelle_geom, lc_raster, contrast_table) {
    buffer_zone <- st_buffer(parcelle_geom, 50)
    edge_zone <- st_difference(buffer_zone, parcelle_geom)

    if (st_is_empty(edge_zone)) {
      return(50)
    }

    edge_vect <- vect(edge_zone)

    tryCatch(
      {
        vals <- extract(lc_raster, edge_vect, fun = NULL)[[2]]
        if (length(vals) == 0 || all(is.na(vals))) {
          return(50)
        }

        val_counts <- table(vals)
        total_pixels <- sum(val_counts)

        weighted_contrast <- 0
        for (code in names(val_counts)) {
          code_num <- as.numeric(code)
          idx <- which(contrast_table$code == code_num)
          weight <- val_counts[code] / total_pixels
          if (length(idx) > 0) {
            weighted_contrast <- weighted_contrast + weight * contrast_table$contraste[idx]
          } else {
            weighted_contrast <- weighted_contrast + weight * 50
          }
        }

        return(as.numeric(weighted_contrast))
      },
      error = function(e) {
        return(50)
      }
    )
  }

  # Parallélisation si furrr disponible
  calc_raster_i <- function(i) {
    calc_raster_contrast(st_geometry(parcelles)[i], ocs_data, esa_contrast)
  }

  if (requireNamespace("furrr", quietly = TRUE) && requireNamespace("future", quietly = TRUE)) {
    library(furrr)
    library(future)
    plan(multisession, workers = max(1, availableCores() - 1))
    cat("Mode parallèle (furrr,", nbrOfWorkers(), "workers)...\n")
    parcelles$L1_contraste <- future_map_dbl(seq_len(nrow(parcelles)), calc_raster_i,
      .progress = TRUE
    )
    plan(sequential)
  } else if (requireNamespace("purrr", quietly = TRUE)) {
    library(purrr)
    cat("Mode séquentiel (purrr)...\n")
    parcelles$L1_contraste <- map_dbl(seq_len(nrow(parcelles)), calc_raster_i)
  } else {
    cat("Mode séquentiel (base R)...\n")
    parcelles$L1_contraste <- sapply(seq_len(nrow(parcelles)), calc_raster_i)
  }

  cat("L1_contraste moyen (ESA):", round(mean(parcelles$L1_contraste, na.rm = TRUE), 1), "\n")

  # === MÉTHODE 3 : OSM ===
} else if (ocs_source == "osm" && osm_available) {
  cat("Calcul du contraste de matrice (OSM)...\n")

  calc_osm_contrast <- function(parcelle_geom, urban_p, meadow_p, farmland_p,
                                roads_l, crs_target) {
    buffer_zone <- st_buffer(parcelle_geom, 50)
    edge_zone <- st_difference(buffer_zone, parcelle_geom)

    if (st_is_empty(edge_zone)) {
      return(50)
    }

    edge_area <- as.numeric(st_area(edge_zone))
    if (edge_area == 0) {
      return(50)
    }

    total_weighted <- 0
    total_area <- 0

    # Urban
    if (!is.null(urban_p) && nrow(urban_p) > 0) {
      urban_t <- st_transform(urban_p, crs_target)
      inter <- suppressWarnings(st_intersection(edge_zone, st_union(urban_t)))
      if (length(inter) > 0 && !st_is_empty(inter)) {
        area <- as.numeric(st_area(inter))
        total_weighted <- total_weighted + area * contrast_scores["residential"]
        total_area <- total_area + area
      }
    }

    # Meadow
    if (!is.null(meadow_p) && nrow(meadow_p) > 0) {
      meadow_t <- st_transform(meadow_p, crs_target)
      inter <- suppressWarnings(st_intersection(edge_zone, st_union(meadow_t)))
      if (length(inter) > 0 && !st_is_empty(inter)) {
        area <- as.numeric(st_area(inter))
        total_weighted <- total_weighted + area * contrast_scores["meadow"]
        total_area <- total_area + area
      }
    }

    # Farmland
    if (!is.null(farmland_p) && nrow(farmland_p) > 0) {
      farmland_t <- st_transform(farmland_p, crs_target)
      inter <- suppressWarnings(st_intersection(edge_zone, st_union(farmland_t)))
      if (length(inter) > 0 && !st_is_empty(inter)) {
        area <- as.numeric(st_area(inter))
        total_weighted <- total_weighted + area * contrast_scores["farmland"]
        total_area <- total_area + area
      }
    }

    # Roads
    if (!is.null(roads_l) && nrow(roads_l) > 0) {
      roads_t <- st_transform(roads_l, crs_target)
      roads_buffer <- st_buffer(roads_t, 10)
      inter <- suppressWarnings(st_intersection(edge_zone, st_union(roads_buffer)))
      if (length(inter) > 0 && !st_is_empty(inter)) {
        area <- as.numeric(st_area(inter))
        total_weighted <- total_weighted + area * contrast_scores["road"]
        total_area <- total_area + area
      }
    }

    if (total_area == 0) {
      return(contrast_scores["unknown"])
    }
    return(total_weighted / total_area)
  }

  crs_target <- st_crs(parcelles)

  # Parallélisation si furrr disponible
  calc_osm_i <- function(i) {
    calc_osm_contrast(
      st_geometry(parcelles)[i],
      urban_poly, meadow_poly, farmland_poly, roads_lines,
      crs_target
    )
  }

  if (requireNamespace("furrr", quietly = TRUE) && requireNamespace("future", quietly = TRUE)) {
    library(furrr)
    library(future)
    plan(multisession, workers = max(1, availableCores() - 1))
    cat("Mode parallèle (furrr,", nbrOfWorkers(), "workers)...\n")
    parcelles$L1_contraste <- future_map_dbl(seq_len(nrow(parcelles)), calc_osm_i,
      .progress = TRUE
    )
    plan(sequential)
  } else if (requireNamespace("purrr", quietly = TRUE)) {
    library(purrr)
    cat("Mode séquentiel (purrr)...\n")
    parcelles$L1_contraste <- map_dbl(seq_len(nrow(parcelles)), calc_osm_i)
  } else {
    cat("Mode séquentiel (base R)...\n")
    parcelles$L1_contraste <- sapply(seq_len(nrow(parcelles)), calc_osm_i)
  }

  cat("L1_contraste moyen (OSM):", round(mean(parcelles$L1_contraste, na.rm = TRUE), 1), "\n")

  # === MÉTHODE 4 : Fallback basé sur distance aux routes ===
} else {
  cat("Aucune donnée d'occupation disponible - estimation via distance routes\n")

  routes_path <- file.path(data_dir, "routes.gpkg")
  if (file.exists(routes_path)) {
    routes <- st_read(routes_path, quiet = TRUE)
    centroids <- st_centroid(parcelles)
    dist_routes <- as.numeric(st_distance(centroids, st_union(routes)))
    parcelles$L1_contraste <- pmax(0, 80 - (dist_routes / 25))
  } else {
    parcelles$L1_contraste <- 50
  }

  cat("L1_contraste moyen (estimé):", round(mean(parcelles$L1_contraste), 1), "\n")
}

cat("\n")

# ============================================================
# 4. EXPOSITION DIRECTIONNELLE (Vent, Rayonnement)
# ============================================================
cat("=== 4. Exposition directionnelle ===\n")

# L'exposition des lisières influence le microclimat forestier
# - Lisières exposées au vent dominant = stress
# - Lisières exposées au sud = rayonnement intense = stress hydrique

# -------------------------------------------------------------
# 4.1 Obtenir la direction dominante du vent via NASA POWER
# -------------------------------------------------------------
cat("Récupération de la direction du vent (NASA POWER)...\n")

if (requireNamespace("nasapower", quietly = TRUE)) {
  library(nasapower)

  # Centroïde de la zone d'étude (convertir en WGS84)
  zone_wgs84 <- st_transform(st_union(parcelles), 4326)
  centroid <- st_coordinates(st_centroid(zone_wgs84))

  tryCatch(
    {
      # Climatologie mensuelle du vent (moyenne sur 30 ans)
      wind_data <- nasapower::get_power(
        community = "ag",
        pars = c("WD10M", "WS10M"),
        lonlat = c(centroid[1], centroid[2]),
        temporal_api = "climatology"
      )

      # Direction dominante = moyenne pondérée par la vitesse du vent
      # Exclure les valeurs annuelles (ANN) pour ne garder que les mois
      wind_monthly <- wind_data[wind_data$PARAMETER == "WD10M" & !is.na(wind_data$ANN), ]
      if (nrow(wind_monthly) == 0) {
        # Utiliser les colonnes mensuelles directement
        wd_values <- as.numeric(wind_data[wind_data$PARAMETER == "WD10M", 4:15])
        ws_values <- as.numeric(wind_data[wind_data$PARAMETER == "WS10M", 4:15])
        vent_dominant <- round(weighted.mean(wd_values, ws_values, na.rm = TRUE))
      } else {
        vent_dominant <- 225 # Fallback
      }

      cat("✓ Direction dominante du vent (NASA POWER):", vent_dominant, "°\n")
      cat("  Source: Climatologie MERRA-2 (moyenne 30 ans)\n")
    },
    error = function(e) {
      vent_dominant <- 225
      cat("⚠ Erreur NASA POWER:", e$message, "\n")
      cat("  Direction par défaut (France):", vent_dominant, "° (Sud-Ouest)\n")
    }
  )
} else {
  # Valeur par défaut pour la France (Sud-Ouest)
  vent_dominant <- 225
  cat("nasapower non disponible - Direction par défaut:", vent_dominant, "° (Sud-Ouest)\n")
  cat("Installez nasapower: install.packages('nasapower')\n")
}

cat("\n")

# -------------------------------------------------------------
# 4.2 Calculer l'orientation des segments de lisière
# -------------------------------------------------------------
calc_edge_exposure <- function(parcelle_geom, vent_dir) {
  # Extraire les coordonnées du périmètre
  coords <- st_coordinates(st_boundary(parcelle_geom))

  if (nrow(coords) < 3) {
    return(c(vent = 50, soleil = 50))
  }

  # Calculer l'azimut de chaque segment
  n <- nrow(coords) - 1
  azimuths <- numeric(n)
  lengths <- numeric(n)

  for (i in 1:n) {
    dx <- coords[i + 1, "X"] - coords[i, "X"]
    dy <- coords[i + 1, "Y"] - coords[i, "Y"]
    azimuths[i] <- (atan2(dx, dy) * 180 / pi + 360) %% 360
    lengths[i] <- sqrt(dx^2 + dy^2)
  }

  # Exposition maximale si lisière orientée perpendiculairement au vent
  # Angle entre la normale à la lisière et la direction du vent
  vent_exposure <- sapply(azimuths, function(az) {
    # Normale à la lisière = azimut + 90°
    normale <- (az + 90) %% 360
    # Différence avec la direction du vent
    diff <- abs(normale - vent_dir)
    if (diff > 180) diff <- 360 - diff
    # Exposition max si perpendiculaire (diff = 0)
    cos(diff * pi / 180)
  })

  # Moyenne pondérée par longueur de segment
  vent_score <- sum(abs(vent_exposure) * lengths) / sum(lengths) * 100

  # Exposition solaire : Sud (180°)
  # Lisières orientées N-S sont exposées à l'Est ou à l'Ouest
  # Lisières orientées E-W sont exposées au Sud ou au Nord
  soleil_exposure <- sapply(azimuths, function(az) {
    normale <- (az + 90) %% 360
    # Différence avec le Sud
    diff <- abs(normale - 180)
    if (diff > 180) diff <- 360 - diff
    # Exposition max si normale pointe vers le Sud (diff = 0)
    cos(diff * pi / 180)
  })

  # Pondérer les segments orientés Sud positivement
  soleil_score <- sum(pmax(0, soleil_exposure) * lengths) / sum(lengths) * 100

  return(c(vent = vent_score, soleil = soleil_score))
}

cat("Calcul de l'exposition directionnelle...\n")
cat("Direction du vent utilisée:", vent_dominant, "°\n")

# Calculer pour chaque parcelle (parallélisé si furrr disponible)
calc_exposure_i <- function(i) {
  calc_edge_exposure(st_geometry(parcelles)[i], vent_dominant)
}

if (requireNamespace("furrr", quietly = TRUE) && requireNamespace("future", quietly = TRUE)) {
  library(furrr)
  library(future)
  plan(multisession, workers = max(1, availableCores() - 1))
  cat("Mode parallèle (furrr,", nbrOfWorkers(), "workers)...\n")
  exposures_list <- future_map(seq_len(nrow(parcelles)), calc_exposure_i, .progress = TRUE)
  plan(sequential)
  exposures <- do.call(rbind, exposures_list)
} else if (requireNamespace("purrr", quietly = TRUE)) {
  library(purrr)
  cat("Mode séquentiel (purrr)...\n")
  exposures_list <- map(seq_len(nrow(parcelles)), calc_exposure_i)
  exposures <- do.call(rbind, exposures_list)
} else {
  cat("Mode séquentiel (base R)...\n")
  exposures <- t(sapply(seq_len(nrow(parcelles)), calc_exposure_i))
}

parcelles$L1_vent <- exposures[, "vent"]
parcelles$L1_soleil <- exposures[, "soleil"]

# Score d'exposition combiné (stress = exposition élevée)
parcelles$L1_exposition <- 0.6 * parcelles$L1_vent + 0.4 * parcelles$L1_soleil

cat("Exposition vent moyenne:", round(mean(parcelles$L1_vent), 1), "\n")
cat("Exposition soleil moyenne:", round(mean(parcelles$L1_soleil), 1), "\n")
cat("L1_exposition moyenne:", round(mean(parcelles$L1_exposition), 1), "\n\n")

# ============================================================
# 5. INDICE L1 DE SYNTHÈSE (Sylvosphère)
# ============================================================
cat("=== 5. Indice L1 de synthèse (Sylvosphère) ===\n")

# Pondération des composantes
# - Géométrie : 30% (quantité de lisière)
# - Contraste : 40% (qualité de la transition)
# - Exposition : 30% (stress climatique)

weights_L1 <- c(
  geometrie = 0.30,
  contraste = 0.40,
  exposition = 0.30
)

parcelles$L1 <- weights_L1["geometrie"] * parcelles$L1_geometrie +
  weights_L1["contraste"] * parcelles$L1_contraste +
  weights_L1["exposition"] * parcelles$L1_exposition

cat("Composantes de L1:\n")
cat("- Géométrie (30%):", round(mean(parcelles$L1_geometrie), 1), "\n")
cat("- Contraste (40%):", round(mean(parcelles$L1_contraste), 1), "\n")
cat("- Exposition (30%):", round(mean(parcelles$L1_exposition), 1), "\n")
cat("\nL1 FINAL (Sylvosphère):", round(mean(parcelles$L1), 1), "/ 100\n")

# Interprétation
cat("\n=== Interprétation ===\n")
cat("L1 élevé = Lisière stressante (forme allongée, urbain, exposée)\n")
cat("L1 faible = Lisière douce (compacte, prairie, protégée)\n")

# Classification qualitative
parcelles$L1_classe <- cut(parcelles$L1,
  breaks = c(0, 25, 50, 75, 100),
  labels = c("Douce", "Modérée", "Dure", "Très dure"),
  include.lowest = TRUE
)

cat("\nDistribution des lisières:\n")
print(table(parcelles$L1_classe))

# Sauvegarder
output_path <- file.path(data_dir, "metriques_lisiere_l1.gpkg")
st_write(parcelles, output_path, delete_dsn = TRUE, quiet = TRUE)
st_write(parcelles, parcelles_path, delete_dsn = TRUE, quiet = TRUE)
cat("\n=== Métriques L1 Lisière exportées ===\n")
cat("Fichier:", output_path, "\n")
cat("Parcelles:", nrow(parcelles), " lignes et ", ncol(parcelles), " colonnes\n\n")
```


### Exercice 4.2 : Fragmentation paysagère (L2)

L'indicateur **L2** mesure le degré de **fragmentation** du paysage forestier à l'aide de métriques paysagères standardisées.

| Métrique | Description | Interprétation |
|----------|-------------|----------------|
| **NP** | Nombre de patches | Plus élevé = plus fragmenté |
| **PD** | Densité de patches | Patches par km² |
| **ED** | Densité de lisières | m de lisière par ha |
| **COHESION** | Cohésion | Connectivité physique (0-100) |
| **AI** | Agrégation | Groupement des patches (0-100) |

```{r ex-4-2-setup}
library(sf)
library(terra)
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
```

```{r ex-4-2, exercise=TRUE, exercise.eval=FALSE, exercise.lines=120, exercise.setup="ex-4-2-setup", exercise.timelimit=300}
# === INDICATEUR L2 (FRAGMENTATION PAYSAGÈRE) ===
# Utilise landscapemetrics pour quantifier la fragmentation

parcelles_path <- file.path(data_dir, "parcelles.gpkg")
bd_foret_path <- file.path(data_dir, "bd_foret.gpkg")

if (!file.exists(parcelles_path)) {
  stop("Données manquantes. Exécutez d'abord les tutoriels précédents.")
}

parcelles <- st_read(parcelles_path, quiet = TRUE)
bd_foret <- if (file.exists(bd_foret_path)) st_read(bd_foret_path, quiet = TRUE) else NULL

cat("=== INDICATEUR L2 : Fragmentation paysagère ===\n\n")

# Zone d'analyse avec buffer 1km pour capturer le contexte paysager
zone_buffer <- st_buffer(st_union(parcelles), 1000)

# Vérifier landscapemetrics
if (requireNamespace("landscapemetrics", quietly = TRUE)) {
  library(landscapemetrics)

  # Créer un raster de couverture forestière
  cat("1. Création du raster de couverture forestière...\n")

  # Résolution 10m pour les métriques paysagères
  # Convertir la zone buffer en extent via vect() pour compatibilité terra
  zone_vect <- vect(zone_buffer)
  r_template <- rast(zone_vect, resolution = 10, crs = st_crs(parcelles)$wkt)

  # Rasteriser : 1 = forêt, 0 = non-forêt
  if (!is.null(bd_foret) && nrow(bd_foret) > 0) {
    bd_foret_zone <- suppressWarnings(st_intersection(st_make_valid(bd_foret), zone_buffer))
    r_foret <- rasterize(vect(bd_foret_zone), r_template, field = 1, background = 0)
  } else {
    # Fallback : utiliser les parcelles comme proxy forestier
    r_foret <- rasterize(vect(parcelles), r_template, field = 1, background = 0)
  }

  cat("   Raster:", ncol(r_foret), "x", nrow(r_foret), "pixels\n\n")

  # Calculer les métriques paysagères au niveau du paysage
  cat("2. Calcul des métriques paysagères (landscapemetrics)...\n")

  # Métriques de fragmentation
  metrics <- tryCatch(
    {
      lsm_results <- calculate_lsm(r_foret,
        what = c(
          "lsm_l_np", # Nombre de patches
          "lsm_l_pd", # Densité de patches
          "lsm_l_ed", # Densité de lisières
          "lsm_l_cohesion", # Cohésion
          "lsm_l_ai"
        )
      ) # Agrégation
      lsm_results
    },
    error = function(e) {
      cat("   Erreur landscapemetrics:", e$message, "\n")
      NULL
    }
  )

  if (!is.null(metrics) && nrow(metrics) > 0) {
    cat("\n=== Métriques paysagères (niveau paysage) ===\n")

    # Extraire les valeurs
    np <- metrics$value[metrics$metric == "np"]
    pd <- metrics$value[metrics$metric == "pd"]
    ed <- metrics$value[metrics$metric == "ed"]
    cohesion <- metrics$value[metrics$metric == "cohesion"]
    ai <- metrics$value[metrics$metric == "ai"]

    cat("NP (nombre patches):", round(np, 0), "\n")
    cat("PD (densité patches/km²):", round(pd, 2), "\n")
    cat("ED (densité lisières m/ha):", round(ed, 2), "\n")
    cat("COHESION:", round(cohesion, 1), "%\n")
    cat("AI (agrégation):", round(ai, 1), "%\n")

    # Calculer L2 : indice de fragmentation (0-100)
    # L2 élevé = peu fragmenté (bon)
    # Basé sur cohésion et agrégation (inversement proportionnel à NP et ED)
    L2 <- round((cohesion + ai) / 2, 1)

    cat("\n=== Indice L2 (Fragmentation) ===\n")
    cat("L2:", L2, "/ 100\n")
    cat("Interprétation: 0 = très fragmenté, 100 = très cohésif\n")

    # Attribuer L2 à chaque parcelle (même valeur car calculé au niveau paysage)
    parcelles$L2 <- L2
    parcelles$L2_np <- round(np, 0)
    parcelles$L2_cohesion <- round(cohesion, 1)
    parcelles$L2_ai <- round(ai, 1)
  } else {
    cat("Impossible de calculer les métriques.\n")
    parcelles$L2 <- NA
  }
} else {
  cat("Package landscapemetrics non disponible.\n")
  cat("Installez-le avec: install.packages('landscapemetrics')\n")

  # Fallback : estimation simplifiée basée sur la géométrie
  cat("\nCalcul simplifié basé sur la géométrie des parcelles...\n")

  perimeter <- as.numeric(st_length(st_cast(parcelles, "MULTILINESTRING")))
  area <- as.numeric(st_area(parcelles))
  shape_index <- perimeter / (2 * sqrt(pi * area))

  # L2 simplifié : inverse de l'indice de forme (forme compacte = moins fragmenté)
  parcelles$L2 <- round(100 / shape_index, 1)
  parcelles$L2 <- pmin(parcelles$L2, 100) # Plafonner à 100
}

# Sauvegarder
output_path <- file.path(data_dir, "metriques_fragmentation_l2.gpkg")
st_write(parcelles, output_path, delete_dsn = TRUE, quiet = TRUE)
st_write(parcelles, parcelles_path, delete_dsn = TRUE, quiet = TRUE)
cat("\n=== Métriques L2 Fragmentation exportées ===\n")
cat("Fichier:", output_path, "\n")
cat("Parcelles:", nrow(parcelles), " lignes et ", ncol(parcelles), " colonnes\n\n")
```


---

### Exercice 4.3 : Trame Verte et Bleue (L3)

L'indicateur **L3** mesure l'intégration de la parcelle dans la **Trame Verte et Bleue (TVB)** nationale, qui identifie les corridors écologiques essentiels.

| Source | Description | Package |
|--------|-------------|---------|
| **SRCE** | Schémas Régionaux de Cohérence Écologique | happign WFS |
| **INPN** | Corridors écologiques nationaux | happign WFS |
| **BD TOPO** | Cours d'eau, haies | happign WFS |

```{r ex-4-3-setup}
library(sf)
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
```

```{r ex-4-3, exercise=TRUE, exercise.eval=FALSE, exercise.lines=120, exercise.setup="ex-4-3-setup", exercise.timelimit=600}
# === INDICATEUR L3 (TRAME VERTE ET BLEUE) ===

parcelles_path <- file.path(data_dir, "parcelles.gpkg")
parcelles <- st_read(parcelles_path, quiet = TRUE)

zone_analyse <- st_buffer(st_union(parcelles), 1000)
bbox <- st_bbox(st_transform(zone_analyse, 4326))

cat("=== Indicateur L3 : Intégration TVB ===\n\n")

# ============================================================
# 1. TÉLÉCHARGEMENT DES DONNÉES TVB
# ============================================================

tvb_data <- NULL
corridors <- NULL
cours_eau <- NULL

# Trame Verte (corridors terrestres)
if (requireNamespace("happign", quietly = TRUE)) {
  library(happign)

  tryCatch(
    {
      # Chercher les couches de corridors écologiques
      wfs_layers <- get_layers_metadata("wfs")

      # Couches TVB potentielles
      tvb_patterns <- c("corridor", "trame_verte", "continuite", "srce", "reservoir")
      tvb_layers <- wfs_layers$Name[grepl(paste(tvb_patterns, collapse = "|"),
        wfs_layers$Name,
        ignore.case = TRUE
      )]

      if (length(tvb_layers) > 0) {
        cat("Couches TVB trouvées:", length(tvb_layers), "\n")

        # Télécharger la première couche disponible
        zone_bbox <- st_as_sfc(st_bbox(zone_analyse))
        st_crs(zone_bbox) <- st_crs(zone_analyse)

        for (layer in head(tvb_layers, 3)) {
          tryCatch(
            {
              tvb_data <- get_wfs(x = zone_bbox, layer = layer, spatial_filter = "bbox")
              if (!is.null(tvb_data) && nrow(tvb_data) > 0) {
                cat("Couche utilisée:", layer, "-", nrow(tvb_data), "entités\n")
                break
              }
            },
            error = function(e) NULL
          )
        }
      }
    },
    error = function(e) {
      cat("Erreur TVB:", e$message, "\n")
    }
  )
}

# Trame Bleue (cours d'eau)
cours_eau_path <- file.path(data_dir, "cours_eau.gpkg")
if (file.exists(cours_eau_path)) {
  cours_eau <- st_read(cours_eau_path, quiet = TRUE)
  cours_eau <- st_transform(cours_eau, st_crs(parcelles))
  cat("Cours d'eau chargés:", nrow(cours_eau), "entités\n")
}

# ============================================================
# 2. CALCUL DE L3 PAR PARCELLE
# ============================================================

cat("\n=== Calcul de L3 ===\n")

# Préparer les données TVB si disponibles
tvb_trans <- NULL
if (!is.null(tvb_data) && nrow(tvb_data) > 0) {
  tvb_trans <- st_transform(tvb_data, st_crs(parcelles))
}

# Fonction de calcul L3 pour une parcelle
calc_l3_i <- function(i, parcelles_geom, tvb_trans, cours_eau) {
  geom <- parcelles_geom[i]
  buffer_500m <- st_buffer(geom, 500)

  # Trame Verte
  trame_verte <- 0
  if (!is.null(tvb_trans) && nrow(tvb_trans) > 0) {
    inter_tvb <- suppressWarnings(
      tryCatch(st_intersection(tvb_trans, buffer_500m), error = function(e) NULL)
    )
    if (!is.null(inter_tvb) && nrow(inter_tvb) > 0) {
      surface_tvb <- as.numeric(sum(st_area(inter_tvb)))
      surface_buffer <- as.numeric(st_area(buffer_500m))
      trame_verte <- min(100, (surface_tvb / surface_buffer) * 200)
    }
  }

  # Trame Bleue
  trame_bleue <- 0
  if (!is.null(cours_eau) && nrow(cours_eau) > 0) {
    dist_eau <- min(as.numeric(st_distance(geom, cours_eau)), na.rm = TRUE)
    trame_bleue <- max(0, 100 - (dist_eau / 20))

    inter_eau <- suppressWarnings(
      tryCatch(st_intersection(cours_eau, geom), error = function(e) NULL)
    )
    if (!is.null(inter_eau) && nrow(inter_eau) > 0) {
      trame_bleue <- min(100, trame_bleue + 30)
    }
  }

  return(c(trame_verte = trame_verte, trame_bleue = trame_bleue))
}

# Parallélisation si furrr disponible
parcelles_geom <- st_geometry(parcelles)

if (requireNamespace("furrr", quietly = TRUE) && requireNamespace("future", quietly = TRUE)) {
  library(furrr)
  library(future)
  plan(multisession, workers = max(1, availableCores() - 1))
  cat("Mode parallèle (furrr,", nbrOfWorkers(), "workers)...\n")
  results_list <- future_map(seq_len(nrow(parcelles)), calc_l3_i,
    parcelles_geom = parcelles_geom,
    tvb_trans = tvb_trans,
    cours_eau = cours_eau,
    .progress = TRUE
  )
  plan(sequential)
  results <- do.call(rbind, results_list)
} else if (requireNamespace("purrr", quietly = TRUE)) {
  library(purrr)
  cat("Mode séquentiel (purrr)...\n")
  results_list <- map(seq_len(nrow(parcelles)), calc_l3_i,
    parcelles_geom = parcelles_geom,
    tvb_trans = tvb_trans,
    cours_eau = cours_eau
  )
  results <- do.call(rbind, results_list)
} else {
  cat("Mode séquentiel (base R)...\n")
  results <- t(sapply(seq_len(nrow(parcelles)), function(i) {
    calc_l3_i(i, parcelles_geom, tvb_trans, cours_eau)
  }))
}

parcelles$L3_trame_verte <- results[, "trame_verte"]
parcelles$L3_trame_bleue <- results[, "trame_bleue"]

# L3 composite: 60% Trame Verte + 40% Trame Bleue
parcelles$L3 <- 0.6 * parcelles$L3_trame_verte + 0.4 * parcelles$L3_trame_bleue

cat("L3 (TVB) moyen:", round(mean(parcelles$L3, na.rm = TRUE), 1), "\n")
cat("- Trame Verte:", round(mean(parcelles$L3_trame_verte, na.rm = TRUE), 1), "\n")
cat("- Trame Bleue:", round(mean(parcelles$L3_trame_bleue, na.rm = TRUE), 1), "\n")

# Sauvegarder
output_path <- file.path(data_dir, "metriques_tvb_l3.gpkg")
st_write(parcelles, output_path, delete_dsn = TRUE, quiet = TRUE)
st_write(parcelles, parcelles_path, delete_dsn = TRUE, quiet = TRUE)
cat("\n=== Métriques L3 TVB exportées ===\n")
cat("Fichier:", output_path, "\n")
cat("Parcelles:", nrow(parcelles), " lignes et ", ncol(parcelles), " colonnes\n\n")
```


---

## Section 5 : Naturalité (N1, N2, N3)

### Exercice 5.1 : Indice de Naturalité

La **naturalité** mesure le degré d'éloignement d'un écosystème par rapport aux perturbations humaines.
L'indice N3 combine plusieurs composantes :

| Indicateur | Description | Source |
|------------|-------------|--------|
| **N1** | Distance aux infrastructures | Routes, bâtiments (BD TOPO/OSM) |
| **N2** | Continuité forestière | BD Forêt, cartes anciennes |
| **N3** | Indice composite | Combinaison pondérée |

```{r ex-5-1-setup}
library(sf)
library(terra)
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
```

```{r ex-5-1, exercise=TRUE, exercise.eval=FALSE, exercise.lines=180, exercise.setup="ex-5-1-setup", exercise.timelimit=600}
# === INDICATEURS NATURALITÉ (N1, N2, N3) ===

parcelles_path <- file.path(data_dir, "parcelles.gpkg")
routes_path <- file.path(data_dir, "routes.gpkg")
bd_foret_path <- file.path(data_dir, "bd_foret.gpkg")

if (!file.exists(parcelles_path)) {
  stop("Données manquantes. Exécutez d'abord les tutoriels précédents.")
}

parcelles <- st_read(parcelles_path, quiet = TRUE)
parcelles_centroids <- st_centroid(parcelles)

cat("=== Calcul des indicateurs de Naturalité ===\n\n")

# ============================================================
# N1 : DISTANCE AUX INFRASTRUCTURES
# ============================================================
cat("=== N1 : Distance aux infrastructures ===\n")

# Distance aux routes
dist_routes <- rep(1000, nrow(parcelles)) # Valeur par défaut

if (file.exists(routes_path)) {
  routes <- st_read(routes_path, quiet = TRUE)
  routes <- st_transform(routes, st_crs(parcelles))

  # Distance de chaque centroïde aux routes
  dist_routes <- as.numeric(st_distance(parcelles_centroids, st_union(routes)))
  cat("Distance moyenne aux routes:", round(mean(dist_routes)), "m\n")
}

# Distance aux bâtiments (via OSM si disponible)
dist_batiments <- rep(500, nrow(parcelles)) # Valeur par défaut

if (requireNamespace("osmdata", quietly = TRUE)) {
  library(osmdata)

  tryCatch(
    {
      bbox_wgs84 <- st_bbox(st_transform(st_buffer(st_union(parcelles), 1000), 4326))

      # Récupérer les bâtiments
      buildings <- opq(bbox_wgs84) |>
        add_osm_feature(key = "building") |>
        osmdata_sf()

      if (!is.null(buildings$osm_polygons) && nrow(buildings$osm_polygons) > 0) {
        batiments <- st_transform(buildings$osm_polygons, st_crs(parcelles))
        batiments_union <- st_union(batiments)
        dist_batiments <- as.numeric(st_distance(parcelles_centroids, batiments_union))
        cat("Distance moyenne aux bâtiments:", round(mean(dist_batiments)), "m\n")
      }
    },
    error = function(e) {
      cat("Bâtiments OSM non disponibles\n")
    }
  )
}

# Distance aux zones urbaines (urbanisation diffuse)
dist_urbain <- rep(2000, nrow(parcelles))

if (requireNamespace("osmdata", quietly = TRUE)) {
  tryCatch(
    {
      urban <- opq(bbox_wgs84) |>
        add_osm_feature(key = "landuse", value = c(
          "residential", "commercial",
          "industrial", "retail"
        )) |>
        osmdata_sf()

      if (!is.null(urban$osm_polygons) && nrow(urban$osm_polygons) > 0) {
        zones_urbaines <- st_transform(urban$osm_polygons, st_crs(parcelles))
        dist_urbain <- as.numeric(st_distance(parcelles_centroids, st_union(zones_urbaines)))
        cat("Distance moyenne zones urbaines:", round(mean(dist_urbain)), "m\n")
      }
    },
    error = function(e) NULL
  )
}

# N1 : Indice composite de distance (0-100, 100 = très éloigné)
# Pondération : routes 40%, bâtiments 35%, urbain 25%
# Normalisation : 0m = 0, 2000m+ = 100
N1_routes <- pmin(100, dist_routes / 20)
N1_batiments <- pmin(100, dist_batiments / 20)
N1_urbain <- pmin(100, dist_urbain / 20)

parcelles$N1 <- 0.40 * N1_routes + 0.35 * N1_batiments + 0.25 * N1_urbain

cat("\nN1 (Distance infrastructures):\n")
cat("  Moyenne:", round(mean(parcelles$N1), 1), "/ 100\n")
cat("  Min:", round(min(parcelles$N1), 1), "/ Max:", round(max(parcelles$N1), 1), "\n\n")

# ============================================================
# N2 : CONTINUITÉ FORESTIÈRE (BD Forêt + BD Forêt Anciennes)
# ============================================================
cat("=== N2 : Continuité forestière ===\n")

# La BD Forêt Anciennes contient les forêts présentes sur les cartes
# d'État-Major (1818-1866), soit ~200 ans d'ancienneté minimum

parcelles$N2 <- 50 # Valeur par défaut
parcelles$N2_anciennete <- 0 # % surface en forêt ancienne
parcelles$N2_boisement <- 0 # % surface boisée actuelle

# -------------------------------------------------------------
# Téléchargement BD Forêt Anciennes (IGN via happign)
# -------------------------------------------------------------
foret_ancienne <- NULL

if (requireNamespace("happign", quietly = TRUE)) {
  library(happign)

  cat("Téléchargement BD Forêt Anciennes (IGN)...\n")

  tryCatch(
    {
      # Chercher la couche forêt ancienne dans le WFS
      wfs_layers <- get_layers_metadata("wfs")

      # Patterns possibles pour la BD Forêt Anciennes
      ancienne_patterns <- c(
        "foret.*ancien", "ancien.*foret", "etat.major",
        "historique", "LANDCOVER.*FORESTAREAS.*HISTORY"
      )

      foret_ancienne_layer <- NULL
      for (pattern in ancienne_patterns) {
        matches <- wfs_layers$Name[grepl(pattern, wfs_layers$Name, ignore.case = TRUE)]
        if (length(matches) > 0) {
          foret_ancienne_layer <- matches[1]
          break
        }
      }

      if (!is.null(foret_ancienne_layer)) {
        cat("Couche trouvée:", foret_ancienne_layer, "\n")

        # Télécharger pour la zone d'analyse
        zone_bbox <- st_as_sfc(st_bbox(st_buffer(st_union(parcelles), 100)))
        st_crs(zone_bbox) <- st_crs(parcelles)

        foret_ancienne <- get_wfs(
          x = zone_bbox,
          layer = foret_ancienne_layer,
          spatial_filter = "bbox"
        )

        if (!is.null(foret_ancienne) && nrow(foret_ancienne) > 0) {
          foret_ancienne <- st_transform(foret_ancienne, st_crs(parcelles))
          foret_ancienne <- st_make_valid(foret_ancienne)
          cat("BD Forêt Anciennes récupérée:", nrow(foret_ancienne), "polygones\n")
        } else {
          foret_ancienne <- NULL
        }
      } else {
        cat("Couche BD Forêt Anciennes non trouvée dans le catalogue WFS\n")
      }
    },
    error = function(e) {
      cat("Erreur BD Forêt Anciennes:", e$message, "\n")
    }
  )
}

# Requête WFS directe si happign échoue
if (is.null(foret_ancienne)) {
  cat("Tentative requête WFS directe pour BD Forêt Anciennes...\n")

  tryCatch(
    {
      bbox <- st_bbox(st_transform(st_buffer(st_union(parcelles), 100), 4326))
      bbox_str <- paste(bbox["ymin"], bbox["xmin"], bbox["ymax"], bbox["xmax"], sep = ",")

      # URL WFS Géoplateforme - couche forêt ancienne
      wfs_url <- paste0(
        "https://data.geopf.fr/wfs/ows",
        "?SERVICE=WFS&VERSION=2.0.0&REQUEST=GetFeature",
        "&TYPENAMES=LANDCOVER.FORESTAREAS.HISTORY:foret_ancienne",
        "&BBOX=", bbox_str, ",EPSG:4326",
        "&OUTPUTFORMAT=application/json",
        "&COUNT=5000"
      )

      response <- tryCatch(st_read(wfs_url, quiet = TRUE), error = function(e) NULL)

      if (!is.null(response) && nrow(response) > 0) {
        foret_ancienne <- st_transform(response, st_crs(parcelles))
        foret_ancienne <- st_make_valid(foret_ancienne)
        cat("BD Forêt Anciennes (WFS direct):", nrow(foret_ancienne), "polygones\n")
      }
    },
    error = function(e) {
      cat("BD Forêt Anciennes non disponible pour cette zone\n")
    }
  )
}

# -------------------------------------------------------------
# Calcul N2 avec BD Forêt actuelle + BD Forêt Anciennes
# -------------------------------------------------------------

# Charger BD Forêt actuelle
bd_foret <- NULL
if (file.exists(bd_foret_path)) {
  bd_foret <- st_read(bd_foret_path, quiet = TRUE)
  bd_foret <- st_transform(bd_foret, st_crs(parcelles))
  bd_foret <- st_make_valid(bd_foret)
  cat("BD Forêt actuelle:", nrow(bd_foret), "polygones\n")
}

cat("\nCalcul de N2 par parcelle...\n")

# Fonction de calcul N2 pour une parcelle
calc_n2_i <- function(i, parcelles_geom, bd_foret, foret_ancienne) {
  parcelle_i <- parcelles_geom[i]
  parcelle_area <- as.numeric(st_area(parcelle_i))

  # --- Taux de boisement actuel (BD Forêt) ---
  taux_boisement <- 0
  if (!is.null(bd_foret)) {
    inter_foret <- suppressWarnings(
      tryCatch(st_intersection(bd_foret, parcelle_i), error = function(e) NULL)
    )
    if (!is.null(inter_foret) && nrow(inter_foret) > 0) {
      forest_area <- sum(as.numeric(st_area(inter_foret)))
      taux_boisement <- min(1, forest_area / parcelle_area)
    }
  }

  # --- Taux de forêt ancienne (BD Forêt Anciennes) ---
  taux_ancienne <- 0
  if (!is.null(foret_ancienne)) {
    inter_ancienne <- suppressWarnings(
      tryCatch(st_intersection(foret_ancienne, parcelle_i), error = function(e) NULL)
    )
    if (!is.null(inter_ancienne) && nrow(inter_ancienne) > 0) {
      ancienne_area <- sum(as.numeric(st_area(inter_ancienne)))
      taux_ancienne <- min(1, ancienne_area / parcelle_area)
    }
  }

  # --- Calcul N2 composite ---
  if (taux_ancienne > 0) {
    n2_score <- 60 + (taux_ancienne * 40)
  } else if (taux_boisement > 0) {
    n2_score <- 30 + (taux_boisement * 30)
  } else {
    n2_score <- 15
  }

  return(c(
    boisement = taux_boisement * 100,
    anciennete = taux_ancienne * 100,
    n2 = n2_score
  ))
}

# Parallélisation si furrr disponible
parcelles_geom <- st_geometry(parcelles)

if (requireNamespace("furrr", quietly = TRUE) && requireNamespace("future", quietly = TRUE)) {
  library(furrr)
  library(future)
  plan(multisession, workers = max(1, availableCores() - 1))
  cat("Mode parallèle (furrr,", nbrOfWorkers(), "workers)...\n")
  results_list <- future_map(seq_len(nrow(parcelles)), calc_n2_i,
    parcelles_geom = parcelles_geom,
    bd_foret = bd_foret,
    foret_ancienne = foret_ancienne,
    .progress = TRUE
  )
  plan(sequential)
  results <- do.call(rbind, results_list)
} else if (requireNamespace("purrr", quietly = TRUE)) {
  library(purrr)
  cat("Mode séquentiel (purrr)...\n")
  results_list <- map(seq_len(nrow(parcelles)), calc_n2_i,
    parcelles_geom = parcelles_geom,
    bd_foret = bd_foret,
    foret_ancienne = foret_ancienne
  )
  results <- do.call(rbind, results_list)
} else {
  cat("Mode séquentiel (base R)...\n")
  results <- t(sapply(seq_len(nrow(parcelles)), function(i) {
    calc_n2_i(i, parcelles_geom, bd_foret, foret_ancienne)
  }))
}

parcelles$N2_boisement <- results[, "boisement"]
parcelles$N2_anciennete <- results[, "anciennete"]
parcelles$N2 <- results[, "n2"]

# Résumé
cat("\nRésultats N2:\n")
cat("  Taux boisement moyen:", round(mean(parcelles$N2_boisement), 1), "%\n")
cat("  Taux forêt ancienne moyen:", round(mean(parcelles$N2_anciennete), 1), "%\n")
cat("  N2 moyen:", round(mean(parcelles$N2), 1), "/ 100\n")

# Distribution par catégorie d'ancienneté
n_ancienne <- sum(parcelles$N2_anciennete > 50)
n_recente <- sum(parcelles$N2_anciennete <= 50 & parcelles$N2_boisement > 50)
n_non_boisee <- sum(parcelles$N2_boisement <= 50)

cat("\nCatégories:\n")
cat("  - Forêt ancienne (>50% sur carte 1850):", n_ancienne, "parcelles\n")
cat("  - Forêt récente (<200 ans):", n_recente, "parcelles\n")
cat("  - Peu ou pas boisé:", n_non_boisee, "parcelles\n\n")

# ============================================================
# N3 : INDICE COMPOSITE DE NATURALITÉ
# ============================================================
cat("=== N3 : Indice composite de naturalité ===\n")

# Facteurs additionnels pour N3 :

# Fragmentation (inverse de L1 si disponible)
if ("L1" %in% names(parcelles)) {
  N3_fragmentation <- 100 - parcelles$L1 # Moins fragmenté = plus naturel
} else {
  N3_fragmentation <- 50
}

# Connectivité (B3 si disponible)
if ("B3" %in% names(parcelles)) {
  N3_connectivite <- parcelles$B3
} else {
  N3_connectivite <- 50
}

# Calcul N3 composite
# Pondération : N1 (distance) 35%, N2 (continuité) 35%, fragmentation 15%, connectivité 15%
parcelles$N3 <- 0.35 * parcelles$N1 +
  0.35 * parcelles$N2 +
  0.15 * N3_fragmentation +
  0.15 * N3_connectivite

cat("Pondération N3:\n")
cat("  - Distance infrastructures (N1): 35%\n")
cat("  - Continuité forestière (N2): 35%\n")
cat("  - Anti-fragmentation: 15%\n")
cat("  - Connectivité: 15%\n")

cat("\nN3 (Naturalité composite):\n")
cat("  Moyenne:", round(mean(parcelles$N3), 1), "/ 100\n")
cat("  Min:", round(min(parcelles$N3), 1), "/ Max:", round(max(parcelles$N3), 1), "\n")

# Classification
parcelles$N3_classe <- cut(parcelles$N3,
  breaks = c(0, 25, 50, 75, 100),
  labels = c("Faible", "Modérée", "Bonne", "Excellente"),
  include.lowest = TRUE
)

cat("\nDistribution de la naturalité:\n")
print(table(parcelles$N3_classe))

# Sauvegarder
output_path <- file.path(data_dir, "metriques_naturalite_n1n2n3.gpkg")
st_write(parcelles, output_path, delete_dsn = TRUE, quiet = TRUE)
st_write(parcelles, parcelles_path, delete_dsn = TRUE, quiet = TRUE)
cat("\n=== Métriques N1, N2, N3 Naturalité exportées ===\n")
cat("Fichier:", output_path, "\n")
cat("Parcelles:", nrow(parcelles), " lignes et ", ncol(parcelles), " colonnes\n\n")
```


---

## Section 6 : Indicateurs Complémentaires (T1, T2)

Cette section calcule les indicateurs complémentaires :
- **T1, T2** : Dynamique temporelle (âge et changement du peuplement)

> **Note** : F2 (fertilité sol) est maintenant calculé dans Tutorial 03 (terrain).

### Exercice 6.1 : Dynamique temporelle (T1, T2)

Les indicateurs **T1** et **T2** évaluent la **dynamique temporelle** des peuplements forestiers.

| Indicateur | Description | Source |
|------------|-------------|--------|
| **T1** | Âge du peuplement | BD Forêt (champ TFV - Type de Formation Végétale) |
| **T2** | Taux de changement | Comparaison BD Forêt multi-dates |

```{r ex-6-1-t-setup}
library(sf)
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
```

```{r ex-6-1-t, exercise=TRUE, exercise.eval=FALSE, exercise.lines=120, exercise.setup="ex-6-1-t-setup", exercise.timelimit=300}
# === INDICATEURS TEMPORELS (T1, T2) ===

parcelles_path <- file.path(data_dir, "parcelles.gpkg")
bd_foret_path <- file.path(data_dir, "bd_foret.gpkg")

if (!file.exists(parcelles_path)) {
  stop("Données manquantes. Exécutez d'abord les tutoriels précédents.")
}

parcelles <- st_read(parcelles_path, quiet = TRUE)

cat("=== INDICATEURS TEMPORELS (T1, T2) ===\n\n")

# ============================================================
# T1 : ÂGE DU PEUPLEMENT
# ============================================================
cat("=== T1 : Âge du peuplement ===\n")

# Estimation de l'âge basée sur le Type de Formation Végétale (TFV)
# TFV codes principaux et âges estimés :
# - Forêt fermée de feuillus : 80-150 ans
# - Forêt fermée de conifères : 60-100 ans
# - Forêt ouverte : 30-60 ans
# - Peupleraie : 15-25 ans
# - Jeune peuplement : 5-20 ans

parcelles$T1 <- 50 # Valeur par défaut (âge moyen)

if (file.exists(bd_foret_path)) {
  bd_foret <- st_read(bd_foret_path, quiet = TRUE)
  bd_foret <- st_transform(bd_foret, st_crs(parcelles))

  cat("BD Forêt chargée:", nrow(bd_foret), "polygones\n")

  # Chercher le champ TFV ou équivalent
  tfv_field <- NULL
  for (field in c("TFV", "tfv", "CODE_TFV", "ESSENCE", "essence")) {
    if (field %in% names(bd_foret)) {
      tfv_field <- field
      break
    }
  }

  if (!is.null(tfv_field)) {
    cat("Champ TFV trouvé:", tfv_field, "\n")

    # Fonction d'estimation de l'âge selon le TFV
    estimate_age <- function(tfv) {
      tfv_lower <- tolower(as.character(tfv))
      age <- ifelse(grepl("ferm.*feuill|futaie.*feuill", tfv_lower), 100,
        ifelse(grepl("ferm.*conif|futaie.*conif", tfv_lower), 80,
          ifelse(grepl("ouvert|taillis", tfv_lower), 45,
            ifelse(grepl("peupler", tfv_lower), 20,
              ifelse(grepl("jeune|lande.*bois", tfv_lower), 15, 50)
            )
          )
        )
      )
      return(age)
    }

    # Fonction de calcul T1 pour une parcelle
    calc_t1_i <- function(i, parcelles_sf, bd_foret, tfv_field, estimate_age) {
      parcelle_i <- parcelles_sf[i, ]
      inter <- suppressWarnings(
        tryCatch(st_intersection(bd_foret, parcelle_i), error = function(e) NULL)
      )

      if (!is.null(inter) && nrow(inter) > 0) {
        inter$area <- as.numeric(st_area(inter))
        inter$age_est <- estimate_age(inter[[tfv_field]])

        total_area <- sum(inter$area)
        if (total_area > 0) {
          return(sum(inter$area * inter$age_est) / total_area)
        }
      }
      return(50) # Valeur par défaut
    }

    # Parallélisation si furrr disponible
    if (requireNamespace("furrr", quietly = TRUE) && requireNamespace("future", quietly = TRUE)) {
      library(furrr)
      library(future)
      plan(multisession, workers = max(1, availableCores() - 1))
      cat("Mode parallèle (furrr,", nbrOfWorkers(), "workers)...\n")
      parcelles$T1 <- future_map_dbl(seq_len(nrow(parcelles)), calc_t1_i,
        parcelles_sf = parcelles,
        bd_foret = bd_foret,
        tfv_field = tfv_field,
        estimate_age = estimate_age,
        .progress = TRUE
      )
      plan(sequential)
    } else if (requireNamespace("purrr", quietly = TRUE)) {
      library(purrr)
      cat("Mode séquentiel (purrr)...\n")
      parcelles$T1 <- map_dbl(seq_len(nrow(parcelles)), calc_t1_i,
        parcelles_sf = parcelles,
        bd_foret = bd_foret,
        tfv_field = tfv_field,
        estimate_age = estimate_age
      )
    } else {
      cat("Mode séquentiel (base R)...\n")
      parcelles$T1 <- sapply(seq_len(nrow(parcelles)), function(i) {
        calc_t1_i(i, parcelles, bd_foret, tfv_field, estimate_age)
      })
    }
  } else {
    cat("Champ TFV non trouvé - utilisation de valeurs par défaut\n")
  }
}

cat("\nRésultats T1 (âge estimé):\n")
cat("  Âge moyen:", round(mean(parcelles$T1, na.rm = TRUE), 0), "ans\n")
cat(
  "  Min:", round(min(parcelles$T1, na.rm = TRUE), 0), "/ Max:",
  round(max(parcelles$T1, na.rm = TRUE), 0), "ans\n"
)

# ============================================================
# T2 : TAUX DE CHANGEMENT
# ============================================================
cat("\n=== T2 : Taux de changement ===\n")

# T2 mesure la stabilité/dynamique du couvert forestier
# Basé sur N2_anciennete (forêt ancienne vs récente)
# Score : 100 = très stable (forêt ancienne), 0 = changement récent

if ("N2_anciennete" %in% names(parcelles)) {
  # Utiliser l'ancienneté comme proxy de stabilité
  parcelles$T2 <- parcelles$N2_anciennete
  cat("T2 calculé depuis N2_anciennete\n")
} else {
  # Valeur par défaut basée sur T1
  # Plus l'âge est élevé, plus la forêt est stable
  parcelles$T2 <- pmin(100, parcelles$T1)
  cat("T2 estimé depuis T1 (âge)\n")
}

cat("\nRésultats T2 (stabilité):\n")
cat("  T2 moyen:", round(mean(parcelles$T2, na.rm = TRUE), 1), "/ 100\n")
cat("  Interprétation: 100 = très stable, 0 = changement récent\n")

# Classification
parcelles$T_classe <- cut((parcelles$T1 + parcelles$T2) / 2,
  breaks = c(0, 25, 50, 75, 150),
  labels = c(
    "Jeune/Instable", "En développement",
    "Mature", "Ancienne/Stable"
  ),
  include.lowest = TRUE
)

cat("\nDistribution temporelle:\n")
print(table(parcelles$T_classe))

# Sauvegarder
output_path <- file.path(data_dir, "metriques_temporel_t1t2.gpkg")
st_write(parcelles, output_path, delete_dsn = TRUE, quiet = TRUE)
st_write(parcelles, parcelles_path, delete_dsn = TRUE, quiet = TRUE)
cat("\n=== Métriques T1, T2 Temporel exportées ===\n")
cat("Fichier:", output_path, "\n")
cat("Parcelles:", nrow(parcelles), " lignes et ", ncol(parcelles), " colonnes\n\n")
```


---

## Section 7 : Export et Synthèse

Les indicateurs ont été calculés par parcelle dans les sections précédentes.
Cette section consolide tous les indicateurs dans un fichier unique.

### Exercice 7.1 : Famille B (Biodiversité)

```{r ex-7-1-setup}
library(sf)
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
```

```{r ex-7-1, exercise=TRUE, exercise.eval=FALSE, exercise.lines=45, exercise.setup="ex-7-1-setup"}
# === FAMILLE B (BIODIVERSITÉ) : B1, B2, B3 ===
# Consolidation des indicateurs déjà calculés

parcelles_path <- file.path(data_dir, "parcelles.gpkg")
output_path <- file.path(data_dir, "indicateurs_ecologiques.gpkg")

parcelles <- st_read(parcelles_path, quiet = TRUE)
cat("=== Famille B (Biodiversité) ===\n\n")

# B1 : Zone de protection (calculé en section 2)
b1_path <- file.path(data_dir, "metriques_zone_protection_b1.gpkg")
if (file.exists(b1_path)) {
  b1_data <- st_read(b1_path, quiet = TRUE) |> st_drop_geometry()
  if ("B1" %in% names(b1_data)) {
    parcelles$B1 <- b1_data$B1
    cat("B1 (protection):", round(mean(parcelles$B1, na.rm = TRUE), 1), "\n")
    cat("   0 = non protégé, 100 = entièrement protégé\n\n")
  }
}

# B2 : Structure verticale (calculé en section 3)
b2_path <- file.path(data_dir, "metriques_structure_verticale_b2.gpkg")
if (file.exists(b2_path)) {
  b2_data <- st_read(b2_path, quiet = TRUE) |> st_drop_geometry()
  if ("B2" %in% names(b2_data)) {
    parcelles$B2 <- b2_data$B2
    cat("B2 (structure):", round(mean(parcelles$B2, na.rm = TRUE), 1), "\n")
    cat("   0 = homogène, 100 = très diversifié verticalement\n\n")
  }
}

# B3 : Connectivité (calculé en section 3)
b3_path <- file.path(data_dir, "metriques_connectivite_b3.gpkg")
if (file.exists(b3_path)) {
  b3_data <- st_read(b3_path, quiet = TRUE) |> st_drop_geometry()
  if ("B3" %in% names(b3_data)) {
    parcelles$B3 <- b3_data$B3
    cat("B3 (connectivité):", round(mean(parcelles$B3, na.rm = TRUE), 1), "\n")
    cat("   0 = isolé, 100 = très connecté\n")
  }
}

# Sauvegarder
st_write(parcelles, output_path, delete_dsn = TRUE, quiet = TRUE)
cat("\n✓ Famille B consolidée:", basename(output_path), "\n")
```


---

### Exercice 7.2 : Famille L (Paysage)

```{r ex-7-2-setup}
library(sf)
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
```

```{r ex-7-2, exercise=TRUE, exercise.eval=FALSE, exercise.lines=45, exercise.setup="ex-7-2-setup"}
# === FAMILLE L (PAYSAGE) : L1, L2, L3 ===
# Consolidation des indicateurs déjà calculés

output_path <- file.path(data_dir, "indicateurs_ecologiques.gpkg")
parcelles <- st_read(output_path, quiet = TRUE)

cat("=== Famille L (Paysage) ===\n\n")

# L1 : Lisière (calculé en exercice 4.1)
l1_path <- file.path(data_dir, "metriques_lisiere_l1.gpkg")
if (file.exists(l1_path)) {
  l1_data <- st_read(l1_path, quiet = TRUE) |> st_drop_geometry()
  if ("L1" %in% names(l1_data)) {
    parcelles$L1 <- l1_data$L1
    cat("L1 (lisière):", round(mean(parcelles$L1, na.rm = TRUE), 1), "\n")
    cat("   0 = lisière douce, 100 = lisière dure (contraste fort)\n\n")
  }
}

# L2 : Fragmentation (calculé en exercice 4.2)
l2_path <- file.path(data_dir, "metriques_fragmentation_l2.gpkg")
if (file.exists(l2_path)) {
  l2_data <- st_read(l2_path, quiet = TRUE) |> st_drop_geometry()
  if ("L2" %in% names(l2_data)) {
    parcelles$L2 <- l2_data$L2
    cat("L2 (fragmentation):", round(mean(parcelles$L2, na.rm = TRUE), 1), "\n")
    cat("   0 = très fragmenté, 100 = très cohésif\n\n")
  }
}

# L3 : TVB (calculé en exercice 4.3)
l3_path <- file.path(data_dir, "metriques_tvb_l3.gpkg")
if (file.exists(l3_path)) {
  l3_data <- st_read(l3_path, quiet = TRUE) |> st_drop_geometry()
  if ("L3" %in% names(l3_data)) {
    parcelles$L3 <- l3_data$L3
    cat("L3 (TVB):", round(mean(parcelles$L3, na.rm = TRUE), 1), "\n")
    cat("   0 = hors trame, 100 = corridor majeur\n")
  }
}

# Sauvegarder
st_write(parcelles, output_path, delete_dsn = TRUE, quiet = TRUE)
cat("\n✓ Famille L consolidée:", basename(output_path), "\n")
```


---

### Exercice 7.3 : Famille T (Temporel)

```{r ex-7-3-setup}
library(sf)
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
```

```{r ex-7-3, exercise=TRUE, exercise.eval=FALSE, exercise.lines=40, exercise.setup="ex-7-3-setup"}
# === FAMILLE T (TEMPOREL) ===
# Consolidation des indicateurs déjà calculés

output_path <- file.path(data_dir, "indicateurs_ecologiques.gpkg")
parcelles <- st_read(output_path, quiet = TRUE)

cat("=== Famille T (Temporel) ===\n\n")

# T1, T2 : Dynamique temporelle (calculés en exercice 6.1)
t_path <- file.path(data_dir, "metriques_temporel_t1t2.gpkg")
if (file.exists(t_path)) {
  t_data <- st_read(t_path, quiet = TRUE) |> st_drop_geometry()
  if ("T1" %in% names(t_data)) {
    parcelles$T1 <- t_data$T1
    cat("T1 (âge peuplement):", round(mean(parcelles$T1, na.rm = TRUE), 1), "\n")
    cat("   0 = très jeune, 100 = mature/ancien\n\n")
  }
  if ("T2" %in% names(t_data)) {
    parcelles$T2 <- t_data$T2
    cat("T2 (stabilité):", round(mean(parcelles$T2, na.rm = TRUE), 1), "\n")
    cat("   0 = changement récent, 100 = très stable\n")
  }
}

# Sauvegarder
st_write(parcelles, output_path, delete_dsn = TRUE, quiet = TRUE)
cat("\n✓ Famille T consolidée:", basename(output_path), "\n")

cat("\n> Note: F2 (fertilité sol) est calculé dans Tutorial 03 (terrain)\n")
```


---

### Exercice 7.4 : Famille N (Naturalité)

```{r ex-7-4-setup}
library(sf)
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
```

```{r ex-7-4, exercise=TRUE, exercise.eval=FALSE, exercise.lines=40, exercise.setup="ex-7-4-setup"}
# === FAMILLE N (NATURALITÉ) : N1, N2, N3 ===
# Consolidation des indicateurs déjà calculés

output_path <- file.path(data_dir, "indicateurs_ecologiques.gpkg")
parcelles <- st_read(output_path, quiet = TRUE)

cat("=== Famille N (Naturalité) ===\n\n")

# N1, N2, N3 : Naturalité (calculés en section 5)
n_path <- file.path(data_dir, "metriques_naturalite_n1n2n3.gpkg")
if (file.exists(n_path)) {
  n_data <- st_read(n_path, quiet = TRUE) |> st_drop_geometry()

  if ("N1" %in% names(n_data)) {
    parcelles$N1 <- n_data$N1
    cat("N1 (distance infrastructures):", round(mean(parcelles$N1, na.rm = TRUE), 1), "\n")
    cat("   0 = proche routes/bâti, 100 = éloigné\n\n")
  }

  if ("N2" %in% names(n_data)) {
    parcelles$N2 <- n_data$N2
    cat("N2 (continuité forestière):", round(mean(parcelles$N2, na.rm = TRUE), 1), "\n")
    cat("   0 = forêt récente, 100 = forêt ancienne\n\n")
  }

  if ("N3" %in% names(n_data)) {
    parcelles$N3 <- n_data$N3
    cat("N3 (naturalité composite):", round(mean(parcelles$N3, na.rm = TRUE), 1), "\n")
    cat("   Combinaison N1 + N2 + fragmentation + connectivité\n")
  }
}

# Sauvegarder
st_write(parcelles, output_path, delete_dsn = TRUE, quiet = TRUE)
cat("\n✓ Famille N consolidée:", basename(output_path), "\n")
```


---

### Exercice 7.5 : Synthèse finale

```{r ex-7-5-setup}
library(sf)
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
```

```{r ex-7-5, exercise=TRUE, exercise.eval=FALSE, exercise.lines=80, exercise.setup="ex-7-5-setup"}
# === SYNTHÈSE FINALE ===
# Consolidation de tous les indicateurs écologiques

output_path <- file.path(data_dir, "indicateurs_ecologiques.gpkg")
parcelles <- st_read(output_path, quiet = TRUE)

cat("=== SYNTHÈSE INDICATEURS ÉCOLOGIQUES ===\n\n")

# Liste des indicateurs par famille (11 indicateurs)
familles <- list(
  "B (Biodiversité)" = c("B1", "B2", "B3"),
  "L (Paysage)" = c("L1", "L2", "L3"),
  "T (Temporel)" = c("T1", "T2"),
  "N (Naturalité)" = c("N1", "N2", "N3")
)

# Afficher les résultats par famille
for (fam in names(familles)) {
  cat("FAMILLE", fam, ":\n")
  for (ind in familles[[fam]]) {
    if (ind %in% names(parcelles)) {
      val <- mean(parcelles[[ind]], na.rm = TRUE)
      cat(sprintf("  - %s: %.1f\n", ind, val))
    } else {
      cat(sprintf("  - %s: non calculé\n", ind))
    }
  }
  cat("\n")
}

# Statistiques globales
indicateurs_calcules <- unlist(familles)
n_calcules <- sum(indicateurs_calcules %in% names(parcelles))
cat(strrep("=", 40), "\n")
cat("Parcelles:", nrow(parcelles), "\n")
cat("Indicateurs:", n_calcules, "/", length(indicateurs_calcules), "\n")
cat("Fichier:", basename(output_path), "\n")
cat(strrep("=", 40), "\n")

# Sauvegarder le fichier final
st_write(parcelles, output_path, delete_dsn = TRUE, quiet = TRUE)
cat("\n✓ Indicateurs écologiques consolidés\n")
```

### Fichiers produits

| Fichier | Contenu | Indicateurs |
|---------|---------|-------------|
| `indicateurs_ecologiques.gpkg` | Synthèse complète (11 indicateurs) | Tous |
| `metriques_zone_protection_b1.gpkg` | Zones protégées | B1 |
| `metriques_structure_verticale_b2.gpkg` | Structure LiDAR | B2 |
| `metriques_connectivite_b3.gpkg` | Connectivité | B3 |
| `metriques_lisiere_l1.gpkg` | Effet lisière | L1 |
| `metriques_fragmentation_l2.gpkg` | Fragmentation paysagère | L2 |
| `metriques_tvb_l3.gpkg` | Trame Verte Bleue | L3 |
| `metriques_temporel_t1t2.gpkg` | Dynamique temporelle | T1, T2 |
| `metriques_naturalite_n1n2n3.gpkg` | Naturalité | N1, N2, N3 |


---

## Quiz final

```{r quiz-final, echo=FALSE}
quiz(
  caption = "Testez vos connaissances",
  question("L'indicateur B1 mesure :",
    answer("Le taux de couverture par des zones protégées (ZNIEFF, N2000)", correct = TRUE),
    answer("La biomasse totale"),
    answer("La biodiversité génétique"),
    answer("Le nombre d'espèces"),
    allow_retry = TRUE,
    random_answer_order = TRUE
  ),
  question("Qu'est-ce que la naturalité (N) ?",
    answer("Le degré d'éloignement par rapport à l'état naturel, non perturbé", correct = TRUE),
    answer("La présence d'espèces natives"),
    answer("La productivité naturelle"),
    answer("Le pH naturel du sol"),
    allow_retry = TRUE,
    random_answer_order = TRUE
  )
)
```

---

## Synthèse

### Indicateurs calculés (14)

| Famille | Code | Indicateur |
|---------|------|------------|
| **B** | B1 | Protection (ZNIEFF, N2000) |
| **B** | B2 | Structure verticale |
| **B** | B3 | Connectivité écologique |
| **L** | L1 | Effet lisière |
| **L** | L2 | Fragmentation |
| **L** | L3 | Diversité paysagère |
| **C** | C2 | Vitalité (NDVI) |
| **T** | T1 | Âge du peuplement |
| **T** | T2 | Taux de changement |
| **A** | A2 | Qualité air forestier |
| **F** | F2 | Fertilité sol |
| **N** | N1 | Continuité forestière |
| **N** | N2 | Distance perturbations |
| **N** | N3 | Naturalité composite |

### Tutoriel suivant

→ **Tutorial 05 : Assemblage** — Indice Composite I_nemeton : Assembler les 32 indicateurs, normaliser les valeurs et calculer l'indice composite final.
