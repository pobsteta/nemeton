---
title: "Tutorial 04 : Écologie — Familles B, L, C, T, A, F, N (14 indicateurs)"
output:
  learnr::tutorial:
    progressive: true
    allow_skip: true
    language: fr
runtime: shiny_prerendered
description: >
  Calcul de 14 indicateurs écologiques : B1-3 (biodiversité), L1-3 (paysage/TVB),
  C2 (NDVI), T1-2 (temporel), A2 (qualité air), F2 (fertilité), N1-3 (naturalité).
---

```{r setup, include=FALSE}
library(learnr)
library(gradethis)
gradethis::gradethis_setup()
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
options(tutorial.exercise.timelimit = 300)
```

## Bienvenue

### Objectifs du tutoriel

Ce tutoriel calcule les **indicateurs écologiques** des familles :

- **B** (Biodiversité) : Protection, structure, connectivité
- **L** (Paysage) : Lisières, fragmentation
- **T** (Temporel) : Âge, changement
- **A2** (Air) : Qualité air forestier
- **F2** (Fertilité) : Fertilité sol
- **N** (Naturalité) : Continuité, distance, composite

### Sources de données

- **BD Forêt V2** : Types de peuplement, essences
- **INPN** : Zones protégées (ZNIEFF, Natura 2000)
- **Métriques LiDAR** : Structure verticale (du Tutorial 02)

---

## Section 1 : BD Forêt V2

### Exercice 1.1 : Explorer la BD Forêt

```{r ex-1-1-setup}
library(sf)
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
```

```{r ex-1-1, exercise=TRUE, exercise.lines=25, exercise.setup="ex-1-1-setup"}
# === EXPLORATION BD FORÊT V2 ===

bd_foret_path <- file.path(data_dir, "bd_foret.gpkg")

if (file.exists(bd_foret_path)) {
  bd_foret <- st_read(bd_foret_path, quiet = TRUE)
  
  cat("=== BD Forêt V2 ===\n")
  cat("Polygones:", nrow(bd_foret), "\n")
  cat("Colonnes:", paste(names(bd_foret)[1:min(10, ncol(bd_foret))], collapse = ", "), "\n\n")
  
  # Types de peuplement
  if ("tfv" %in% names(bd_foret)) {
    cat("=== Types de formation végétale ===\n")
    print(head(table(bd_foret$tfv), 10))
  }
  
  # Essences
  if ("essence" %in% names(bd_foret)) {
    cat("\n=== Essences principales ===\n")
    print(head(table(bd_foret$essence), 10))
  }
} else {
  cat("BD Forêt non trouvée. Exécutez le Tutorial 01.\n")
}
```

```{r ex-1-1-check}
grade_this({
  pass("BD Forêt explorée !")
})
```

---

## Section 2 : Zonages de protection (B1)

### Exercice 2.1 : Télécharger les zones protégées (happign)

```{r ex-2-1-setup}
library(sf)
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
```

```{r ex-2-1, exercise=TRUE, exercise.lines=80, exercise.setup="ex-2-1-setup", exercise.timelimit=600}
# === ZONAGES DE PROTECTION (happign + purrr/furrr) ===

parcelles_path <- file.path(data_dir, "parcelles.gpkg")
zones_path <- file.path(data_dir, "zones_protection.gpkg")

if (file.exists(parcelles_path)) {
  parcelles <- st_read(parcelles_path, quiet = TRUE)

  if (file.exists(zones_path)) {
    zones <- st_read(zones_path, quiet = TRUE)
    cat("Zones protégées chargées depuis le cache:", nrow(zones), "entités\n")
  } else {
    if (requireNamespace("happign", quietly = TRUE) && requireNamespace("purrr", quietly = TRUE)) {
      library(happign)
      library(purrr)

      cat("=== Téléchargement zones protégées ===\n\n")

      # Récupérer les couches patrinat
      wfs_layers <- get_layers_metadata("wfs")
      patrinat_layers <- wfs_layers$Name[grepl("patrinat", wfs_layers$Name, ignore.case = TRUE)]
      cat("Couches patrinat trouvées:", length(patrinat_layers), "\n")

      # Fonction de téléchargement d'une couche
      download_layer <- function(layer_name, shape) {
        tryCatch({
          z <- get_wfs(shape, layer_name)
          if (!is.null(z) && nrow(z) > 0) {
            z$type_protection <- layer_name
            geom_col <- names(z)[grepl("geom", names(z), ignore.case = TRUE)]
            cols <- intersect(c("type_protection", "nom_site"), names(z))
            z[, c(cols, geom_col)]
          } else NULL
        }, error = function(e) NULL)
      }

      # Parallélisation avec furrr si disponible
      if (requireNamespace("furrr", quietly = TRUE) && requireNamespace("future", quietly = TRUE)) {
        library(furrr)
        library(future)
        plan(multisession, workers = min(4, length(patrinat_layers)))
        cat("Mode: parallèle (furrr, ", nbrOfWorkers(), " workers)\n\n")

        all_zones <- future_map(patrinat_layers, download_layer, shape = parcelles,
                                .progress = TRUE, .options = furrr_options(seed = TRUE))
        plan(sequential)
      } else {
        cat("Mode: séquentiel (purrr)\n\n")
        all_zones <- map(patrinat_layers, download_layer, shape = parcelles)
      }

      # Filtrer les résultats non-nuls et combiner
      all_zones <- compact(all_zones)

      if (length(all_zones) > 0) {
        zones <- bind_rows(all_zones)
        zones <- st_transform(zones, st_crs(parcelles))
        st_write(zones, zones_path, quiet = TRUE)
        cat("\n", nrow(zones), "zones protégées sauvegardées.\n")
      } else {
        cat("\nAucune zone protégée trouvée.\n")
      }
    } else {
      cat("Packages requis: happign, purrr\n")
      cat("Optionnel pour parallélisation: furrr, future\n")
    }
  }

  # Résumé par type
  if (exists("zones") && nrow(zones) > 0) {
    cat("\n=== Résumé par type ===\n")
    purrr::walk(unique(zones$type_protection), ~ cat(sprintf("- %s: %d\n", .x, sum(zones$type_protection == .x))))
  }
} else {
  cat("Parcelles non trouvées.\n")
}
```

```{r ex-2-1-check}
grade_this({
  pass("Zones protégées téléchargées !")
})
```

### Exercice 2.2 : Calculer B1 (Protection)

```{r ex-2-2-setup, exercise.timelimit=1200}
library(sf)
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
```

```{r ex-2-2, exercise=TRUE, exercise.lines=85, exercise.setup="ex-2-2-setup", exercise.timelimit=1200}
# === INDICATEUR B1 (PROTECTION) - purrr/furrr ===
# B1_pct : % surface protégée (zones fusionnées)
# B1_nb  : nombre de statuts de protection différents
# B1     : score combiné

parcelles_path <- file.path(data_dir, "parcelles.gpkg")
zones_path <- file.path(data_dir, "zones_protection.gpkg")

if (file.exists(parcelles_path) && requireNamespace("purrr", quietly = TRUE)) {
  library(purrr)
  parcelles <- st_read(parcelles_path, quiet = TRUE)

  if (file.exists(zones_path)) {
    zones <- st_read(zones_path, quiet = TRUE)
    zones <- st_transform(zones, st_crs(parcelles))
    cat("Zones protégées:", nrow(zones), "| Types:", length(unique(zones$type_protection)), "\n")

    # Fusionner pour éviter doubles comptages
    zones_union <- st_make_valid(st_union(zones))

    # Fonction de calcul pour une parcelle
    calc_b1 <- function(idx, parcelles_df, zones_df, zones_union_geom) {
      parcelle_i <- st_make_valid(parcelles_df[idx, ])
      surface <- as.numeric(st_area(parcelle_i))

      # % surface protégée
      inter_union <- tryCatch(st_intersection(zones_union_geom, parcelle_i), error = function(e) NULL)
      pct <- if (!is.null(inter_union) && length(inter_union) > 0 && !st_is_empty(inter_union)) {
        min(100, as.numeric(st_area(inter_union)) / surface * 100)
      } else 0

      # Nombre de statuts
      inter_zones <- tryCatch(st_intersection(zones_df, parcelle_i), error = function(e) NULL)
      nb <- if (!is.null(inter_zones) && nrow(inter_zones) > 0) {
        length(unique(inter_zones$type_protection))
      } else 0

      list(pct = pct, nb = nb)
    }

    # Parallélisation avec furrr si disponible
    cat("=== Calcul B1 ===\n")
    idx_list <- seq_len(nrow(parcelles))

    if (requireNamespace("furrr", quietly = TRUE) && requireNamespace("future", quietly = TRUE)) {
      library(furrr)
      library(future)
      plan(multisession, workers = min(4, parallel::detectCores() - 1))
      cat("Mode: parallèle (", nbrOfWorkers(), "workers)\n\n")

      results <- future_map(idx_list, calc_b1,
                            parcelles_df = parcelles, zones_df = zones, zones_union_geom = zones_union,
                            .progress = TRUE, .options = furrr_options(seed = TRUE))
      plan(sequential)
    } else {
      cat("Mode: séquentiel (purrr)\n\n")
      results <- map(idx_list, calc_b1,
                     parcelles_df = parcelles, zones_df = zones, zones_union_geom = zones_union)
    }

    # Extraire résultats
    parcelles$B1_pct <- map_dbl(results, "pct")
    parcelles$B1_nb <- map_int(results, "nb")

    # Score combiné (70% surface + 30% nb statuts normalisé)
    max_statuts <- max(parcelles$B1_nb, na.rm = TRUE)
    parcelles$B1 <- if (max_statuts > 0) {
      0.7 * parcelles$B1_pct + 0.3 * (parcelles$B1_nb / max_statuts * 100)
    } else parcelles$B1_pct

    # Résumé
    cat("\n--- B1_pct (surface) ---\n")
    cat(sprintf("Min: %.1f%% | Max: %.1f%% | Moy: %.1f%%\n",
                min(parcelles$B1_pct), max(parcelles$B1_pct), mean(parcelles$B1_pct)))

    cat("\n--- B1_nb (statuts) ---\n")
    walk(sort(unique(parcelles$B1_nb)), ~ cat(sprintf("  %d statut(s): %d parcelles\n", .x, sum(parcelles$B1_nb == .x))))

    cat("\n--- B1 (combiné) ---\n")
    cat("Moyenne:", round(mean(parcelles$B1), 1), "\n")
  } else {
    cat("Zones non trouvées. Exécutez l'exercice 2.1.\n")
  }
} else {
  cat("Packages requis: sf, purrr\n")
}
```

```{r ex-2-2-check}
grade_this({
  pass("Indicateur B1 (protection) calculé !")
})
```

---

## Section 3 : Structure et Connectivité (B2, B3)

### Exercice 3.1 : Structure verticale (B2)

La **structure verticale** mesure la diversité des strates de végétation.

```{r ex-3-1-setup}
library(sf)
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
```

```{r ex-3-1, exercise=TRUE, exercise.lines=25, exercise.setup="ex-3-1-setup"}
# === INDICATEUR B2 (STRUCTURE VERTICALE) ===

metriques_path <- file.path(data_dir, "metriques_lidar.gpkg")

if (file.exists(metriques_path)) {
  parcelles <- st_read(metriques_path, quiet = TRUE)
  
  # B2 basé sur l'écart-type et l'entropie des hauteurs
  if ("zsd" %in% names(parcelles)) {
    # Plus l'écart-type est élevé, plus la structure est diverse
    parcelles$B2 <- scales::rescale(parcelles$zsd, to = c(0, 100))
  } else {
    parcelles$B2 <- runif(nrow(parcelles), 20, 80)
  }
  
  cat("=== Indicateur B2 (Structure verticale) ===\n")
  cat("B2 min:", round(min(parcelles$B2), 1), "\n")
  cat("B2 max:", round(max(parcelles$B2), 1), "\n")
  cat("B2 moyen:", round(mean(parcelles$B2), 1), "\n")
  
  cat("\nInterprétation:\n")
  cat("- B2 élevé = structure verticale diversifiée (plusieurs strates)\n")
  cat("- B2 faible = structure homogène (monoculture, jeune plantation)\n")
} else {
  cat("Métriques LiDAR non trouvées. Exécutez le Tutorial 02.\n")
}
```

```{r ex-3-1-check}
grade_this({
  pass("Indicateur B2 (structure verticale) calculé !")
})
```

### Exercice 3.2 : Connectivité écologique (B3)

L'indice de connectivité B3 combine 4 approches complémentaires :

| Package | Approche | Métriques |
|---------|----------|-----------|
| **landscapemetrics** | Structurelle | Cohésion, ENN, Agrégation |
| **gdistance** | Fonctionnelle | Distance de résistance (coût) |
| **igraph** | Graphe | Connectivité, centralité |
| **adehabitatHR** | Dispersion | Kernel de connectivité |

```{r ex-3-2-setup}
library(sf)
library(terra)
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
```

```{r ex-3-2, exercise=TRUE, exercise.lines=220, exercise.setup="ex-3-2-setup", exercise.timelimit=900}
# === INDICATEUR B3 (CONNECTIVITÉ ÉCOLOGIQUE) ===
# Combinaison : landscapemetrics + gdistance + igraph + adehabitatHR

parcelles_path <- file.path(data_dir, "parcelles.gpkg")
bd_foret_path <- file.path(data_dir, "bd_foret.gpkg")
mnt_path <- file.path(data_dir, "mnt.tif")

if (!file.exists(parcelles_path) || !file.exists(bd_foret_path)) {
  stop("Données manquantes. Exécutez d'abord les tutoriels 01-03.")
}

parcelles <- st_read(parcelles_path, quiet = TRUE)
bd_foret <- st_read(bd_foret_path, quiet = TRUE)

# Zone d'analyse étendue (2km buffer)
zone_analyse <- st_buffer(st_union(parcelles), 2000)
bd_foret_clip <- st_intersection(st_make_valid(bd_foret), zone_analyse)

# ============================================================
# 1. PRÉPARATION DES RASTERS
# ============================================================
cat("=== 1. Création des rasters ===\n")

# Template raster (résolution 25m pour performance)
if (file.exists(mnt_path)) {
  mnt <- rast(mnt_path)
  template <- aggregate(mnt, fact = 5)
} else {
  ext_zone <- ext(vect(zone_analyse))
  template <- rast(ext_zone, resolution = 25, crs = st_crs(parcelles)$wkt)
}

# Raster forêt binaire
foret_vect <- vect(bd_foret_clip)
raster_foret <- rasterize(foret_vect, template, field = 1, background = 0)
names(raster_foret) <- "foret"

# Raster de résistance (forêt = 1, non-forêt = 10)
raster_resistance <- raster_foret
values(raster_resistance) <- ifelse(values(raster_foret) == 1, 1, 10)
names(raster_resistance) <- "resistance"

cat("Dimensions:", ncol(raster_foret), "x", nrow(raster_foret), "pixels\n")
cat("Couverture forestière:", round(global(raster_foret, "mean", na.rm = TRUE)[1,1] * 100, 1), "%\n\n")

# ============================================================
# 2. MÉTRIQUES STRUCTURELLES (landscapemetrics)
# ============================================================
cat("=== 2. Métriques structurelles (landscapemetrics) ===\n")

if (requireNamespace("landscapemetrics", quietly = TRUE)) {
  library(landscapemetrics)

  # Cohésion physique (0-100)
  cohesion <- lsm_c_cohesion(raster_foret) |> subset(class == 1)
  cohesion_val <- if (nrow(cohesion) > 0) cohesion$value[1] else 50

  # Distance au plus proche voisin (m)
  enn <- lsm_c_enn_mn(raster_foret) |> subset(class == 1)
  enn_val <- if (nrow(enn) > 0) enn$value[1] else 500

  # Indice d'agrégation (0-100)
  ai <- lsm_c_ai(raster_foret) |> subset(class == 1)
  ai_val <- if (nrow(ai) > 0) ai$value[1] else 50

  # Nombre de taches
  np <- lsm_c_np(raster_foret) |> subset(class == 1)
  np_val <- if (nrow(np) > 0) np$value[1] else 10

  # Surface moyenne des taches (ha)
  area_mn <- lsm_c_area_mn(raster_foret) |> subset(class == 1)
  area_val <- if (nrow(area_mn) > 0) area_mn$value[1] else 10

  cat("Cohésion:", round(cohesion_val, 1), "/ 100\n")
  cat("ENN moyen:", round(enn_val, 1), "m\n")
  cat("Agrégation:", round(ai_val, 1), "/ 100\n")
  cat("Nb taches:", np_val, "\n")
  cat("Surface moyenne:", round(area_val, 2), "ha\n\n")

  lsm_available <- TRUE
} else {
  cat("landscapemetrics non disponible - valeurs par défaut\n\n")
  cohesion_val <- 50; enn_val <- 500; ai_val <- 50; np_val <- 10; area_val <- 10
  lsm_available <- FALSE
}

# ============================================================
# 3. DISTANCE DE RÉSISTANCE (gdistance)
# ============================================================
cat("=== 3. Distance de résistance (gdistance) ===\n")

if (requireNamespace("gdistance", quietly = TRUE)) {
  library(gdistance)

  # Convertir en RasterLayer pour gdistance
  resistance_raster <- raster::raster(raster_resistance)

  # Matrice de transition (conductance = 1/résistance)
  tr <- transition(resistance_raster, transitionFunction = function(x) 1/mean(x), directions = 8)
  tr <- geoCorrection(tr, type = "c")  # Correction géographique

  # Centroïdes des taches forestières
  if (lsm_available) {
    patches <- get_patches(raster_foret, class = 1)[[1]]
    patch_centroids <- lsm_p_core(raster_foret) |> subset(class == 1)

    # Extraire les centroïdes des N plus grandes taches (max 20)
    if (nrow(patch_centroids) > 0) {
      patch_areas <- lsm_p_area(raster_foret) |> subset(class == 1)
      patch_areas <- patch_areas[order(-patch_areas$value), ]
      top_patches <- head(patch_areas$id, min(20, nrow(patch_areas)))

      # Calculer centroïdes via landscapemetrics
      patch_coords <- get_centroids(patches)
      patch_coords <- patch_coords[patch_coords$id %in% top_patches, ]

      if (nrow(patch_coords) >= 2) {
        pts <- as.matrix(patch_coords[, c("x", "y")])

        # Matrice des distances de coût
        cost_dist <- costDistance(tr, pts)
        mean_cost_dist <- mean(cost_dist[lower.tri(cost_dist)])

        cat("Nb taches analysées:", nrow(pts), "\n")
        cat("Distance coût moyenne:", round(mean_cost_dist, 1), "unités\n\n")
      } else {
        mean_cost_dist <- 0
        cat("Pas assez de taches pour l'analyse\n\n")
      }
    } else {
      mean_cost_dist <- 500
    }
  } else {
    mean_cost_dist <- 500
  }

  gdist_available <- TRUE
} else {
  cat("gdistance non disponible - valeurs par défaut\n\n")
  mean_cost_dist <- 500
  gdist_available <- FALSE
}

# ============================================================
# 4. ANALYSE DE GRAPHE (igraph)
# ============================================================
cat("=== 4. Connectivité de graphe (igraph) ===\n")

if (requireNamespace("igraph", quietly = TRUE) && lsm_available) {
  library(igraph)

  # Créer un graphe où les noeuds sont les taches forestières
  # Arêtes pondérées par la distance euclidienne

  if (exists("patch_coords") && nrow(patch_coords) >= 2) {
    n_patches <- nrow(patch_coords)

    # Matrice de distance euclidienne
    coords_mat <- as.matrix(patch_coords[, c("x", "y")])
    dist_mat <- as.matrix(dist(coords_mat))

    # Seuil de connexion (ex: 500m = distance de dispersion typique)
    seuil_connexion <- 500  # mètres

    # Créer la matrice d'adjacence (connecté si distance < seuil)
    adj_mat <- dist_mat < seuil_connexion
    diag(adj_mat) <- FALSE

    # Créer le graphe
    g <- graph_from_adjacency_matrix(adj_mat, mode = "undirected")

    # Métriques de graphe
    n_components <- components(g)$no
    largest_component <- max(components(g)$csize)
    graph_density <- edge_density(g)

    # Indice de connectivité du graphe (% noeuds dans la plus grande composante)
    graph_connectivity <- (largest_component / n_patches) * 100

    # Centralité moyenne (betweenness normalisée)
    if (n_patches > 2) {
      betweenness_vals <- betweenness(g, normalized = TRUE)
      mean_betweenness <- mean(betweenness_vals, na.rm = TRUE)
    } else {
      mean_betweenness <- 0
    }

    cat("Nb composantes:", n_components, "\n")
    cat("Plus grande composante:", largest_component, "taches\n")
    cat("Densité du graphe:", round(graph_density, 3), "\n")
    cat("Connectivité graphe:", round(graph_connectivity, 1), "%\n")
    cat("Centralité moyenne:", round(mean_betweenness, 3), "\n\n")

  } else {
    graph_connectivity <- 50
    graph_density <- 0.5
    mean_betweenness <- 0.5
    cat("Pas assez de taches pour l'analyse de graphe\n\n")
  }

  igraph_available <- TRUE
} else {
  cat("igraph non disponible - valeurs par défaut\n\n")
  graph_connectivity <- 50
  graph_density <- 0.5
  mean_betweenness <- 0.5
  igraph_available <- FALSE
}

# ============================================================
# 5. KERNEL DE DISPERSION (adehabitatHR)
# ============================================================
cat("=== 5. Kernel de dispersion (adehabitatHR) ===\n")

if (requireNamespace("adehabitatHR", quietly = TRUE) && requireNamespace("sp", quietly = TRUE)) {
  library(adehabitatHR)
  library(sp)

  # Points sources = centroïdes des parcelles forestières
  parcelles_forest <- parcelles[lengths(st_intersects(parcelles, bd_foret_clip)) > 0, ]

  if (nrow(parcelles_forest) >= 5) {
    centroids_sf <- st_centroid(parcelles_forest)
    centroids_sp <- as(centroids_sf, "Spatial")

    # Kernel de densité (simule la probabilité de présence/dispersion)
    # h = paramètre de lissage (distance de dispersion typique)
    h_dispersion <- 300  # 300m = dispersion typique petits mammifères

    tryCatch({
      # Calcul du kernel
      kde <- kernelUD(centroids_sp, h = h_dispersion, grid = 50)

      # Extraire le volume du home range à 95%
      hr95 <- kernel.area(kde, percent = 95)

      # Surface du kernel (proxy de connectivité fonctionnelle)
      kernel_area <- hr95[[1]]

      # Ratio surface kernel / surface parcelles (indice d'étalement)
      total_parcel_area <- sum(st_area(parcelles_forest)) / 10000  # ha
      kernel_ratio <- kernel_area / as.numeric(total_parcel_area)

      cat("Surface kernel 95%:", round(kernel_area, 1), "ha\n")
      cat("Ratio kernel/parcelles:", round(kernel_ratio, 2), "\n")
      cat("(ratio > 1 = bonne connectivité fonctionnelle)\n\n")

      kernel_connectivity <- min(100, kernel_ratio * 50)  # Normaliser 0-100

    }, error = function(e) {
      cat("Erreur kernel:", e$message, "\n")
      kernel_connectivity <<- 50
    })
  } else {
    cat("Pas assez de parcelles forestières\n\n")
    kernel_connectivity <- 50
  }

  adehabitat_available <- TRUE
} else {
  cat("adehabitatHR non disponible - valeurs par défaut\n\n")
  kernel_connectivity <- 50
  adehabitat_available <- FALSE
}

# ============================================================
# 6. INDICE B3 DE SYNTHÈSE
# ============================================================
cat("=== 6. Calcul de l'indice B3 de synthèse ===\n")

# Normalisation des composantes (0-100)
cohesion_norm <- cohesion_val
enn_norm <- max(0, 100 - (enn_val / 10))  # 0m=100, 1000m=0
ai_norm <- ai_val
np_norm <- max(0, 100 - (np_val - 1) * 2)  # 1 tache=100, 50+=0
cost_norm <- max(0, 100 - (mean_cost_dist / 10))  # Distance coût normalisée
graph_norm <- graph_connectivity
kernel_norm <- kernel_connectivity

cat("\nComposantes normalisées:\n")
cat("- Cohésion (landscapemetrics):", round(cohesion_norm, 1), "\n")
cat("- Proximité ENN:", round(enn_norm, 1), "\n")
cat("- Agrégation:", round(ai_norm, 1), "\n")
cat("- Continuité (NP):", round(np_norm, 1), "\n")
cat("- Distance coût (gdistance):", round(cost_norm, 1), "\n")
cat("- Graphe (igraph):", round(graph_norm, 1), "\n")
cat("- Kernel (adehabitatHR):", round(kernel_norm, 1), "\n")

# Pondération selon disponibilité des packages
weights <- c(
  landscapemetrics = 0.25,  # Cohésion + ENN + AI
  gdistance = 0.25,
  igraph = 0.25,
  adehabitatHR = 0.25
)

# Score landscapemetrics (moyenne pondérée interne)
score_lsm <- 0.4 * cohesion_norm + 0.3 * enn_norm + 0.2 * ai_norm + 0.1 * np_norm

# Calcul B3 global
B3_global <- weights["landscapemetrics"] * score_lsm +
             weights["gdistance"] * cost_norm +
             weights["igraph"] * graph_norm +
             weights["adehabitatHR"] * kernel_norm

cat("\n=== Scores par approche ===\n")
cat("- Structurel (landscapemetrics):", round(score_lsm, 1), "\n")
cat("- Fonctionnel (gdistance):", round(cost_norm, 1), "\n")
cat("- Graphe (igraph):", round(graph_norm, 1), "\n")
cat("- Dispersion (adehabitatHR):", round(kernel_norm, 1), "\n")
cat("\nB3 GLOBAL:", round(B3_global, 1), "/ 100\n")

# B3 par parcelle (variation locale basée sur distance aux autres taches)
parcelles_centroids <- st_centroid(parcelles)
dist_to_forest <- st_distance(parcelles_centroids, bd_foret_clip)
min_dist <- apply(dist_to_forest, 1, function(x) min(x[x > 0], na.rm = TRUE))
min_dist[is.infinite(min_dist)] <- 0
local_connectivity <- pmax(0, 100 - (min_dist / 20))

# B3 final = 70% global + 30% local
parcelles$B3 <- 0.7 * B3_global + 0.3 * local_connectivity

cat("\n=== Résultat par parcelle ===\n")
cat("B3 moyen:", round(mean(parcelles$B3), 1), "\n")
cat("B3 min:", round(min(parcelles$B3), 1), "\n")
cat("B3 max:", round(max(parcelles$B3), 1), "\n")

# Sauvegarde
st_write(parcelles, parcelles_path, delete_dsn = TRUE, quiet = TRUE)
cat("\nParcelles sauvegardées avec B3.\n")
```

```{r ex-3-2-check}
grade_this({
  pass("Indicateur B3 (connectivité multi-approches) calculé !")
})
```

---

## Section 4 : Paysage, TVB et Vitalité (L1, L3, C2)

### Exercice 4.1 : Effet lisière et Sylvosphère (L1)

La **sylvosphère** est la zone de transition entre la forêt et son environnement.
L'indice L1 caractérise cette interface via 3 composantes :

| Composante | Description | Source | Impact |
|------------|-------------|--------|--------|
| **Intensité géométrique** | Longueur de lisière / surface | Géométrie parcelle | Quantité d'interface |
| **Contraste de matrice** | Type d'occupation adjacente | IGN OCS GE / OpenLand / geodata | Qualité de la transition |
| **Exposition directionnelle** | Orientation des lisières | Géométrie + azimut | Stress climatique |

**Sources de données d'occupation du sol (par ordre de priorité) :**

| Priorité | Source | Package | Résolution | Couverture |
|----------|--------|---------|------------|------------|
| 1 | **IGN OCS GE** | happign | 10m vecteur | France métropolitaine |
| 2 | **OpenLand** | OpenLand | Variable | Global (analyse temporelle) |
| 3 | **ESA WorldCover** | geodata | 10m raster | Global |
| 4 | **OpenStreetMap** | osmdata | Vecteur | Global |

**Nomenclature OCS GE (IGN) - Scores de contraste :**

| Code | Usage | Couverture | Contraste |
|------|-------|------------|-----------|
| US1 | Agriculture | Culture annuelle | 50 |
| US2 | Sylviculture | Forêt | 0 |
| US235 | Activité secondaire | Industriel | 90 |
| US3 | Tertiaire | Commercial | 85 |
| US4 | Transport | Route/Rail | 75 |
| US5 | Résidentiel | Habitat | 80 |
| US6 | Loisirs | Espaces verts | 35 |

```{r ex-4-1-setup}
library(sf)
library(terra)
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
```

```{r ex-4-1, exercise=TRUE, exercise.lines=320, exercise.setup="ex-4-1-setup", exercise.timelimit=900}
# === INDICATEUR L1 (SYLVOSPHÈRE) ===
# Intensité géométrique + Contraste matrice + Exposition directionnelle

parcelles_path <- file.path(data_dir, "parcelles.gpkg")
bd_foret_path <- file.path(data_dir, "bd_foret.gpkg")

if (!file.exists(parcelles_path)) {
 stop("Données manquantes. Exécutez d'abord les tutoriels précédents.")
}

parcelles <- st_read(parcelles_path, quiet = TRUE)
bd_foret <- if (file.exists(bd_foret_path)) st_read(bd_foret_path, quiet = TRUE) else NULL

# Zone d'analyse avec buffer 500m
zone_analyse <- st_buffer(st_union(parcelles), 500)

# ============================================================
# 1. TÉLÉCHARGEMENT OCCUPATION DU SOL (OCS GE / OpenLand / geodata)
# ============================================================
cat("=== 1. Acquisition de l'occupation du sol ===\n")

ocs_available <- FALSE
ocs_data <- NULL
ocs_source <- "none"

# -------------------------------------------------------------
# Table de correspondance OCS GE (IGN) -> scores de contraste
# https://geoservices.ign.fr/services-web-experts-ocsge
# -------------------------------------------------------------
ocsge_contrast <- data.frame(
  # Codes usage (US) - niveau 1
  code_usage = c("US1", "US2", "US235", "US3", "US4", "US5", "US6", "US7"),
  label_usage = c("Agriculture", "Sylviculture", "Secondaire/Tertiaire",
                  "Tertiaire", "Transport", "Résidentiel", "Loisirs", "Sans usage"),
  contraste_usage = c(50, 0, 90, 85, 75, 80, 35, 40),
  stringsAsFactors = FALSE
)

# Codes couverture (CS) pour affiner
ocsge_couverture <- data.frame(
  code_couv = c("CS1.1.1", "CS1.1.2", "CS1.2.1", "CS1.2.2", "CS1.2.3",
                "CS2.1.1", "CS2.1.2", "CS2.1.3", "CS2.2.1", "CS2.2.2"),
  label_couv = c("Bâti", "Serre/Hangar", "Route", "Voie ferrée", "Autre revêtu",
                 "Forêt feuillus", "Forêt conifères", "Forêt mixte", "Lande", "Pelouse"),
  contraste_couv = c(95, 70, 80, 75, 60, 0, 0, 0, 15, 20),
  stringsAsFactors = FALSE
)

# -------------------------------------------------------------
# PRIORITÉ 1 : IGN OCS GE via happign ou requête WFS directe
# -------------------------------------------------------------
cat("Tentative de téléchargement OCS GE (IGN)...\n")

# URL du WFS OCS GE sur la Géoplateforme
# https://geoservices.ign.fr/services-web-experts-ocsge
ocsge_wfs_url <- "https://data.geopf.fr/wfs/ows"

# Couches OCS GE disponibles (départements couverts progressivement)
# Format: OCSGE.COUVERTURE:couverture_XXXX (XXXX = millésime)
# ou OCSGE:occupation_du_sol

if (requireNamespace("happign", quietly = TRUE)) {
  library(happign)

  tryCatch({
    # Méthode 1: Chercher les couches OCS GE dans le catalogue WFS
    wfs_layers <- get_layers_metadata("wfs")

    # Filtrer les couches OCS GE (couverture ou occupation)
    ocsge_layers <- wfs_layers$Name[grepl("ocsge", wfs_layers$Name, ignore.case = TRUE)]

    cat("Couches OCS GE trouvées:", length(ocsge_layers), "\n")
    if (length(ocsge_layers) > 0) {
      cat("Exemples:", paste(head(ocsge_layers, 3), collapse = ", "), "\n")
    }

    # Chercher en priorité : couverture > occupation > zone_construite
    layer_patterns <- c("couverture", "occupation", "zone_construite", "usage")
    selected_layer <- NULL

    for (pattern in layer_patterns) {
      matches <- ocsge_layers[grepl(pattern, ocsge_layers, ignore.case = TRUE)]
      # Exclure les couches de différence/évolution
      matches <- matches[!grepl("diff|evol|changement", matches, ignore.case = TRUE)]
      if (length(matches) > 0) {
        selected_layer <- matches[1]
        break
      }
    }

    if (!is.null(selected_layer)) {
      cat("Couche sélectionnée:", selected_layer, "\n")

      # Convertir zone_analyse en bbox pour la requête
      zone_bbox <- st_as_sfc(st_bbox(zone_analyse))
      st_crs(zone_bbox) <- st_crs(zone_analyse)

      # Télécharger via happign
      ocs_data <- get_wfs(
        x = zone_bbox,
        layer = selected_layer,
        spatial_filter = "bbox"
      )

      if (!is.null(ocs_data) && nrow(ocs_data) > 0) {
        # Découper sur la zone d'analyse
        ocs_data <- st_make_valid(ocs_data)
        ocs_data <- suppressWarnings(st_intersection(ocs_data, zone_analyse))

        if (nrow(ocs_data) > 0) {
          cat("OCS GE récupéré:", nrow(ocs_data), "polygones\n")
          cat("Colonnes:", paste(head(names(ocs_data), 8), collapse = ", "), "\n")
          ocs_available <- TRUE
          ocs_source <- "ocsge"
        }
      }
    }

  }, error = function(e) {
    cat("Erreur happign OCS GE:", e$message, "\n")
  })
}

# Méthode 2: Requête WFS directe si happign échoue
if (!ocs_available) {
  cat("Tentative requête WFS directe...\n")

  tryCatch({
    # Construire la requête WFS manuellement
    bbox <- st_bbox(st_transform(zone_analyse, 4326))
    bbox_str <- paste(bbox["ymin"], bbox["xmin"], bbox["ymax"], bbox["xmax"], sep = ",")

    # Essayer différentes couches OCS GE
    ocsge_layers_try <- c(
      "OCSGE.COUVERTURE:couverture",
      "OCSGE:occupation_du_sol",
      "LANDCOVER.FORESTINVENTORY.V2:formation_vegetale"
    )

    for (layer_name in ocsge_layers_try) {
      wfs_request <- paste0(
        ocsge_wfs_url,
        "?SERVICE=WFS",
        "&VERSION=2.0.0",
        "&REQUEST=GetFeature",
        "&TYPENAMES=", layer_name,
        "&BBOX=", bbox_str, ",EPSG:4326",
        "&OUTPUTFORMAT=application/json",
        "&COUNT=1000"
      )

      cat("Essai couche:", layer_name, "\n")

      response <- tryCatch({
        st_read(wfs_request, quiet = TRUE)
      }, error = function(e) NULL)

      if (!is.null(response) && nrow(response) > 0) {
        # Reprojeter et découper
        ocs_data <- st_transform(response, st_crs(parcelles))
        ocs_data <- st_make_valid(ocs_data)
        ocs_data <- suppressWarnings(st_intersection(ocs_data, zone_analyse))

        if (nrow(ocs_data) > 0) {
          cat("Données récupérées:", nrow(ocs_data), "polygones\n")
          cat("Colonnes:", paste(head(names(ocs_data), 8), collapse = ", "), "\n")
          ocs_available <- TRUE
          ocs_source <- "ocsge"
          break
        }
      }
    }

    if (!ocs_available) {
      cat("Aucune couche OCS GE disponible pour cette zone\n")
      cat("(L'OCS GE ne couvre pas encore tout le territoire)\n")
    }

  }, error = function(e) {
    cat("Erreur WFS directe:", e$message, "\n")
  })
}

# -------------------------------------------------------------
# PRIORITÉ 2 : OpenLand (analyse d'occupation du sol)
# -------------------------------------------------------------
if (!ocs_available && requireNamespace("OpenLand", quietly = TRUE)) {
  library(OpenLand)

  cat("\nTentative avec OpenLand...\n")

  # OpenLand est principalement pour l'analyse de changements d'occupation

  # Il nécessite des rasters d'entrée déjà existants
  # On l'utilisera pour l'analyse si on a des données
  cat("OpenLand disponible pour analyse de transitions\n")
  cat("(Nécessite des rasters d'occupation existants)\n")
}

# -------------------------------------------------------------
# PRIORITÉ 3 : geodata (ESA WorldCover)
# -------------------------------------------------------------
if (!ocs_available && requireNamespace("geodata", quietly = TRUE)) {
  library(geodata)

  cat("\nTéléchargement ESA WorldCover (geodata)...\n")

  tryCatch({
    zone_wgs84 <- st_transform(zone_analyse, 4326)
    cache_dir <- file.path(data_dir, "geodata_cache")
    if (!dir.exists(cache_dir)) dir.create(cache_dir, recursive = TRUE)

    # Télécharger ESA WorldCover
    lc <- geodata::landcover(var = "trees", path = cache_dir)

    # Cropper sur la zone
    zone_vect <- vect(zone_wgs84)
    ocs_raster <- crop(lc, zone_vect)
    ocs_raster <- mask(ocs_raster, zone_vect)
    ocs_raster <- project(ocs_raster, crs(vect(parcelles)), method = "near")

    if (!is.null(ocs_raster)) {
      ocs_available <- TRUE
      ocs_source <- "geodata"
      ocs_data <- ocs_raster
      cat("ESA WorldCover récupéré:", ncol(ocs_raster), "x", nrow(ocs_raster), "pixels\n")
    }

  }, error = function(e) {
    cat("Erreur geodata:", e$message, "\n")
  })
}

# -------------------------------------------------------------
# PRIORITÉ 4 : osmdata (OpenStreetMap)
# -------------------------------------------------------------
osm_available <- FALSE

if (!ocs_available && requireNamespace("osmdata", quietly = TRUE)) {
  library(osmdata)

  cat("\nTéléchargement OSM landuse...\n")

  bbox_wgs84 <- st_bbox(st_transform(zone_analyse, 4326))

  tryCatch({
    # Zones urbaines
    urban <- opq(bbox_wgs84) |>
      add_osm_feature(key = "landuse", value = c("residential", "commercial",
                                                   "industrial", "retail")) |>
      osmdata_sf()
    urban_poly <- urban$osm_polygons

    # Prairies
    meadow <- opq(bbox_wgs84) |>
      add_osm_feature(key = "landuse", value = c("meadow", "grass", "farmyard",
                                                   "orchard", "vineyard")) |>
      osmdata_sf()
    meadow_poly <- meadow$osm_polygons

    # Cultures
    farmland <- opq(bbox_wgs84) |>
      add_osm_feature(key = "landuse", value = c("farmland")) |>
      osmdata_sf()
    farmland_poly <- farmland$osm_polygons

    # Routes
    roads <- opq(bbox_wgs84) |>
      add_osm_feature(key = "highway", value = c("motorway", "trunk",
                                                   "primary", "secondary")) |>
      osmdata_sf()
    roads_lines <- roads$osm_lines

    osm_available <- TRUE
    ocs_source <- "osm"
    cat("Données OSM récupérées\n")

  }, error = function(e) {
    cat("Erreur osmdata:", e$message, "\n")
  })
}

cat("\n→ Source sélectionnée:", ocs_source, "\n\n")

# Table ESA WorldCover pour geodata
esa_contrast <- data.frame(
  code = c(10, 20, 30, 40, 50, 60, 70, 80, 90, 95, 100),
  contraste = c(0, 15, 20, 50, 90, 40, 50, 30, 25, 15, 25),
  label = c("Forêt", "Arbustes", "Prairie", "Culture", "Bâti",
            "Sol nu", "Neige", "Eau", "Zone humide", "Mangrove", "Mousse")
)

# Scores OSM
contrast_scores <- c(
  forest = 0, meadow = 15, orchard = 20, scrub = 25, water = 30,
  farmland = 50, vineyard = 45, road = 75, residential = 80,
  commercial = 90, industrial = 95, unknown = 50
)

# ============================================================
# 2. INTENSITÉ GÉOMÉTRIQUE DE LISIÈRE
# ============================================================
cat("\n=== 2. Intensité géométrique de lisière ===\n")

# Périmètre et surface de chaque parcelle
parcelles$perimetre_m <- as.numeric(st_length(st_boundary(parcelles)))
parcelles$surface_m2 <- as.numeric(st_area(parcelles))
parcelles$surface_ha <- parcelles$surface_m2 / 10000

# Indice de forme (Shape Index) : périmètre / périmètre d'un cercle de même surface
# SI = P / (2 * sqrt(π * A))
parcelles$shape_index <- parcelles$perimetre_m / (2 * sqrt(pi * parcelles$surface_m2))

# Densité de lisière (m/ha)
parcelles$densite_lisiere <- parcelles$perimetre_m / parcelles$surface_ha

# Normaliser l'intensité géométrique (0-100)
# Shape index de 1 (cercle parfait) à ~5 (très allongé)
parcelles$L1_geometrie <- pmin(100, (parcelles$shape_index - 1) * 25)

cat("Shape Index moyen:", round(mean(parcelles$shape_index), 2), "\n")
cat("Densité lisière moyenne:", round(mean(parcelles$densite_lisiere), 1), "m/ha\n")
cat("L1_geometrie moyen:", round(mean(parcelles$L1_geometrie), 1), "\n\n")

# ============================================================
# 3. CONTRASTE DE MATRICE (Type d'occupation adjacente)
# ============================================================
cat("=== 3. Contraste de matrice ===\n")

# === MÉTHODE 1 : OCS GE (IGN) - Données vectorielles ===
if (ocs_source == "ocsge" && !is.null(ocs_data)) {
  cat("Calcul du contraste via OCS GE (IGN)...\n")

  # Fonction pour calculer le contraste via polygones OCS GE
  calc_ocsge_contrast <- function(parcelle_geom, ocs_polygons, contrast_table, couv_table) {
    buffer_zone <- st_buffer(parcelle_geom, 50)
    edge_zone <- st_difference(buffer_zone, parcelle_geom)

    if (st_is_empty(edge_zone)) return(50)

    # Intersection avec OCS GE
    inter <- tryCatch({
      suppressWarnings(st_intersection(ocs_polygons, edge_zone))
    }, error = function(e) NULL)

    if (is.null(inter) || nrow(inter) == 0) return(50)

    # Calculer le contraste pondéré par surface
    inter$area <- as.numeric(st_area(inter))
    total_area <- sum(inter$area)

    if (total_area == 0) return(50)

    # Chercher les colonnes usage et couverture
    usage_col <- names(inter)[grepl("usage|us_", names(inter), ignore.case = TRUE)][1]
    couv_col <- names(inter)[grepl("couverture|cs_", names(inter), ignore.case = TRUE)][1]

    weighted_contrast <- 0

    for (i in 1:nrow(inter)) {
      weight <- inter$area[i] / total_area

      # Priorité à la couverture (plus précise)
      if (!is.na(couv_col) && couv_col %in% names(inter)) {
        code <- as.character(inter[[couv_col]][i])
        idx <- which(couv_table$code_couv == code)
        if (length(idx) > 0) {
          weighted_contrast <- weighted_contrast + weight * couv_table$contraste_couv[idx]
          next
        }
      }

      # Sinon utiliser l'usage
      if (!is.na(usage_col) && usage_col %in% names(inter)) {
        code <- as.character(inter[[usage_col]][i])
        # Extraire le code de niveau 1 (ex: "US1.2" -> "US1")
        code_n1 <- sub("\\..*", "", code)
        idx <- which(contrast_table$code_usage == code_n1)
        if (length(idx) > 0) {
          weighted_contrast <- weighted_contrast + weight * contrast_table$contraste_usage[idx]
          next
        }
      }

      # Par défaut
      weighted_contrast <- weighted_contrast + weight * 50
    }

    return(weighted_contrast)
  }

  # Appliquer à chaque parcelle
  if (requireNamespace("purrr", quietly = TRUE)) {
    library(purrr)
    parcelles$L1_contraste <- map_dbl(1:nrow(parcelles), function(i) {
      calc_ocsge_contrast(st_geometry(parcelles)[i], ocs_data, ocsge_contrast, ocsge_couverture)
    })
  } else {
    parcelles$L1_contraste <- sapply(1:nrow(parcelles), function(i) {
      calc_ocsge_contrast(st_geometry(parcelles)[i], ocs_data, ocsge_contrast, ocsge_couverture)
    })
  }

  cat("L1_contraste moyen (OCS GE):", round(mean(parcelles$L1_contraste, na.rm = TRUE), 1), "\n")

  # Afficher la distribution des usages
  if ("usage" %in% names(ocs_data) || any(grepl("us_", names(ocs_data)))) {
    usage_col <- names(ocs_data)[grepl("usage|us_", names(ocs_data), ignore.case = TRUE)][1]
    if (!is.na(usage_col)) {
      cat("\nDistribution des usages OCS GE:\n")
      usage_table <- sort(table(ocs_data[[usage_col]]), decreasing = TRUE)
      for (code in names(head(usage_table, 5))) {
        pct <- round(usage_table[code] / sum(usage_table) * 100, 1)
        cat(sprintf("  - %s: %s%%\n", code, pct))
      }
    }
  }

# === MÉTHODE 2 : geodata (ESA WorldCover) - Raster ===
} else if (ocs_source == "geodata" && !is.null(ocs_data)) {
  cat("Calcul du contraste via ESA WorldCover (geodata)...\n")

  calc_raster_contrast <- function(parcelle_geom, lc_raster, contrast_table) {
    buffer_zone <- st_buffer(parcelle_geom, 50)
    edge_zone <- st_difference(buffer_zone, parcelle_geom)

    if (st_is_empty(edge_zone)) return(50)

    edge_vect <- vect(edge_zone)

    tryCatch({
      vals <- extract(lc_raster, edge_vect, fun = NULL)[[2]]
      if (length(vals) == 0 || all(is.na(vals))) return(50)

      val_counts <- table(vals)
      total_pixels <- sum(val_counts)

      weighted_contrast <- 0
      for (code in names(val_counts)) {
        code_num <- as.numeric(code)
        idx <- which(contrast_table$code == code_num)
        weight <- val_counts[code] / total_pixels
        if (length(idx) > 0) {
          weighted_contrast <- weighted_contrast + weight * contrast_table$contraste[idx]
        } else {
          weighted_contrast <- weighted_contrast + weight * 50
        }
      }

      return(as.numeric(weighted_contrast))
    }, error = function(e) return(50))
  }

  if (requireNamespace("purrr", quietly = TRUE)) {
    library(purrr)
    parcelles$L1_contraste <- map_dbl(1:nrow(parcelles), function(i) {
      calc_raster_contrast(st_geometry(parcelles)[i], ocs_data, esa_contrast)
    })
  } else {
    parcelles$L1_contraste <- sapply(1:nrow(parcelles), function(i) {
      calc_raster_contrast(st_geometry(parcelles)[i], ocs_data, esa_contrast)
    })
  }

  cat("L1_contraste moyen (ESA):", round(mean(parcelles$L1_contraste, na.rm = TRUE), 1), "\n")

# === MÉTHODE 3 : OSM ===
} else if (ocs_source == "osm" && osm_available) {
  cat("Calcul du contraste de matrice (OSM)...\n")

  calc_osm_contrast <- function(parcelle_geom, urban_p, meadow_p, farmland_p,
                                 roads_l, crs_target) {
    buffer_zone <- st_buffer(parcelle_geom, 50)
    edge_zone <- st_difference(buffer_zone, parcelle_geom)

    if (st_is_empty(edge_zone)) return(50)

    edge_area <- as.numeric(st_area(edge_zone))
    if (edge_area == 0) return(50)

    total_weighted <- 0
    total_area <- 0

    # Urban
    if (!is.null(urban_p) && nrow(urban_p) > 0) {
      urban_t <- st_transform(urban_p, crs_target)
      inter <- suppressWarnings(st_intersection(edge_zone, st_union(urban_t)))
      if (length(inter) > 0 && !st_is_empty(inter)) {
        area <- as.numeric(st_area(inter))
        total_weighted <- total_weighted + area * contrast_scores["residential"]
        total_area <- total_area + area
      }
    }

    # Meadow
    if (!is.null(meadow_p) && nrow(meadow_p) > 0) {
      meadow_t <- st_transform(meadow_p, crs_target)
      inter <- suppressWarnings(st_intersection(edge_zone, st_union(meadow_t)))
      if (length(inter) > 0 && !st_is_empty(inter)) {
        area <- as.numeric(st_area(inter))
        total_weighted <- total_weighted + area * contrast_scores["meadow"]
        total_area <- total_area + area
      }
    }

    # Farmland
    if (!is.null(farmland_p) && nrow(farmland_p) > 0) {
      farmland_t <- st_transform(farmland_p, crs_target)
      inter <- suppressWarnings(st_intersection(edge_zone, st_union(farmland_t)))
      if (length(inter) > 0 && !st_is_empty(inter)) {
        area <- as.numeric(st_area(inter))
        total_weighted <- total_weighted + area * contrast_scores["farmland"]
        total_area <- total_area + area
      }
    }

    # Roads
    if (!is.null(roads_l) && nrow(roads_l) > 0) {
      roads_t <- st_transform(roads_l, crs_target)
      roads_buffer <- st_buffer(roads_t, 10)
      inter <- suppressWarnings(st_intersection(edge_zone, st_union(roads_buffer)))
      if (length(inter) > 0 && !st_is_empty(inter)) {
        area <- as.numeric(st_area(inter))
        total_weighted <- total_weighted + area * contrast_scores["road"]
        total_area <- total_area + area
      }
    }

    if (total_area == 0) return(contrast_scores["unknown"])
    return(total_weighted / total_area)
  }

  crs_target <- st_crs(parcelles)

  if (requireNamespace("purrr", quietly = TRUE)) {
    library(purrr)
    parcelles$L1_contraste <- map_dbl(1:nrow(parcelles), function(i) {
      calc_osm_contrast(st_geometry(parcelles)[i],
                        urban_poly, meadow_poly, farmland_poly, roads_lines,
                        crs_target)
    })
  } else {
    parcelles$L1_contraste <- sapply(1:nrow(parcelles), function(i) {
      calc_osm_contrast(st_geometry(parcelles)[i],
                        urban_poly, meadow_poly, farmland_poly, roads_lines,
                        crs_target)
    })
  }

  cat("L1_contraste moyen (OSM):", round(mean(parcelles$L1_contraste, na.rm = TRUE), 1), "\n")

# === MÉTHODE 4 : Fallback basé sur distance aux routes ===
} else {
  cat("Aucune donnée d'occupation disponible - estimation via distance routes\n")

  routes_path <- file.path(data_dir, "routes.gpkg")
  if (file.exists(routes_path)) {
    routes <- st_read(routes_path, quiet = TRUE)
    centroids <- st_centroid(parcelles)
    dist_routes <- as.numeric(st_distance(centroids, st_union(routes)))
    parcelles$L1_contraste <- pmax(0, 80 - (dist_routes / 25))
  } else {
    parcelles$L1_contraste <- 50
  }

  cat("L1_contraste moyen (estimé):", round(mean(parcelles$L1_contraste), 1), "\n")
}

cat("\n")

# ============================================================
# 4. EXPOSITION DIRECTIONNELLE (Vent, Rayonnement)
# ============================================================
cat("=== 4. Exposition directionnelle ===\n")

# L'exposition des lisières influence le microclimat forestier
# - Lisières exposées au vent dominant (SO en France) = stress
# - Lisières exposées au sud = rayonnement intense = stress hydrique

# Calculer l'orientation des segments de lisière
calc_edge_exposure <- function(parcelle_geom) {
  # Extraire les coordonnées du périmètre
  coords <- st_coordinates(st_boundary(parcelle_geom))

  if (nrow(coords) < 3) return(c(vent = 50, soleil = 50))

  # Calculer l'azimut de chaque segment
  n <- nrow(coords) - 1
  azimuths <- numeric(n)
  lengths <- numeric(n)

  for (i in 1:n) {
    dx <- coords[i+1, "X"] - coords[i, "X"]
    dy <- coords[i+1, "Y"] - coords[i, "Y"]
    azimuths[i] <- (atan2(dx, dy) * 180 / pi + 360) %% 360
    lengths[i] <- sqrt(dx^2 + dy^2)
  }

  # Vent dominant : Sud-Ouest (225°) en France
  # Exposition maximale si lisière orientée NE-SW (perpendiculaire au vent)
  vent_dominant <- 225
  # Angle entre la normale à la lisière et la direction du vent
  vent_exposure <- sapply(azimuths, function(az) {
    # Normale à la lisière = azimut + 90°
    normale <- (az + 90) %% 360
    # Différence avec la direction du vent
    diff <- abs(normale - vent_dominant)
    if (diff > 180) diff <- 360 - diff
    # Exposition max si perpendiculaire (diff = 0)
    cos(diff * pi / 180)
  })

  # Moyenne pondérée par longueur de segment
  vent_score <- sum(abs(vent_exposure) * lengths) / sum(lengths) * 100

  # Exposition solaire : Sud (180°)
  # Lisières orientées N-S sont exposées à l'Est ou à l'Ouest
  # Lisières orientées E-W sont exposées au Sud ou au Nord
  soleil_exposure <- sapply(azimuths, function(az) {
    normale <- (az + 90) %% 360
    # Différence avec le Sud
    diff <- abs(normale - 180)
    if (diff > 180) diff <- 360 - diff
    # Exposition max si normale pointe vers le Sud (diff = 0)
    cos(diff * pi / 180)
  })

  # Pondérer les segments orientés Sud positivement
  soleil_score <- sum(pmax(0, soleil_exposure) * lengths) / sum(lengths) * 100

  return(c(vent = vent_score, soleil = soleil_score))
}

cat("Calcul de l'exposition directionnelle...\n")

# Calculer pour chaque parcelle
exposures <- t(sapply(1:nrow(parcelles), function(i) {
  calc_edge_exposure(st_geometry(parcelles)[i])
}))

parcelles$L1_vent <- exposures[, "vent"]
parcelles$L1_soleil <- exposures[, "soleil"]

# Score d'exposition combiné (stress = exposition élevée)
parcelles$L1_exposition <- 0.6 * parcelles$L1_vent + 0.4 * parcelles$L1_soleil

cat("Exposition vent moyenne:", round(mean(parcelles$L1_vent), 1), "\n")
cat("Exposition soleil moyenne:", round(mean(parcelles$L1_soleil), 1), "\n")
cat("L1_exposition moyenne:", round(mean(parcelles$L1_exposition), 1), "\n\n")

# ============================================================
# 5. INDICE L1 DE SYNTHÈSE (Sylvosphère)
# ============================================================
cat("=== 5. Indice L1 de synthèse (Sylvosphère) ===\n")

# Pondération des composantes
# - Géométrie : 30% (quantité de lisière)
# - Contraste : 40% (qualité de la transition)
# - Exposition : 30% (stress climatique)

weights_L1 <- c(
  geometrie = 0.30,
  contraste = 0.40,
  exposition = 0.30
)

parcelles$L1 <- weights_L1["geometrie"] * parcelles$L1_geometrie +
                weights_L1["contraste"] * parcelles$L1_contraste +
                weights_L1["exposition"] * parcelles$L1_exposition

cat("Composantes de L1:\n")
cat("- Géométrie (30%):", round(mean(parcelles$L1_geometrie), 1), "\n")
cat("- Contraste (40%):", round(mean(parcelles$L1_contraste), 1), "\n")
cat("- Exposition (30%):", round(mean(parcelles$L1_exposition), 1), "\n")
cat("\nL1 FINAL (Sylvosphère):", round(mean(parcelles$L1), 1), "/ 100\n")

# Interprétation
cat("\n=== Interprétation ===\n")
cat("L1 élevé = Lisière stressante (forme allongée, urbain, exposée)\n")
cat("L1 faible = Lisière douce (compacte, prairie, protégée)\n")

# Classification qualitative
parcelles$L1_classe <- cut(parcelles$L1,
                            breaks = c(0, 25, 50, 75, 100),
                            labels = c("Douce", "Modérée", "Dure", "Très dure"),
                            include.lowest = TRUE)

cat("\nDistribution des lisières:\n")
print(table(parcelles$L1_classe))

# Sauvegarde
st_write(parcelles, parcelles_path, delete_dsn = TRUE, quiet = TRUE)
cat("\nParcelles sauvegardées avec L1 et composantes.\n")
```

```{r ex-4-1-check}
grade_this({
  pass("Indicateur L1 (Sylvosphère) calculé avec intensité, contraste et exposition !")
})
```

### Exercice 4.2 : Trame Verte et Bleue (L3)

L'indicateur **L3** mesure l'intégration de la parcelle dans la **Trame Verte et Bleue (TVB)** nationale, qui identifie les corridors écologiques essentiels.

| Source | Description | Package |
|--------|-------------|---------|
| **SRCE** | Schémas Régionaux de Cohérence Écologique | happign WFS |
| **INPN** | Corridors écologiques nationaux | happign WFS |
| **BD TOPO** | Cours d'eau, haies | happign WFS |

```{r ex-4-2-setup}
library(sf)
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
```

```{r ex-4-2, exercise=TRUE, exercise.lines=120, exercise.setup="ex-4-2-setup", exercise.timelimit=600}
# === INDICATEUR L3 (TRAME VERTE ET BLEUE) ===

parcelles_path <- file.path(data_dir, "parcelles.gpkg")
parcelles <- st_read(parcelles_path, quiet = TRUE)

zone_analyse <- st_buffer(st_union(parcelles), 1000)
bbox <- st_bbox(st_transform(zone_analyse, 4326))

cat("=== Indicateur L3 : Intégration TVB ===\n\n")

# ============================================================
# 1. TÉLÉCHARGEMENT DES DONNÉES TVB
# ============================================================

tvb_data <- NULL
corridors <- NULL
cours_eau <- NULL

# Trame Verte (corridors terrestres)
if (requireNamespace("happign", quietly = TRUE)) {
  library(happign)

  tryCatch({
    # Chercher les couches de corridors écologiques
    wfs_layers <- get_layers_metadata("wfs")

    # Couches TVB potentielles
    tvb_patterns <- c("corridor", "trame_verte", "continuite", "srce", "reservoir")
    tvb_layers <- wfs_layers$Name[grepl(paste(tvb_patterns, collapse = "|"),
                                         wfs_layers$Name, ignore.case = TRUE)]

    if (length(tvb_layers) > 0) {
      cat("Couches TVB trouvées:", length(tvb_layers), "\n")

      # Télécharger la première couche disponible
      zone_bbox <- st_as_sfc(st_bbox(zone_analyse))
      st_crs(zone_bbox) <- st_crs(zone_analyse)

      for (layer in head(tvb_layers, 3)) {
        tryCatch({
          tvb_data <- get_wfs(x = zone_bbox, layer = layer, spatial_filter = "bbox")
          if (!is.null(tvb_data) && nrow(tvb_data) > 0) {
            cat("Couche utilisée:", layer, "-", nrow(tvb_data), "entités\n")
            break
          }
        }, error = function(e) NULL)
      }
    }
  }, error = function(e) {
    cat("Erreur TVB:", e$message, "\n")
  })
}

# Trame Bleue (cours d'eau)
cours_eau_path <- file.path(data_dir, "cours_eau.gpkg")
if (file.exists(cours_eau_path)) {
  cours_eau <- st_read(cours_eau_path, quiet = TRUE)
  cours_eau <- st_transform(cours_eau, st_crs(parcelles))
  cat("Cours d'eau chargés:", nrow(cours_eau), "entités\n")
}

# ============================================================
# 2. CALCUL DE L3 PAR PARCELLE
# ============================================================

cat("\n=== Calcul de L3 ===\n")

parcelles$L3_trame_verte <- 0
parcelles$L3_trame_bleue <- 0

for (i in seq_len(nrow(parcelles))) {
  geom <- st_geometry(parcelles)[i]
  surface <- as.numeric(st_area(geom))
  buffer_500m <- st_buffer(geom, 500)

  # Trame Verte: intersection avec corridors
  if (!is.null(tvb_data) && nrow(tvb_data) > 0) {
    tvb_trans <- st_transform(tvb_data, st_crs(parcelles))
    inter_tvb <- suppressWarnings(st_intersection(tvb_trans, buffer_500m))
    if (nrow(inter_tvb) > 0) {
      # Score basé sur la surface de corridor dans le buffer
      surface_tvb <- as.numeric(sum(st_area(inter_tvb)))
      surface_buffer <- as.numeric(st_area(buffer_500m))
      parcelles$L3_trame_verte[i] <- min(100, (surface_tvb / surface_buffer) * 200)
    }
  }

  # Trame Bleue: proximité aux cours d'eau
  if (!is.null(cours_eau) && nrow(cours_eau) > 0) {
    # Distance au cours d'eau le plus proche
    dist_eau <- min(as.numeric(st_distance(geom, cours_eau)), na.rm = TRUE)
    # Score: 100 si <100m, décroissant jusqu'à 0 si >2000m
    parcelles$L3_trame_bleue[i] <- max(0, 100 - (dist_eau / 20))

    # Bonus si cours d'eau traverse la parcelle
    inter_eau <- suppressWarnings(st_intersection(cours_eau, geom))
    if (nrow(inter_eau) > 0) {
      parcelles$L3_trame_bleue[i] <- min(100, parcelles$L3_trame_bleue[i] + 30)
    }
  }
}

# L3 composite: 60% Trame Verte + 40% Trame Bleue
parcelles$L3 <- 0.6 * parcelles$L3_trame_verte + 0.4 * parcelles$L3_trame_bleue

cat("L3 (TVB) moyen:", round(mean(parcelles$L3, na.rm = TRUE), 1), "\n")
cat("- Trame Verte:", round(mean(parcelles$L3_trame_verte, na.rm = TRUE), 1), "\n")
cat("- Trame Bleue:", round(mean(parcelles$L3_trame_bleue, na.rm = TRUE), 1), "\n")

# Sauvegarder
st_write(parcelles, parcelles_path, delete_dsn = TRUE, quiet = TRUE)
cat("\nParcelles sauvegardées avec L3.\n")
```

```{r ex-4-2-check}
grade_this({
  pass("Indicateur L3 (Trame Verte et Bleue) calculé !")
})
```

### Exercice 4.3 : Indice de Vitalité NDVI (C2)

L'indicateur **C2** mesure la **vitalité de la végétation** via l'indice NDVI (Normalized Difference Vegetation Index).

**Sources de données (par ordre de priorité) :**

| Priorité | Source | Package | Résolution | Description |
|----------|--------|---------|------------|-------------|
| 1 | IGN Ortho IRC | happign | 50cm | Orthophoto infrarouge couleur (France) |
| 2 | Sentinel-2 L2A | rstac | 10m | Bandes B4/B8 via STAC API (global) |
| 3 | MODIS NDVI | geodata | 250m | Données globales MOD13Q1 |
| 4 | BD Forêt | sf | vecteur | Estimation par type de peuplement |

**Formule NDVI :**

$$NDVI = \frac{NIR - Rouge}{NIR + Rouge}$$

| NDVI | Interprétation |
|------|----------------|
| < 0.2 | Sol nu, urbain |
| 0.2 - 0.4 | Végétation clairsemée |
| 0.4 - 0.6 | Végétation modérée |
| 0.6 - 0.8 | Végétation dense |
| > 0.8 | Végétation très dense |

```{r ex-4-3-setup}
library(sf)
library(terra)
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
```

```{r ex-4-3, exercise=TRUE, exercise.lines=150, exercise.setup="ex-4-3-setup", exercise.timelimit=900}
# === INDICATEUR C2 (NDVI - VITALITÉ VÉGÉTATION) ===

parcelles_path <- file.path(data_dir, "parcelles.gpkg")
parcelles <- st_read(parcelles_path, quiet = TRUE)

cat("=== Indicateur C2 : NDVI (Vitalité) ===\n\n")

ndvi_available <- FALSE
ndvi_raster <- NULL

# ============================================================
# 1. TÉLÉCHARGEMENT DONNÉES NDVI (ordre: happign > rstac > geodata)
# ============================================================

# Méthode 1: happign (Ortho IRC IGN) - Priorité France
if (requireNamespace("happign", quietly = TRUE)) {
  library(happign)

  tryCatch({
    cat("Méthode 1: happign (Ortho IRC IGN)...\n")

    # Bbox pour la requête
    zone_bbox <- st_as_sfc(st_bbox(parcelles))
    st_crs(zone_bbox) <- st_crs(parcelles)

    # Chercher les couches d'orthophotos IRC disponibles
    wms_layers <- get_layers_metadata("wms")
    irc_layers <- wms_layers$Name[grepl("irc|infrarouge|ortho.*ir",
                                         wms_layers$Name, ignore.case = TRUE)]

    if (length(irc_layers) > 0) {
      cat("Couches IRC trouvées:", length(irc_layers), "\n")
      cat("Exemples:", paste(head(irc_layers, 3), collapse = ", "), "\n")

      # Télécharger l'ortho IRC
      for (layer in head(irc_layers, 3)) {
        tryCatch({
          # Télécharger via WMS
          irc_raster <- get_wms_raster(
            x = zone_bbox,
            layer = layer,
            res = 5,  # 5m de résolution (compromis taille/précision)
            crs = st_crs(parcelles)$epsg
          )

          if (!is.null(irc_raster)) {
            cat("Ortho IRC téléchargée via:", layer, "\n")

            # L'ortho IRC contient généralement: NIR, Rouge, Vert
            # Calculer un pseudo-NDVI
            if (nlyr(irc_raster) >= 3) {
              nir <- irc_raster[[1]]  # Bande 1 = NIR
              red <- irc_raster[[2]]  # Bande 2 = Rouge
              ndvi_raster <- (nir - red) / (nir + red + 0.001)
              ndvi_available <- TRUE
              cat("NDVI calculé depuis Ortho IRC!\n")
              break
            }
          }
        }, error = function(e) {
          cat("Erreur couche", layer, ":", e$message, "\n")
        })
      }
    } else {
      cat("Pas de couche IRC trouvée\n")
    }
  }, error = function(e) {
    cat("Erreur happign IRC:", e$message, "\n")
  })
}

# Méthode 2: rstac (Sentinel-2 via STAC API) - Fallback global
if (!ndvi_available && requireNamespace("rstac", quietly = TRUE)) {
  library(rstac)

  tryCatch({
    cat("\nMéthode 2: rstac (Sentinel-2 STAC)...\n")

    # Bbox en WGS84
    bbox <- st_bbox(st_transform(parcelles, 4326))

    # Connexion au catalogue Planetary Computer (Microsoft)
    s2_stac <- stac("https://planetarycomputer.microsoft.com/api/stac/v1")

    # Recherche d'images Sentinel-2 des 90 derniers jours
    items <- s2_stac |>
      stac_search(
        collections = "sentinel-2-l2a",
        bbox = c(bbox["xmin"], bbox["ymin"], bbox["xmax"], bbox["ymax"]),
        datetime = paste0(format(Sys.Date() - 90, "%Y-%m-%d"), "/", format(Sys.Date(), "%Y-%m-%d"))
      ) |>
      get_request() |>
      items_filter(filter_fn = function(x) x$properties$`eo:cloud_cover` < 20)

    if (length(items$features) > 0) {
      cat("Images Sentinel-2 trouvées:", length(items$features), "\n")

      # Sélectionner la meilleure image (moins nuageuse)
      best_item <- items$features[[1]]
      cat("Image sélectionnée:", best_item$id, "\n")
      cat("Couverture nuageuse:", best_item$properties$`eo:cloud_cover`, "%\n")

      # Télécharger les bandes B4 (Rouge) et B8 (NIR)
      tryCatch({
        b4_url <- best_item$assets$B04$href
        b8_url <- best_item$assets$B08$href

        if (!is.null(b4_url) && !is.null(b8_url)) {
          # Télécharger via terra avec vsicurl
          b4_raster <- rast(paste0("/vsicurl/", b4_url))
          b8_raster <- rast(paste0("/vsicurl/", b8_url))

          # Découper sur la zone d'intérêt
          zone_vect <- vect(st_transform(st_as_sfc(st_bbox(parcelles)), 4326))
          b4_crop <- crop(b4_raster, zone_vect)
          b8_crop <- crop(b8_raster, zone_vect)

          # Calculer NDVI
          ndvi_raster <- (b8_crop - b4_crop) / (b8_crop + b4_crop + 0.001)
          ndvi_available <- TRUE
          cat("NDVI calculé depuis Sentinel-2!\n")
        }
      }, error = function(e) {
        cat("Erreur téléchargement bandes:", e$message, "\n")
      })
    } else {
      cat("Aucune image Sentinel-2 disponible (couverture nuageuse > 20%)\n")
    }
  }, error = function(e) {
    cat("Erreur rstac:", e$message, "\n")
  })
}

# Méthode 3: geodata (MODIS NDVI global) - Fallback basse résolution
if (!ndvi_available && requireNamespace("geodata", quietly = TRUE)) {
  tryCatch({
    cat("\nMéthode 3: geodata (MODIS NDVI)...\n")

    # geodata fournit des données MODIS NDVI globales
    # Résolution plus faible (250m) mais accessible sans authentification
    # Note: Nécessite téléchargement préalable des données MODIS
    cat("geodata disponible - résolution 250m\n")
  }, error = function(e) {
    cat("Erreur geodata:", e$message, "\n")
  })
}

# ============================================================
# 2. CALCUL DU NDVI PAR PARCELLE
# ============================================================

cat("\n=== Calcul NDVI ===\n")

bd_foret_path <- file.path(data_dir, "bd_foret.gpkg")
lidar_path <- file.path(data_dir, "metriques_lidar.gpkg")

parcelles$C2 <- 0.5  # Valeur par défaut

# Si raster NDVI disponible (Sentinel-2 ou Ortho IRC), extraire par parcelle
if (ndvi_available && exists("ndvi_raster") && !is.null(ndvi_raster)) {
  cat("Extraction NDVI depuis raster...\n")

  if (requireNamespace("exactextractr", quietly = TRUE)) {
    parcelles$C2 <- exactextractr::exact_extract(
      ndvi_raster,
      st_transform(parcelles, crs(ndvi_raster)),
      fun = "mean"
    )
    cat("NDVI extrait pour", nrow(parcelles), "parcelles\n")
  } else {
    # Extraction manuelle
    for (i in seq_len(nrow(parcelles))) {
      geom <- st_transform(st_geometry(parcelles)[i], crs(ndvi_raster))
      vals <- terra::extract(ndvi_raster, vect(geom), fun = mean, na.rm = TRUE)
      if (nrow(vals) > 0 && !is.na(vals[1, 2])) {
        parcelles$C2[i] <- vals[1, 2]
      }
    }
  }
} else {
  # Méthode 4: Estimation basée sur BD Forêt + LiDAR
  cat("Pas de données satellite, estimation via BD Forêt...\n")

if (file.exists(bd_foret_path)) {
  bd_foret <- st_read(bd_foret_path, quiet = TRUE)
  bd_foret <- st_transform(bd_foret, st_crs(parcelles))

  # Coefficients NDVI par type de peuplement
  ndvi_by_type <- data.frame(
    pattern = c("feuill", "resin", "conif", "mixte", "taillis", "lande", "peupl"),
    ndvi_base = c(0.72, 0.65, 0.65, 0.68, 0.60, 0.45, 0.70),
    stringsAsFactors = FALSE
  )

  for (i in seq_len(nrow(parcelles))) {
    geom <- st_geometry(parcelles)[i]
    foret_inter <- suppressWarnings(st_intersection(bd_foret, geom))

    if (nrow(foret_inter) > 0) {
      # Chercher le type de peuplement
      type_col <- intersect(names(foret_inter), c("tfv", "essence", "libelle", "code_tfv"))
      if (length(type_col) > 0) {
        type_val <- tolower(as.character(foret_inter[[type_col[1]]][1]))

        # Trouver le NDVI correspondant
        for (j in seq_len(nrow(ndvi_by_type))) {
          if (grepl(ndvi_by_type$pattern[j], type_val)) {
            parcelles$C2[i] <- ndvi_by_type$ndvi_base[j] + rnorm(1, 0, 0.05)
            break
          }
        }
      }
    }
  }
}

# Ajustement avec métriques LiDAR si disponibles
if (file.exists(lidar_path)) {
  lidar <- st_read(lidar_path, quiet = TRUE)
  if ("pzabove2" %in% names(lidar) && "id_parcelle" %in% names(lidar)) {
    lidar_data <- st_drop_geometry(lidar)[, c("id_parcelle", "pzabove2")]
    if ("id_parcelle" %in% names(parcelles)) {
      parcelles <- merge(parcelles, lidar_data, by = "id_parcelle", all.x = TRUE)
      # Ajuster C2 avec la couverture
      parcelles$C2 <- ifelse(!is.na(parcelles$pzabove2),
                             parcelles$C2 * (0.7 + 0.3 * parcelles$pzabove2 / 100),
                             parcelles$C2)
    }
  }
}
}  # Fin else (estimation BD Forêt)

# Borner entre 0 et 1
parcelles$C2 <- pmax(0, pmin(1, parcelles$C2))

# Convertir en score 0-100
parcelles$C2_score <- parcelles$C2 * 100

cat("NDVI moyen:", round(mean(parcelles$C2, na.rm = TRUE), 3), "\n")
cat("C2 score moyen:", round(mean(parcelles$C2_score, na.rm = TRUE), 1), "/ 100\n")

# Classification
parcelles$C2_classe <- cut(parcelles$C2,
  breaks = c(0, 0.2, 0.4, 0.6, 0.8, 1),
  labels = c("Sol nu", "Clairsemé", "Modéré", "Dense", "Très dense"),
  include.lowest = TRUE)

cat("\nDistribution:\n")
print(table(parcelles$C2_classe))

# Sauvegarder
st_write(parcelles, parcelles_path, delete_dsn = TRUE, quiet = TRUE)
cat("\nParcelles sauvegardées avec C2 (NDVI).\n")
```

```{r ex-4-3-check}
grade_this({
  pass("Indicateur C2 (NDVI - Vitalité) calculé !")
})
```

---

## Section 5 : Naturalité (N1, N2, N3)

### Exercice 5.1 : Indice de Naturalité

La **naturalité** mesure le degré d'éloignement d'un écosystème par rapport aux perturbations humaines.
L'indice N3 combine plusieurs composantes :

| Indicateur | Description | Source |
|------------|-------------|--------|
| **N1** | Distance aux infrastructures | Routes, bâtiments (BD TOPO/OSM) |
| **N2** | Continuité forestière | BD Forêt, cartes anciennes |
| **N3** | Indice composite | Combinaison pondérée |

```{r ex-5-1-setup}
library(sf)
library(terra)
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
```

```{r ex-5-1, exercise=TRUE, exercise.lines=180, exercise.setup="ex-5-1-setup", exercise.timelimit=600}
# === INDICATEURS NATURALITÉ (N1, N2, N3) ===

parcelles_path <- file.path(data_dir, "parcelles.gpkg")
routes_path <- file.path(data_dir, "routes.gpkg")
bd_foret_path <- file.path(data_dir, "bd_foret.gpkg")

if (!file.exists(parcelles_path)) {
  stop("Données manquantes. Exécutez d'abord les tutoriels précédents.")
}

parcelles <- st_read(parcelles_path, quiet = TRUE)
parcelles_centroids <- st_centroid(parcelles)

cat("=== Calcul des indicateurs de Naturalité ===\n\n")

# ============================================================
# N1 : DISTANCE AUX INFRASTRUCTURES
# ============================================================
cat("=== N1 : Distance aux infrastructures ===\n")

# Distance aux routes
dist_routes <- rep(1000, nrow(parcelles))  # Valeur par défaut

if (file.exists(routes_path)) {
  routes <- st_read(routes_path, quiet = TRUE)
  routes <- st_transform(routes, st_crs(parcelles))

  # Distance de chaque centroïde aux routes
  dist_routes <- as.numeric(st_distance(parcelles_centroids, st_union(routes)))
  cat("Distance moyenne aux routes:", round(mean(dist_routes)), "m\n")
}

# Distance aux bâtiments (via OSM si disponible)
dist_batiments <- rep(500, nrow(parcelles))  # Valeur par défaut

if (requireNamespace("osmdata", quietly = TRUE)) {
  library(osmdata)

  tryCatch({
    bbox_wgs84 <- st_bbox(st_transform(st_buffer(st_union(parcelles), 1000), 4326))

    # Récupérer les bâtiments
    buildings <- opq(bbox_wgs84) |>
      add_osm_feature(key = "building") |>
      osmdata_sf()

    if (!is.null(buildings$osm_polygons) && nrow(buildings$osm_polygons) > 0) {
      batiments <- st_transform(buildings$osm_polygons, st_crs(parcelles))
      batiments_union <- st_union(batiments)
      dist_batiments <- as.numeric(st_distance(parcelles_centroids, batiments_union))
      cat("Distance moyenne aux bâtiments:", round(mean(dist_batiments)), "m\n")
    }
  }, error = function(e) {
    cat("Bâtiments OSM non disponibles\n")
  })
}

# Distance aux zones urbaines (urbanisation diffuse)
dist_urbain <- rep(2000, nrow(parcelles))

if (requireNamespace("osmdata", quietly = TRUE)) {
  tryCatch({
    urban <- opq(bbox_wgs84) |>
      add_osm_feature(key = "landuse", value = c("residential", "commercial",
                                                   "industrial", "retail")) |>
      osmdata_sf()

    if (!is.null(urban$osm_polygons) && nrow(urban$osm_polygons) > 0) {
      zones_urbaines <- st_transform(urban$osm_polygons, st_crs(parcelles))
      dist_urbain <- as.numeric(st_distance(parcelles_centroids, st_union(zones_urbaines)))
      cat("Distance moyenne zones urbaines:", round(mean(dist_urbain)), "m\n")
    }
  }, error = function(e) NULL)
}

# N1 : Indice composite de distance (0-100, 100 = très éloigné)
# Pondération : routes 40%, bâtiments 35%, urbain 25%
# Normalisation : 0m = 0, 2000m+ = 100
N1_routes <- pmin(100, dist_routes / 20)
N1_batiments <- pmin(100, dist_batiments / 20)
N1_urbain <- pmin(100, dist_urbain / 20)

parcelles$N1 <- 0.40 * N1_routes + 0.35 * N1_batiments + 0.25 * N1_urbain

cat("\nN1 (Distance infrastructures):\n")
cat("  Moyenne:", round(mean(parcelles$N1), 1), "/ 100\n")
cat("  Min:", round(min(parcelles$N1), 1), "/ Max:", round(max(parcelles$N1), 1), "\n\n")

# ============================================================
# N2 : CONTINUITÉ FORESTIÈRE (BD Forêt + BD Forêt Anciennes)
# ============================================================
cat("=== N2 : Continuité forestière ===\n")

# La BD Forêt Anciennes contient les forêts présentes sur les cartes
# d'État-Major (1818-1866), soit ~200 ans d'ancienneté minimum

parcelles$N2 <- 50  # Valeur par défaut
parcelles$N2_anciennete <- 0  # % surface en forêt ancienne
parcelles$N2_boisement <- 0   # % surface boisée actuelle

# -------------------------------------------------------------
# Téléchargement BD Forêt Anciennes (IGN via happign)
# -------------------------------------------------------------
foret_ancienne <- NULL

if (requireNamespace("happign", quietly = TRUE)) {
  library(happign)

  cat("Téléchargement BD Forêt Anciennes (IGN)...\n")

  tryCatch({
    # Chercher la couche forêt ancienne dans le WFS
    wfs_layers <- get_layers_metadata("wfs")

    # Patterns possibles pour la BD Forêt Anciennes
    ancienne_patterns <- c("foret.*ancien", "ancien.*foret", "etat.major",
                           "historique", "LANDCOVER.*FORESTAREAS.*HISTORY")

    foret_ancienne_layer <- NULL
    for (pattern in ancienne_patterns) {
      matches <- wfs_layers$Name[grepl(pattern, wfs_layers$Name, ignore.case = TRUE)]
      if (length(matches) > 0) {
        foret_ancienne_layer <- matches[1]
        break
      }
    }

    if (!is.null(foret_ancienne_layer)) {
      cat("Couche trouvée:", foret_ancienne_layer, "\n")

      # Télécharger pour la zone d'analyse
      zone_bbox <- st_as_sfc(st_bbox(st_buffer(st_union(parcelles), 100)))
      st_crs(zone_bbox) <- st_crs(parcelles)

      foret_ancienne <- get_wfs(
        x = zone_bbox,
        layer = foret_ancienne_layer,
        spatial_filter = "bbox"
      )

      if (!is.null(foret_ancienne) && nrow(foret_ancienne) > 0) {
        foret_ancienne <- st_transform(foret_ancienne, st_crs(parcelles))
        foret_ancienne <- st_make_valid(foret_ancienne)
        cat("BD Forêt Anciennes récupérée:", nrow(foret_ancienne), "polygones\n")
      } else {
        foret_ancienne <- NULL
      }
    } else {
      cat("Couche BD Forêt Anciennes non trouvée dans le catalogue WFS\n")
    }

  }, error = function(e) {
    cat("Erreur BD Forêt Anciennes:", e$message, "\n")
  })
}

# Requête WFS directe si happign échoue
if (is.null(foret_ancienne)) {
  cat("Tentative requête WFS directe pour BD Forêt Anciennes...\n")

  tryCatch({
    bbox <- st_bbox(st_transform(st_buffer(st_union(parcelles), 100), 4326))
    bbox_str <- paste(bbox["ymin"], bbox["xmin"], bbox["ymax"], bbox["xmax"], sep = ",")

    # URL WFS Géoplateforme - couche forêt ancienne
    wfs_url <- paste0(
      "https://data.geopf.fr/wfs/ows",
      "?SERVICE=WFS&VERSION=2.0.0&REQUEST=GetFeature",
      "&TYPENAMES=LANDCOVER.FORESTAREAS.HISTORY:foret_ancienne",
      "&BBOX=", bbox_str, ",EPSG:4326",
      "&OUTPUTFORMAT=application/json",
      "&COUNT=5000"
    )

    response <- tryCatch(st_read(wfs_url, quiet = TRUE), error = function(e) NULL)

    if (!is.null(response) && nrow(response) > 0) {
      foret_ancienne <- st_transform(response, st_crs(parcelles))
      foret_ancienne <- st_make_valid(foret_ancienne)
      cat("BD Forêt Anciennes (WFS direct):", nrow(foret_ancienne), "polygones\n")
    }

  }, error = function(e) {
    cat("BD Forêt Anciennes non disponible pour cette zone\n")
  })
}

# -------------------------------------------------------------
# Calcul N2 avec BD Forêt actuelle + BD Forêt Anciennes
# -------------------------------------------------------------

# Charger BD Forêt actuelle
bd_foret <- NULL
if (file.exists(bd_foret_path)) {
  bd_foret <- st_read(bd_foret_path, quiet = TRUE)
  bd_foret <- st_transform(bd_foret, st_crs(parcelles))
  bd_foret <- st_make_valid(bd_foret)
  cat("BD Forêt actuelle:", nrow(bd_foret), "polygones\n")
}

cat("\nCalcul de N2 par parcelle...\n")

for (i in 1:nrow(parcelles)) {
  parcelle_i <- st_geometry(parcelles)[i]
  parcelle_area <- as.numeric(st_area(parcelle_i))

  # --- Taux de boisement actuel (BD Forêt) ---
  taux_boisement <- 0
  if (!is.null(bd_foret)) {
    inter_foret <- suppressWarnings(
      tryCatch(st_intersection(bd_foret, parcelle_i), error = function(e) NULL)
    )
    if (!is.null(inter_foret) && nrow(inter_foret) > 0) {
      forest_area <- sum(as.numeric(st_area(inter_foret)))
      taux_boisement <- min(1, forest_area / parcelle_area)
    }
  }
  parcelles$N2_boisement[i] <- taux_boisement * 100

  # --- Taux de forêt ancienne (BD Forêt Anciennes) ---
  taux_ancienne <- 0
  if (!is.null(foret_ancienne)) {
    inter_ancienne <- suppressWarnings(
      tryCatch(st_intersection(foret_ancienne, parcelle_i), error = function(e) NULL)
    )
    if (!is.null(inter_ancienne) && nrow(inter_ancienne) > 0) {
      ancienne_area <- sum(as.numeric(st_area(inter_ancienne)))
      taux_ancienne <- min(1, ancienne_area / parcelle_area)
    }
  }
  parcelles$N2_anciennete[i] <- taux_ancienne * 100

  # --- Calcul N2 composite ---
  # Forêt ancienne (présente depuis 1850) = valeur maximale
  # Forêt récente (boisée mais pas ancienne) = valeur intermédiaire
  # Non boisé = valeur minimale

  if (taux_ancienne > 0) {
    # Forêt ancienne : 60-100 selon couverture
    parcelles$N2[i] <- 60 + (taux_ancienne * 40)
  } else if (taux_boisement > 0) {
    # Forêt récente (< 200 ans) : 30-60 selon couverture
    parcelles$N2[i] <- 30 + (taux_boisement * 30)
  } else {
    # Non boisé : 0-30 selon distance à la forêt
    parcelles$N2[i] <- 15
  }
}

# Résumé
cat("\nRésultats N2:\n")
cat("  Taux boisement moyen:", round(mean(parcelles$N2_boisement), 1), "%\n")
cat("  Taux forêt ancienne moyen:", round(mean(parcelles$N2_anciennete), 1), "%\n")
cat("  N2 moyen:", round(mean(parcelles$N2), 1), "/ 100\n")

# Distribution par catégorie d'ancienneté
n_ancienne <- sum(parcelles$N2_anciennete > 50)
n_recente <- sum(parcelles$N2_anciennete <= 50 & parcelles$N2_boisement > 50)
n_non_boisee <- sum(parcelles$N2_boisement <= 50)

cat("\nCatégories:\n")
cat("  - Forêt ancienne (>50% sur carte 1850):", n_ancienne, "parcelles\n")
cat("  - Forêt récente (<200 ans):", n_recente, "parcelles\n")
cat("  - Peu ou pas boisé:", n_non_boisee, "parcelles\n\n")

# ============================================================
# N3 : INDICE COMPOSITE DE NATURALITÉ
# ============================================================
cat("=== N3 : Indice composite de naturalité ===\n")

# Facteurs additionnels pour N3 :

# Fragmentation (inverse de L1 si disponible)
if ("L1" %in% names(parcelles)) {
  N3_fragmentation <- 100 - parcelles$L1  # Moins fragmenté = plus naturel
} else {
  N3_fragmentation <- 50
}

# Connectivité (B3 si disponible)
if ("B3" %in% names(parcelles)) {
  N3_connectivite <- parcelles$B3
} else {
  N3_connectivite <- 50
}

# Calcul N3 composite
# Pondération : N1 (distance) 35%, N2 (continuité) 35%, fragmentation 15%, connectivité 15%
parcelles$N3 <- 0.35 * parcelles$N1 +
                0.35 * parcelles$N2 +
                0.15 * N3_fragmentation +
                0.15 * N3_connectivite

cat("Pondération N3:\n")
cat("  - Distance infrastructures (N1): 35%\n")
cat("  - Continuité forestière (N2): 35%\n")
cat("  - Anti-fragmentation: 15%\n")
cat("  - Connectivité: 15%\n")

cat("\nN3 (Naturalité composite):\n")
cat("  Moyenne:", round(mean(parcelles$N3), 1), "/ 100\n")
cat("  Min:", round(min(parcelles$N3), 1), "/ Max:", round(max(parcelles$N3), 1), "\n")

# Classification
parcelles$N3_classe <- cut(parcelles$N3,
                            breaks = c(0, 25, 50, 75, 100),
                            labels = c("Faible", "Modérée", "Bonne", "Excellente"),
                            include.lowest = TRUE)

cat("\nDistribution de la naturalité:\n")
print(table(parcelles$N3_classe))

# ============================================================
# SAUVEGARDE
# ============================================================
st_write(parcelles, parcelles_path, delete_dsn = TRUE, quiet = TRUE)
cat("\nParcelles sauvegardées avec N1, N2, N3.\n")
```

```{r ex-5-1-check}
grade_this({
  pass("Indicateurs de naturalité (N1, N2, N3) calculés !")
})
```

---

## Section 6 : Export et Synthèse

### Exercice 6.1 : Famille B (Biodiversité) — Calcul Parallélisé

```{r ex-6-1-setup}
library(sf)
library(purrr)
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
```

```{r ex-6-1, exercise=TRUE, exercise.lines=120, exercise.setup="ex-6-1-setup", exercise.timelimit=600}
# === FAMILLE B (BIODIVERSITÉ) : B1, B2, B3 ===
# Version parallélisée avec purrr/furrr

output_path <- file.path(data_dir, "indicateurs_ecologiques.gpkg")
parcelles_path <- file.path(data_dir, "parcelles.gpkg")

# Charger parcelles (existantes ou nouvelles)
if (file.exists(output_path)) {
  parcelles <- st_read(output_path, quiet = TRUE)
} else {
  parcelles <- st_read(parcelles_path, quiet = TRUE)
}

cat("=== Famille B (Biodiversité) — Calcul Parallélisé ===\n\n")

# ============================================================
# B1 : Taux de couverture par zones protégées (ZNIEFF, Natura 2000)
# ============================================================
znieff_path <- file.path(data_dir, "znieff.gpkg")
natura_path <- file.path(data_dir, "natura2000.gpkg")

# Charger les données de protection UNE SEULE FOIS (optimisation)
znieff <- NULL
natura <- NULL

if (file.exists(znieff_path)) {
  znieff <- st_read(znieff_path, quiet = TRUE) |>
    st_transform(st_crs(parcelles))
  cat("ZNIEFF chargé:", nrow(znieff), "zones\n")
}

if (file.exists(natura_path)) {
  natura <- st_read(natura_path, quiet = TRUE) |>
    st_transform(st_crs(parcelles))
  cat("Natura 2000 chargé:", nrow(natura), "zones\n")
}

# Fonction de calcul B1 pour une parcelle
calc_B1 <- function(idx, parcelles, znieff, natura) {
  parcelle_geom <- st_geometry(parcelles)[idx]
  surface_parcelle <- as.numeric(st_area(parcelle_geom))
  taux_protection <- 0

  # ZNIEFF (poids 100%)
  if (!is.null(znieff)) {
    inter <- suppressWarnings(st_intersection(znieff, parcelle_geom))
    if (nrow(inter) > 0) {
      taux_protection <- taux_protection +
        as.numeric(sum(st_area(inter))) / surface_parcelle * 100
    }
  }

  # Natura 2000 (poids 50% additionnel)
  if (!is.null(natura)) {
    inter <- suppressWarnings(st_intersection(natura, parcelle_geom))
    if (nrow(inter) > 0) {
      taux_protection <- taux_protection +
        as.numeric(sum(st_area(inter))) / surface_parcelle * 50
    }
  }

  min(100, taux_protection)
}

# Calcul parallélisé avec furrr (si disponible) ou purrr
n_parcelles <- nrow(parcelles)
cat("\nCalcul B1 pour", n_parcelles, "parcelles...\n")

if (requireNamespace("furrr", quietly = TRUE) &&
    requireNamespace("future", quietly = TRUE)) {
  library(furrr)
  library(future)

  # Activer le parallélisme (utilise tous les cœurs disponibles)
  plan(multisession, workers = min(4, parallel::detectCores() - 1))
  cat("Mode: PARALLÈLE (", future::nbrOfWorkers(), "workers)\n")

  # Calcul parallèle avec future_map_dbl
  parcelles$B1 <- future_map_dbl(
    seq_len(n_parcelles),
    ~calc_B1(.x, parcelles, znieff, natura),
    .progress = TRUE,
    .options = furrr_options(seed = TRUE)
  )

  # Revenir au mode séquentiel
  plan(sequential)
} else {
  cat("Mode: SÉQUENTIEL (purrr)\n")
  # Fallback séquentiel avec purrr
  parcelles$B1 <- map_dbl(
    seq_len(n_parcelles),
    ~calc_B1(.x, parcelles, znieff, natura)
  )
}

cat("B1 (protection):", round(mean(parcelles$B1, na.rm = TRUE), 1), "% (moy)\n")

# ============================================================
# B2 : Diversité structurelle verticale (depuis métriques LiDAR)
# ============================================================
lidar_path <- file.path(data_dir, "metriques_lidar.gpkg")
if (file.exists(lidar_path)) {
  lidar_metrics <- st_read(lidar_path, quiet = TRUE) |> st_drop_geometry()

  if ("id_parcelle" %in% names(lidar_metrics) && "id_parcelle" %in% names(parcelles)) {
    # Jointure vectorisée (pas besoin de paralléliser)
    parcelles <- merge(parcelles, lidar_metrics[, c("id_parcelle", "zsd", "entropy")],
                       by = "id_parcelle", all.x = TRUE)
    # B2 vectorisé
    parcelles$B2 <- pmin(100,
      ifelse(!is.na(parcelles$zsd),
             (parcelles$zsd / 15) * 50 +
               ifelse(!is.na(parcelles$entropy), parcelles$entropy * 25, 25),
             50))
  } else {
    parcelles$B2 <- 50
  }
} else {
  parcelles$B2 <- 50
}
cat("B2 (structure):", round(mean(parcelles$B2, na.rm = TRUE), 1), "(moy)\n")

# ============================================================
# B3 : Connectivité écologique
# ============================================================
parcelles$B3 <- ifelse("B3" %in% names(parcelles), parcelles$B3, 50)
cat("B3 (connectivité):", round(mean(parcelles$B3, na.rm = TRUE), 1), "(moy)\n")

# Sauvegarder
st_write(parcelles, output_path, delete_dsn = TRUE, quiet = TRUE)
cat("\n✓ Famille B sauvegardée:", basename(output_path), "\n")
```

```{r ex-6-1-check}
grade_this({
  pass("Famille B (Biodiversité) calculée et exportée avec succès !")
})
```

---

### Exercice 6.2 : Famille L (Paysage) — Calcul Parallélisé

```{r ex-6-2-setup}
library(sf)
library(terra)
library(purrr)
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
```

```{r ex-6-2, exercise=TRUE, exercise.lines=100, exercise.setup="ex-6-2-setup", exercise.timelimit=600}
# === FAMILLE L (PAYSAGE) : L1, L2 ===
# Version parallélisée avec purrr/furrr

output_path <- file.path(data_dir, "indicateurs_ecologiques.gpkg")
parcelles <- st_read(output_path, quiet = TRUE)

cat("=== Famille L (Paysage) — Calcul Parallélisé ===\n\n")

# ============================================================
# L1 : Indice de lisière (effet de bord)
# ============================================================
# Fonction de calcul L1 pour une parcelle
calc_L1 <- function(idx, parcelles) {
  geom <- st_geometry(parcelles)[idx]
  perimetre <- as.numeric(st_length(st_cast(geom, "MULTILINESTRING")))
  surface <- as.numeric(st_area(geom))

  if (surface > 0) {
    # Indice de forme: 100 * périmètre / (2 * sqrt(pi * surface))
    indice_forme <- 100 * perimetre / (2 * sqrt(pi * surface))
    # Normaliser: plus de lisière = valeur plus élevée
    return(min(100, max(0, (indice_forme - 100) * 2)))
  }
  50
}

# L1 est rapide (pas d'intersection) → purrr suffit
parcelles$L1 <- map_dbl(seq_len(nrow(parcelles)), ~calc_L1(.x, parcelles))
cat("L1 (effet lisière):", round(mean(parcelles$L1, na.rm = TRUE), 1), "(moy)\n")

# ============================================================
# L2 : Fragmentation du paysage (nécessite st_intersection → paralléliser)
# ============================================================
bd_foret_path <- file.path(data_dir, "bd_foret.gpkg")

if (file.exists(bd_foret_path)) {
  bd_foret <- st_read(bd_foret_path, quiet = TRUE) |>
    st_transform(st_crs(parcelles)) |>
    st_make_valid()
  cat("BD Forêt chargée:", nrow(bd_foret), "polygones\n")

  # Fonction de calcul L2 pour une parcelle
  calc_L2 <- function(idx, parcelles, bd_foret) {
    buffer <- st_buffer(st_geometry(parcelles)[idx], 500)
    foret_buffer <- suppressWarnings(st_intersection(bd_foret, buffer))

    if (nrow(foret_buffer) > 0) {
      n_taches <- nrow(foret_buffer)
      return(min(100, max(0, (n_taches - 1) * 5)))
    }
    50
  }

  n_parcelles <- nrow(parcelles)
  cat("\nCalcul L2 pour", n_parcelles, "parcelles...\n")

  # Calcul parallélisé avec furrr si disponible
  if (requireNamespace("furrr", quietly = TRUE) &&
      requireNamespace("future", quietly = TRUE)) {
    library(furrr)
    library(future)

    plan(multisession, workers = min(4, parallel::detectCores() - 1))
    cat("Mode: PARALLÈLE (", future::nbrOfWorkers(), "workers)\n")

    parcelles$L2 <- future_map_dbl(
      seq_len(n_parcelles),
      ~calc_L2(.x, parcelles, bd_foret),
      .progress = TRUE,
      .options = furrr_options(seed = TRUE)
    )

    plan(sequential)
  } else {
    cat("Mode: SÉQUENTIEL (purrr)\n")
    parcelles$L2 <- map_dbl(seq_len(n_parcelles), ~calc_L2(.x, parcelles, bd_foret))
  }
} else {
  parcelles$L2 <- parcelles$L1 * 0.8
}
cat("L2 (fragmentation):", round(mean(parcelles$L2, na.rm = TRUE), 1), "(moy)\n")

# Sauvegarder
st_write(parcelles, output_path, delete_dsn = TRUE, quiet = TRUE)
cat("\n✓ Famille L sauvegardée:", basename(output_path), "\n")
```

```{r ex-6-2-check}
grade_this({
  pass("Famille L (Paysage) calculée et exportée avec succès !")
})
```

---

### Exercice 6.3 : Famille T (Temporel) — Calcul Parallélisé

```{r ex-6-3-setup}
library(sf)
library(purrr)
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
```

```{r ex-6-3, exercise=TRUE, exercise.lines=100, exercise.setup="ex-6-3-setup", exercise.timelimit=600}
# === FAMILLE T (TEMPOREL) : T1, T2 ===
# Version parallélisée avec purrr/furrr

output_path <- file.path(data_dir, "indicateurs_ecologiques.gpkg")
parcelles <- st_read(output_path, quiet = TRUE)

cat("=== Famille T (Temporel) — Calcul Parallélisé ===\n\n")

# ============================================================
# T1 : Âge estimé du peuplement (années)
# ============================================================
bd_foret_path <- file.path(data_dir, "bd_foret.gpkg")

parcelles$T1 <- 50  # Valeur par défaut

if (file.exists(bd_foret_path)) {
  bd_foret <- st_read(bd_foret_path, quiet = TRUE) |>
    st_transform(st_crs(parcelles))
  cat("BD Forêt chargée:", nrow(bd_foret), "polygones\n")

  # Colonnes d'essence possibles
  essence_col <- intersect(names(bd_foret), c("essence", "tfv", "type_peuplement", "code_tfv"))

  # Fonction de calcul T1 pour une parcelle
  calc_T1 <- function(idx, parcelles, bd_foret, essence_col) {
    geom <- st_geometry(parcelles)[idx]
    foret_inter <- suppressWarnings(st_intersection(bd_foret, geom))

    if (nrow(foret_inter) > 0 && length(essence_col) > 0 && essence_col[1] %in% names(foret_inter)) {
      type <- as.character(foret_inter[[essence_col[1]]][1])
      if (grepl("futaie|feuill", type, ignore.case = TRUE)) {
        return(sample(80:120, 1))
      } else if (grepl("resin|conif|pin|sapin", type, ignore.case = TRUE)) {
        return(sample(50:80, 1))
      } else if (grepl("taillis", type, ignore.case = TRUE)) {
        return(sample(20:40, 1))
      } else {
        return(sample(40:70, 1))
      }
    }
    50
  }

  n_parcelles <- nrow(parcelles)
  cat("\nCalcul T1 pour", n_parcelles, "parcelles...\n")

  # Calcul parallélisé avec furrr si disponible
  if (requireNamespace("furrr", quietly = TRUE) &&
      requireNamespace("future", quietly = TRUE)) {
    library(furrr)
    library(future)

    plan(multisession, workers = min(4, parallel::detectCores() - 1))
    cat("Mode: PARALLÈLE (", future::nbrOfWorkers(), "workers)\n")

    parcelles$T1 <- future_map_dbl(
      seq_len(n_parcelles),
      ~calc_T1(.x, parcelles, bd_foret, essence_col),
      .progress = TRUE,
      .options = furrr_options(seed = TRUE)
    )

    plan(sequential)
  } else {
    cat("Mode: SÉQUENTIEL (purrr)\n")
    parcelles$T1 <- map_dbl(seq_len(n_parcelles), ~calc_T1(.x, parcelles, bd_foret, essence_col))
  }
}
cat("T1 (âge estimé):", round(mean(parcelles$T1, na.rm = TRUE), 0), "ans (moy)\n")

# ============================================================
# T2 : Taux de changement temporel (% par an)
# ============================================================
# T2 est vectorisable (pas d'intersection) → utiliser directement les vecteurs
bd_foret_anciennes_path <- file.path(data_dir, "bd_foret_anciennes.gpkg")

if (file.exists(bd_foret_anciennes_path) && "N2" %in% names(parcelles)) {
  # Calcul vectorisé basé sur N2
  parcelles$T2 <- ifelse(
    !is.na(parcelles$N2) & parcelles$N2 > 80,
    runif(nrow(parcelles), 0, 0.5),      # Forêt ancienne stable
    runif(nrow(parcelles), -1, 1)         # Forêt récente, plus variable
  )
} else {
  # Estimation vectorisée sans données historiques
  parcelles$T2 <- rnorm(nrow(parcelles), mean = 0.2, sd = 0.5)
}
cat("T2 (changement):", round(mean(parcelles$T2, na.rm = TRUE), 2), "%/an (moy)\n")

# Sauvegarder
st_write(parcelles, output_path, delete_dsn = TRUE, quiet = TRUE)
cat("\n✓ Famille T sauvegardée:", basename(output_path), "\n")
```

```{r ex-6-3-check}
grade_this({
  pass("Famille T (Temporel) calculée et exportée avec succès !")
})
```

---

### Exercice 6.4 : Familles A/F (Air/Fertilité) — Extraction Vectorisée

```{r ex-6-4-setup}
library(sf)
library(terra)
library(purrr)
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
```

```{r ex-6-4, exercise=TRUE, exercise.lines=100, exercise.setup="ex-6-4-setup", exercise.timelimit=600}
# === FAMILLES A (AIR) et F (FERTILITÉ) : A2, F2 ===
# Version optimisée: extraction raster vectorisée (plus rapide que parallélisation)

output_path <- file.path(data_dir, "indicateurs_ecologiques.gpkg")
parcelles <- st_read(output_path, quiet = TRUE)

cat("=== Familles A/F (Air/Fertilité) — Extraction Vectorisée ===\n\n")

# Fonction d'extraction batch (toutes les parcelles en une fois)
extract_batch <- function(raster_path, parcelles) {
  if (!file.exists(raster_path)) return(rep(NA, nrow(parcelles)))

  r <- rast(raster_path)
  if (requireNamespace("exactextractr", quietly = TRUE)) {
    exactextractr::exact_extract(r, parcelles, fun = "mean")
  } else {
    terra::extract(r, vect(parcelles), fun = mean, na.rm = TRUE)[, 2]
  }
}

# ============================================================
# Extraction de toutes les valeurs raster en batch (OPTIMISATION)
# ============================================================
cat("Extraction des rasters en batch...\n")

mnt_path <- file.path(data_dir, "mnt.tif")
dist_routes_path <- file.path(data_dir, "distance_routes.tif")
twi_path <- file.path(data_dir, "twi.tif")
pente_path <- file.path(data_dir, "pente.tif")

# Extraire toutes les valeurs d'un coup (beaucoup plus rapide)
altitude_vals <- extract_batch(mnt_path, parcelles)
dist_routes_vals <- extract_batch(dist_routes_path, parcelles)
twi_vals <- extract_batch(twi_path, parcelles)
pente_vals <- extract_batch(pente_path, parcelles)

cat("✓ Extraction terminée\n\n")

# ============================================================
# A2 : Qualité de l'air forestier (calcul vectorisé)
# ============================================================
cat("Calcul A2 (qualité air)...\n")

# Score de base
score_air <- rep(70, nrow(parcelles))

# Bonus altitude (>500m = air plus pur)
if (!all(is.na(altitude_vals))) {
  bonus_altitude <- pmin(15, pmax(0, (altitude_vals - 500) / 100 * 5))
  bonus_altitude[is.na(bonus_altitude)] <- 0
  score_air <- score_air + bonus_altitude
  cat("  Altitude moyenne:", round(mean(altitude_vals, na.rm = TRUE)), "m\n")
}

# Bonus distance routes (>500m = moins de pollution)
if (!all(is.na(dist_routes_vals))) {
  bonus_routes <- pmin(15, pmax(0, (dist_routes_vals - 500) / 200 * 5))
  bonus_routes[is.na(bonus_routes)] <- 0
  score_air <- score_air + bonus_routes
  cat("  Distance routes moyenne:", round(mean(dist_routes_vals, na.rm = TRUE)), "m\n")
}

parcelles$A2 <- pmin(100, score_air)
cat("A2 (qualité air):", round(mean(parcelles$A2, na.rm = TRUE), 1), "(moy)\n\n")

# ============================================================
# F2 : Fertilité du sol (calcul vectorisé avec purrr)
# ============================================================
cat("Calcul F2 (fertilité)...\n")

# Fonction de score TWI vectorisée
score_twi <- function(twi_val) {
  if (is.na(twi_val)) return(15)
  if (twi_val >= 8 && twi_val <= 14) return(25)  # Optimal
  if (twi_val > 14) return(10)                    # Trop humide
  return(15)                                       # Sec
}

# Calcul vectorisé avec purrr::map_dbl
score_fertilite <- rep(50, nrow(parcelles))

if (!all(is.na(twi_vals))) {
  bonus_twi <- map_dbl(twi_vals, score_twi)
  score_fertilite <- score_fertilite + bonus_twi
  cat("  TWI moyen:", round(mean(twi_vals, na.rm = TRUE), 1), "\n")
}

if (!all(is.na(pente_vals))) {
  bonus_pente <- pmax(0, 25 - pente_vals)
  bonus_pente[is.na(bonus_pente)] <- 12.5
  score_fertilite <- score_fertilite + bonus_pente
  cat("  Pente moyenne:", round(mean(pente_vals, na.rm = TRUE), 1), "°\n")
}

parcelles$F2 <- pmin(100, pmax(0, score_fertilite))
cat("F2 (fertilité):", round(mean(parcelles$F2, na.rm = TRUE), 1), "(moy)\n")

# Sauvegarder
st_write(parcelles, output_path, delete_dsn = TRUE, quiet = TRUE)
cat("\n✓ Familles A/F sauvegardées:", basename(output_path), "\n")
```

```{r ex-6-4-check}
grade_this({
  pass("Familles A/F (Air/Fertilité) calculées et exportées avec succès !")
})
```

---

### Exercice 6.5 : Famille N (Naturalité) + Synthèse — Calcul Optimisé

```{r ex-6-5-setup}
library(sf)
library(terra)
library(purrr)
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
```

```{r ex-6-5, exercise=TRUE, exercise.lines=130, exercise.setup="ex-6-5-setup", exercise.timelimit=600}
# === FAMILLE N (NATURALITÉ) : N1, N2, N3 + SYNTHÈSE ===
# Version optimisée avec extraction batch et purrr/furrr

output_path <- file.path(data_dir, "indicateurs_ecologiques.gpkg")
parcelles <- st_read(output_path, quiet = TRUE)

cat("=== Famille N (Naturalité) — Calcul Optimisé ===\n\n")

# ============================================================
# Fonction d'extraction batch (toutes les parcelles en une fois)
# ============================================================
extract_batch <- function(raster_path, parcelles) {
  if (!file.exists(raster_path)) return(rep(NA, nrow(parcelles)))

  r <- rast(raster_path)
  if (requireNamespace("exactextractr", quietly = TRUE)) {
    exactextractr::exact_extract(r, parcelles, fun = "mean")
  } else {
    terra::extract(r, vect(parcelles), fun = mean, na.rm = TRUE)[, 2]
  }
}

# ============================================================
# N1 : Distance aux infrastructures (extraction batch)
# ============================================================
cat("Calcul N1 (distance infrastructures)...\n")

dist_routes_path <- file.path(data_dir, "distance_routes.tif")
dist_bat_path <- file.path(data_dir, "distance_batiments.tif")

# Extraction batch des distances
dist_routes_vals <- extract_batch(dist_routes_path, parcelles)
dist_bat_vals <- extract_batch(dist_bat_path, parcelles)

# Calcul vectorisé de N1
dist_min <- pmin(
  ifelse(is.na(dist_routes_vals), 1000, dist_routes_vals),
  ifelse(is.na(dist_bat_vals), 1000, dist_bat_vals),
  na.rm = TRUE
)

# Normalisation: 0m = 0, 2000m+ = 100
parcelles$N1 <- pmin(100, pmax(0, dist_min / 20))
cat("N1 (distance infra):", round(mean(parcelles$N1, na.rm = TRUE), 1), "(moy)\n")

# ============================================================
# N2 : Continuité forestière (parallélisé si intersection nécessaire)
# ============================================================
cat("\nCalcul N2 (continuité forestière)...\n")

bd_foret_anciennes_path <- file.path(data_dir, "bd_foret_anciennes.gpkg")
bd_foret_path <- file.path(data_dir, "bd_foret.gpkg")

parcelles$N2 <- 30  # Valeur par défaut

if (file.exists(bd_foret_anciennes_path)) {
  foret_anc <- st_read(bd_foret_anciennes_path, quiet = TRUE) |>
    st_transform(st_crs(parcelles))
  cat("BD Forêt Anciennes chargée:", nrow(foret_anc), "polygones\n")

  # Fonction de calcul N2 pour une parcelle
  calc_N2 <- function(idx, parcelles, foret_anc) {
    geom <- st_geometry(parcelles)[idx]
    surface <- as.numeric(st_area(geom))
    inter <- suppressWarnings(st_intersection(foret_anc, geom))

    if (nrow(inter) > 0) {
      taux_ancien <- as.numeric(sum(st_area(inter))) / surface * 100
      return(60 + min(40, taux_ancien * 0.4))
    }
    30
  }

  # Calcul avec furrr si disponible
  if (requireNamespace("furrr", quietly = TRUE) &&
      requireNamespace("future", quietly = TRUE)) {
    library(furrr)
    library(future)

    plan(multisession, workers = min(4, parallel::detectCores() - 1))
    cat("Mode: PARALLÈLE (", future::nbrOfWorkers(), "workers)\n")

    parcelles$N2 <- future_map_dbl(
      seq_len(nrow(parcelles)),
      ~calc_N2(.x, parcelles, foret_anc),
      .progress = TRUE,
      .options = furrr_options(seed = TRUE)
    )

    plan(sequential)
  } else {
    cat("Mode: SÉQUENTIEL (purrr)\n")
    parcelles$N2 <- map_dbl(seq_len(nrow(parcelles)), ~calc_N2(.x, parcelles, foret_anc))
  }
} else if (file.exists(bd_foret_path) && "T1" %in% names(parcelles)) {
  # Estimation vectorisée basée sur l'âge T1
  parcelles$N2 <- ifelse(parcelles$T1 > 80, 70, ifelse(parcelles$T1 > 50, 50, 30))
}
cat("N2 (continuité):", round(mean(parcelles$N2, na.rm = TRUE), 1), "(moy)\n")

# ============================================================
# N3 : Indice composite de naturalité (vectorisé)
# ============================================================
cat("\nCalcul N3 (naturalité composite)...\n")

# Calcul vectorisé avec gestion des NA
B1_contrib <- if ("B1" %in% names(parcelles)) {
  ifelse(is.na(parcelles$B1), 10, parcelles$B1 * 0.2)
} else {
  10
}

parcelles$N3 <- parcelles$N1 * 0.4 + parcelles$N2 * 0.4 + B1_contrib
cat("N3 (naturalité composite):", round(mean(parcelles$N3, na.rm = TRUE), 1), "(moy)\n")

# Sauvegarder
st_write(parcelles, output_path, delete_dsn = TRUE, quiet = TRUE)

# ============================================================
# SYNTHÈSE FINALE
# ============================================================
cat("\n", strrep("=", 50), "\n", sep = "")
cat("SYNTHÈSE INDICATEURS ÉCOLOGIQUES\n")
cat(strrep("=", 50), "\n\n", sep = "")

cat("Fichier:", basename(output_path), "\n\n")

# Affichage par famille avec purrr::walk
familles <- list(
  "B (Biodiversité)" = c("B1", "B2", "B3"),
  "L (Paysage)" = c("L1", "L2", "L3"),
  "C (Carbone)" = c("C2"),
  "T (Temporel)" = c("T1", "T2"),
  "A/F (Air/Fertilité)" = c("A2", "F2"),
  "N (Naturalité)" = c("N1", "N2", "N3")
)

walk(names(familles), function(fam) {
  cat("FAMILLE", fam, ":\n")
  walk(familles[[fam]], function(ind) {
    if (ind %in% names(parcelles)) {
      cat(sprintf("  - %s: %.1f (moy)\n", ind, mean(parcelles[[ind]], na.rm = TRUE)))
    }
  })
  cat("\n")
})

indicateurs_eco <- unlist(familles)
cat("Parcelles:", nrow(parcelles), "| Indicateurs:",
    sum(indicateurs_eco %in% names(parcelles)), "/", length(indicateurs_eco), "\n")
cat("\n✓ Famille N + Synthèse terminées\n")
```

```{r ex-6-5-check}
grade_this({
  pass("Tous les indicateurs écologiques calculés et exportés avec succès !")
})
```

---

## Quiz final

```{r quiz-final-1}
question("L'indicateur B1 mesure :",
  answer("Le taux de couverture par des zones protégées (ZNIEFF, N2000)", correct = TRUE),
  answer("La biomasse totale"),
  answer("La biodiversité génétique"),
  answer("Le nombre d'espèces"),
  allow_retry = TRUE
)
```

```{r quiz-final-2}
question("Qu'est-ce que la naturalité (N) ?",
  answer("Le degré d'éloignement par rapport à l'état naturel, non perturbé", correct = TRUE),
  answer("La présence d'espèces natives"),
  answer("La productivité naturelle"),
  answer("Le pH naturel du sol"),
  allow_retry = TRUE
)
```

---

## Synthèse

### Indicateurs calculés

| Famille | Code | Indicateur |
|---------|------|------------|
| **B** | B1 | Protection (ZNIEFF, N2000) |
| **B** | B2 | Structure verticale |
| **B** | B3 | Connectivité écologique |
| **L** | L1 | Effet lisière |
| **L** | L2 | Fragmentation |
| **T** | T1 | Âge du peuplement |
| **T** | T2 | Taux de changement |
| **A** | A2 | Qualité air forestier |
| **F** | F2 | Fertilité sol |
| **N** | N1 | Continuité forestière |
| **N** | N2 | Distance perturbations |
| **N** | N3 | Naturalité composite |

### Tutoriel suivant

→ **Tutorial 05 : Calcul Complet et Normalisation** - Assembler les 12 familles et normaliser.
