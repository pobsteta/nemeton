---
title: "Tutorial 07 : LiDAR Avancé — LAScatalog, lasR et BABA"
output:
  learnr::tutorial:
    progressive: true
    allow_skip: true
    language: fr
runtime: shiny_prerendered
description: >
  Traitement LiDAR avancé avec LAScatalog pour gros jeux de données,
  pipelines lasR haute performance, segmentation d'arbres avec lidaRtRee,
  détection des trouées/lisières, et approche BABA (Buffered Area-Based)
  pour cartographie haute résolution des indicateurs nemeton.
---

```{r setup, include=FALSE}
library(learnr)

# Options
knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  message = FALSE
)

# Timeout pour les exercices LiDAR avancés (15 min)
options(tutorial.exercise.timelimit = 900)

# Configuration des timeouts réseau (5 minutes)
NETWORK_TIMEOUT <- 300
options(
  timeout = NETWORK_TIMEOUT,
  HTTPUserAgent = "nemeton-tutorial/1.0"
)

# Configuration httr (connect + request timeout)
if (requireNamespace("httr", quietly = TRUE)) {
  httr::set_config(httr::config(
    connecttimeout = NETWORK_TIMEOUT,
    timeout = NETWORK_TIMEOUT
  ))
}

# Configuration GDAL/curl
Sys.setenv(
  GDAL_HTTP_TIMEOUT = as.character(NETWORK_TIMEOUT),
  GDAL_HTTP_CONNECTTIMEOUT = as.character(NETWORK_TIMEOUT),
  CURL_SSL_BACKEND = "openssl"
)

# Configuration parallélisation (6 cores sur 8 disponibles)
N_CORES <- 6L
if (requireNamespace("future", quietly = TRUE)) {
  future::plan(future::multisession, workers = N_CORES)
}
# Configuration lidR pour LAScatalog
options(lidR.progress = TRUE)
# Configuration lasR (si disponible)
if (requireNamespace("lasR", quietly = TRUE)) {
  options(lasR.threads = N_CORES)
}

# =============================================================================
# DONNÉES DU TUTORIEL
# =============================================================================

# Répertoire des données LiDAR (Tutorial 01)
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
data_dir <- normalizePath(data_dir, mustWork = FALSE)

# Charger les placettes lidaRtRee (96 placettes de 15m, projet Newfor)
# Les données sont dans le dossier vignettes/data du package lidaRtRee
lidartree_data_dir <- system.file("extdata", package = "lidaRtRee")
if (lidartree_data_dir == "") {

  # Fallback: chercher dans vignettes/data si extdata n'existe pas

  lidartree_data_dir <- system.file("vignettes", "data", package = "lidaRtRee")
}

# Fonction helper pour charger les placettes Newfor
load_newfor_plots <- function() {
  # Chercher les fichiers de centres de placettes
  plot_centers_file <- file.path(lidartree_data_dir, "aba.model", "field", "plot_centers.csv")


  if (file.exists(plot_centers_file)) {
    centers <- read.csv(plot_centers_file)
    # Créer des géométries circulaires de 15m de rayon
    if (requireNamespace("sf", quietly = TRUE)) {
      plots_sf <- sf::st_as_sf(centers, coords = c("X", "Y"), crs = 2154)
      plots_sf <- sf::st_buffer(plots_sf, dist = 15)
      return(plots_sf)
    }
  }
  return(NULL)
}
```

## Bienvenue

### Objectifs du tutoriel

Ce tutoriel **avancé** vous guide dans le traitement de **gros jeux de données LiDAR** en utilisant des outils professionnels. Il complète le Tutorial 02 avec des techniques plus sophistiquées.

À la fin de ce tutoriel, vous saurez :

1. **Utiliser LAScatalog** pour traiter des données LiDAR multi-tuiles
2. **Créer des pipelines lasR** optimisés pour la performance
3. **Segmenter des arbres individuels** avec lidaRtRee
4. **Détecter trouées et lisières** forestières
5. **Extraire des métriques de structure** avancées
6. **Appliquer l'approche BABA** pour cartographie haute résolution
7. **Coregistrer des placettes terrain** avec le MNH
8. **Exporter les métriques** pour les indicateurs nemeton

### Comparaison avec Tutorial 02

| Aspect | Tutorial 02 | Tutorial 07 (avancé) |
|--------|-------------|----------------------|
| Package principal | lidR | lidR + lasR + lidaRtRee |
| Traitement | Fichier par fichier | LAScatalog (multi-tuiles) |
| Performance | Standard | Haute performance |
| Résolution sortie | 20-30m | 10m (BABA) |
| Segmentation | Non | Arbres individuels |
| Trouées/lisières | Non | Oui |
| Calibration | Non | Oui (ABA/BABA) |
| RAM requise | 4 GB | 8 GB |
| Durée | 60 min | 90-120 min |

### Prérequis

Ce tutoriel combine les données du **Tutorial 01** et du package **lidaRtRee** :

- **Données LiDAR** : Les 18 dalles LiDAR HD IGN téléchargées dans le Tutorial 01 (42 km²)
- **Placettes terrain** : 28 placettes de 15m de rayon couvertes par le LiDAR (7 clusters)
- **Zone d'étude** : Partie centrale du massif des Quatre Montagnes (Vercors)

> **Note** : Le jeu de données lidaRtRee contient 96 placettes sur une zone plus large. Nous utilisons les 28 placettes couvertes par nos dalles LiDAR.

### Packages utilisés

**CORE :**

- `lidR` >= 4.1.1 : Traitement LiDAR standard
- `lasR` : Pipelines haute performance (r-universe)
- `lidaRtRee` >= 4.0.9 : Fonctions forestières (INRAE GitLab)

**SUPPORT :**

- `terra` : Manipulation rasters
- `sf` : Données vectorielles
- `future` : Parallélisation
- `exactextractr` : Extraction par polygone

### Installation des packages spéciaux

```r
# Installation (à exécuter UNE FOIS avant le tutoriel)

# lidR (CRAN)
install.packages('lidR')

# lasR (r-universe uniquement)
install.packages('lasR', repos = 'https://r-lidar.r-universe.dev')

# lidaRtRee (INRAE GitLab)
remotes::install_gitlab('lidar/lidaRtRee', host = 'forge.inrae.fr')
```

### Quiz d'introduction

```{r quiz-intro, echo=FALSE}
question("Quelle est la principale différence entre lidR et lasR ?",
  answer("lasR est une version payante de lidR"),
  answer("lidR charge les données en R, lasR traite en C++ sans exposer les données à R", correct = TRUE),
  answer("lasR ne peut pas lire les fichiers .laz"),
  answer("lidR est plus rapide que lasR"),
  allow_retry = TRUE,
  random_answer_order = TRUE
)
```

## Section 1 : LAScatalog

### Concept du LAScatalog

Un **LAScatalog** est une structure qui référence plusieurs fichiers LiDAR sans les charger en mémoire. Cela permet de :

- **Traiter de gros jeux de données** qui ne tiennent pas en RAM
- **Paralléliser** le traitement sur plusieurs cœurs
- **Gérer automatiquement les buffers** pour éviter les effets de bord

```
                         LAScatalog

   ┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐     Fichiers LiDAR
   │tile1│ │tile2│ │tile3│ │tile4│     (sur disque)
   └──┬──┘ └──┬──┘ └──┬──┘ └──┬──┘
      │       │       │       │
      └───────┴───────┴───────┘
                  │
                  ▼
         ┌───────────────┐
         │  LAScatalog   │  Métadonnées uniquement
         │  (en mémoire) │  (emprises, CRS, stats)
         └───────────────┘
                  │
                  ▼
   ┌─────────────────────────────┐
   │ Traitement par tuiles       │  Charge une tuile à la fois
   │ avec buffer automatique     │  + buffer pour éviter artefacts
   └─────────────────────────────┘
```

### Exercice 1.1 : Création d'un LAScatalog

Créez un LAScatalog à partir des 18 dalles LiDAR HD téléchargées dans le Tutorial 01.

```{r ex-1-1, exercise=TRUE, exercise.timelimit=120}
library(lidR)
library(sf)

# Répertoire des données (Tutorial 01)
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
data_dir <- normalizePath(data_dir, mustWork = FALSE)

# Lister les 18 dalles LiDAR HD des Quatre Montagnes (recherche récursive)
fichiers_laz <- list.files(
  file.path(data_dir, "lidar_hd"),
  pattern = "\\.laz$",
  full.names = TRUE,
  recursive = TRUE
)

cat("Dalles LiDAR trouvées:", length(fichiers_laz), "/ 18 attendues\n")

# Créer le LAScatalog
ctg <- readLAScatalog(fichiers_laz)

# Afficher les informations
print(ctg)
plot(ctg)
```


### Exercice 1.2 : Configuration des options

Configurez les options du LAScatalog pour un traitement optimisé.

```{r ex-1-2-setup}
library(lidR)
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
data_dir <- normalizePath(data_dir, mustWork = FALSE)
fichiers_laz <- list.files(file.path(data_dir, "lidar_hd"),
                           pattern = "\\.laz$", full.names = TRUE, recursive = TRUE)
if (length(fichiers_laz) > 0) {
  ctg <- readLAScatalog(fichiers_laz)
} else {
  ctg <- NULL
}
```

```{r ex-1-2, exercise=TRUE, exercise.timelimit=60, exercise.setup="ex-1-2-setup"}
# === CONFIGURATION PARALLÉLISATION (6 cores sur 8) ===
library(future)
N_CORES <- 6L
plan(multisession, workers = N_CORES)
set_lidr_threads(N_CORES)

cat("=== Configuration parallèle ===\n")
cat("Cores utilisés:", N_CORES, "/ 8 disponibles\n\n")

# === OPTIONS DE TRAITEMENT PAR TUILES ===
opt_chunk_size(ctg) <- 500      # Taille des tuiles en mètres
opt_chunk_buffer(ctg) <- 30     # Buffer en mètres (évite effets de bord)

# Options de sortie
opt_output_files(ctg) <- ""     # "" = retour en mémoire (petit jeu de données)
                                 # ou template comme "{XLEFT}_{YBOTTOM}"

# Options de parallélisation LAScatalog
opt_progress(ctg) <- TRUE       # Afficher la progression

# Vérifier la configuration
cat("=== Configuration LAScatalog ===\n")
cat("Taille tuiles:", opt_chunk_size(ctg), "m\n")
cat("Buffer:", opt_chunk_buffer(ctg), "m\n")
cat("Threads lidR:", get_lidr_threads(), "\n")

# Afficher le découpage prévu
plot(ctg, chunk = TRUE)
```


### Exercice 1.3 : Visualisation avec placettes de calibration

Affichez le LAScatalog avec les placettes de calibration superposées pour visualiser la couverture.

```{r ex-1-3-setup}
library(lidR)
library(sf)
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
data_dir <- normalizePath(data_dir, mustWork = FALSE)
fichiers_laz <- list.files(file.path(data_dir, "lidar_hd"),
                           pattern = "\\.laz$", full.names = TRUE, recursive = TRUE)
if (length(fichiers_laz) > 0) {
  ctg <- readLAScatalog(fichiers_laz)
} else {
  ctg <- NULL
}

# Charger les placettes Quatre Montagnes de lidaRtRee
if (requireNamespace("lidaRtRee", quietly = TRUE) && !is.null(ctg)) {
  data("quatre_montagnes", package = "lidaRtRee", envir = environment())

  # Utiliser l'emprise réelle du LAScatalog (dynamique)
  ctg_extent <- ext(ctg)

  # Filtrer les placettes couvertes par le LiDAR
  covered <- quatre_montagnes$X >= ctg_extent$xmin &
             quatre_montagnes$X <= ctg_extent$xmax &
             quatre_montagnes$Y >= ctg_extent$ymin &
             quatre_montagnes$Y <= ctg_extent$ymax

  placettes_data <- quatre_montagnes[covered, ]
  placettes_calibration <- sf::st_as_sf(placettes_data, coords = c("X", "Y"), crs = 2154)
  placettes_calibration <- sf::st_buffer(placettes_calibration, dist = 15)  # Rayon 15m
} else {
  placettes_calibration <- NULL
}
```

```{r ex-1-3, exercise=TRUE, exercise.timelimit=60, exercise.setup="ex-1-3-setup"}
library(lidR)
library(sf)

# Vérifier que le catalogue et les placettes sont disponibles
if (is.null(ctg)) {
  cat("Catalogue non disponible. Exécutez d'abord le Tutorial 01.\n")
} else if (is.null(placettes_calibration)) {
  cat("Placettes non disponibles. Installez lidaRtRee:\n")
  cat("remotes::install_gitlab('lidar/lidaRtRee', host = 'forge.inrae.fr')\n")
} else {
  # Afficher le catalogue
  cat("=== LAScatalog ===\n")
  print(ctg)

  cat("\n=== Placettes de calibration ===\n")
  cat("Nombre de placettes:", nrow(placettes_calibration), "\n")
  cat("Rayon des placettes: 15 m (surface ≈ 707 m²)\n")

  # Visualisation : catalogue + placettes
  plot(ctg, main = "LAScatalog avec placettes de calibration")
  plot(st_geometry(placettes_calibration), add = TRUE,
       col = "red", border = "darkred", lwd = 2)

  # Ajouter une légende
  legend("topright",
         legend = c("Dalles LiDAR HD", "Placettes terrain (15m)"),
         fill = c("lightblue", "red"),
         border = c("blue", "darkred"),
         bty = "n")

  cat("\nLes placettes rouges seront utilisées pour:\n")
  cat("- Calibrer les modèles BABA (Section 6)\n")
  cat("- Valider les métriques LiDAR (Section 8)\n")
}
```


### Quiz LAScatalog

```{r quiz-catalog, echo=FALSE}
quiz(
  question("Pourquoi utiliser un buffer dans LAScatalog ?",
    answer("Pour augmenter la taille des fichiers"),
    answer("Pour éviter les artefacts aux bords des tuiles", correct = TRUE),
    answer("Pour accélérer le traitement"),
    answer("Pour réduire la mémoire utilisée"),
    allow_retry = TRUE
  ),
  question("Que signifie opt_chunk_size(ctg) <- 500 ?",
    answer("Limiter à 500 fichiers"),
    answer("Traiter par tuiles de 500 x 500 mètres", correct = TRUE),
    answer("Utiliser 500 MB de RAM"),
    answer("Garder 500 points par m²"),
    allow_retry = TRUE
  )
)
```

## Section 2 : Pipelines lasR

### Introduction à lasR

**lasR** est un package haute performance pour le traitement LiDAR. Contrairement à lidR qui charge les données en R, lasR traite directement en C++ sans exposer les données à l'utilisateur.

**Avantages** :
- Traitement 5-10x plus rapide
- Consommation mémoire réduite
- Pipelines chaînables

**Inconvénient** :
- Moins flexible (pas d'accès direct aux points)

```
                    lidR vs lasR

  lidR:                           lasR:
  ┌──────────┐                    ┌──────────┐
  │ Fichier  │                    │ Fichier  │
  │   .laz   │                    │   .laz   │
  └────┬─────┘                    └────┬─────┘
       │                               │
       ▼                               ▼
  ┌──────────┐                    ┌──────────┐
  │ Charger  │                    │ Pipeline │ (défini en R)
  │ en R     │                    │   C++    │
  └────┬─────┘                    └────┬─────┘
       │                               │
       ▼                               ▼
  ┌──────────┐                    ┌──────────┐
  │data.frame│ (en mémoire)       │ Résultat │ (direct)
  └────┬─────┘                    └──────────┘
       │
       ▼
  ┌──────────┐
  │ Traiter  │
  │ en R     │
  └────┬─────┘
       │
       ▼
  ┌──────────┐
  │ Résultat │
  └──────────┘
```

### Exercice 2.1 : Pipeline basique

Créez un pipeline lasR simple pour générer un MNT.

```{r ex-2-1-setup}
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
# Normaliser le chemin pour lasR (C++ ne gère pas le tilde)
data_dir <- normalizePath(data_dir, mustWork = FALSE)
fichiers_laz <- list.files(file.path(data_dir, "lidar_hd"),
                           pattern = "\\.laz$", full.names = TRUE, recursive = TRUE)
```

```{r ex-2-1, exercise=TRUE, exercise.timelimit=300, exercise.setup="ex-2-1-setup"}
# Vérifier que lasR est disponible
if (!requireNamespace("lasR", quietly = TRUE)) {
  cat("lasR n'est pas installé. Installez-le avec:\n")
  cat("install.packages('lasR', repos = 'https://r-lidar.r-universe.dev')\n")
} else {
  library(lasR)

  # Définir le pipeline
  # 1. Lire les fichiers
  # 2. Trianguler les points sol
  # 3. Rasteriser à 1m de résolution
  
  ofile  <- file.path(data_dir, "mnt_lasr.tif")

  pipeline <- reader_las(filter = "-drop_class 7") +
    triangulate(filter = keep_ground()) +
    rasterize(res = 1, operators = "max", ofile = ofile)

  # Afficher le pipeline
  print(pipeline)

  # Note: L'exécution nécessite des données LiDAR
  ans <- lasR::exec(pipeline, on = fichiers_laz[1])
  
  # On affiche le résultat
  print(ans)
  
  cat("\nPipeline créé avec succès !\n")
  
  terra::plot(ans, col = gray.colors(25,0,1), main = "MNT lasR")
}
```



### Exercice 2.2 : Pipeline complexe MNT + MNH

Créez un pipeline complet qui génère plusieurs produits en une seule passe.

```{r ex-2-2-setup}
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
# Normaliser le chemin pour lasR (C++ ne gère pas le tilde)
data_dir <- normalizePath(data_dir, mustWork = FALSE)
fichiers_laz <- list.files(file.path(data_dir, "lidar_hd"),
                           pattern = "\\.laz$", full.names = TRUE, recursive = TRUE)
```

```{r ex-2-2, exercise=TRUE, exercise.timelimit=1800, exercise.setup="ex-2-2-setup"}
# =============================================================================
# GESTION MÉMOIRE - Important pour les gros jeux de données
# =============================================================================
gc()  # Forcer le garbage collection avant traitement
cat("=== Gestion mémoire ===\n")
cat("Mémoire utilisée avant:", round(sum(gc()[, 2]), 1), "MB\n\n")

N_CORES <- 6L

cat("=== Stratégies de parallélisation lasR ===\n\n")
cat("1. sequential()        - Pas de parallélisation (debug)\n")
cat("2. concurrent_points() - Parallélise les étapes dans un fichier (défaut)\n")
cat("3. concurrent_files()  - Traite plusieurs fichiers en parallèle (RAPIDE)\n")
cat("4. nested()            - Combine les deux (experts)\n\n")
cat("Cores utilisés:", N_CORES, "/ 8 disponibles\n")
cat("Stratégie: concurrent_files() - la plus rapide avec SSD\n\n")

library(lidR)
# On crée le catalogue
if (length(fichiers_laz) > 0) {
  ctg <- readLAScatalog(fichiers_laz)
} else {
  ctg <- NULL
}

# On crée un répertoire résultat des calculs
result <- file.path(data_dir, "result_lasr")
if (!dir.exists(result)) {
  dir.create(result, recursive = TRUE)
}

# Vérifier que lasR est disponible
if (!requireNamespace("lasR", quietly = TRUE)) {
  cat("lasR n'est pas installé. Installez-le avec:\n")
  cat("install.packages('lasR', repos = 'https://r-lidar.r-universe.dev')\n")
} else {
  library(lasR)

  # 1. Créer l'étape de triangulation (référencée plus tard)
  tri <- triangulate(filter = keep_ground())

  # Pipeline lasR complet pour nemeton
  pipeline_complet <- reader_las() +

    # 2. MNT depuis points sol
    tri +
    rasterize(res = 1, operators = "max",
              ofile = file.path(result, "lasr_mnt_lidar_*.tif")) +

    # 3. Normalisation des hauteurs (référence l'étape tri)
    transform_with(tri) +

    # 4. MNH (hauteur max normalisée)
    rasterize(res = 1, operators = "max",
              ofile = file.path(result, "lasr_mnh_lidar_*.tif"))

  # Afficher le pipeline
  print(pipeline_complet)

  # Exécution avec stratégie concurrent_files (la plus rapide)
  # Note: Ne pas utiliser tous les cores pour éviter les problèmes de mémoire
  ans <- lasR::exec(pipeline_complet, on = ctg,
                    ncores = concurrent_files(N_CORES))

  # Affiche le resultat
  print(ans)

  cat("\nAvantage: Une seule lecture des fichiers pour tous les produits !")
  cat("\nStratégie concurrent_files:", N_CORES, "fichiers traités en parallèle\n")

  # =============================================================================
  # FUSION DES TUILES EN RASTER VIRTUEL (VRT)
  # =============================================================================
  cat("\n\n=== Création des rasters virtuels (VRT) ===\n")
  
  library(terra)
  # Lister les tuiles produites pour chaque produit
  mnt_tiles <- list.files(result, pattern = "lasr_mnt_lidar_.*\\.tif$", full.names = TRUE)
  mnh_tiles <- list.files(result, pattern = "lasr_mnh_lidar_.*\\.tif$", full.names = TRUE)
  
  cat("Tuiles MNT:", length(mnt_tiles), "\n")
  cat("Tuiles MNH:", length(mnh_tiles), "\n")

  # Créer les VRT avec terra::vrt()
  # Avantage: pas de duplication de données, lecture à la demande
  if (length(mnt_tiles) > 0) {
    mnt_vrt <- vrt(mnt_tiles, file.path(data_dir, "mnt_complet.vrt"), overwrite = TRUE)
    cat("VRT MNT créé:", file.path(data_dir, "mnt_complet.vrt"), "\n")
    cat("  Dimensions:", nrow(mnt_vrt), "x", ncol(mnt_vrt), "pixels\n")
    cat("  Résolution:", res(mnt_vrt)[1], "m\n")
  }

  if (length(mnh_tiles) > 0) {
    mnh_vrt <- vrt(mnh_tiles, file.path(data_dir, "mnh_complet.vrt"), overwrite = TRUE)
    cat("VRT MNH créé:", file.path(data_dir, "mnh_complet.vrt"), "\n")
  }

  cat("\n=== Avantages du VRT ===\n")
  cat("- Pas de duplication de données (fichier XML léger)\n")
  cat("- Lecture à la demande (seules les tuiles nécessaires sont chargées)\n")
  cat("- Compatible GDAL, QGIS, R (terra, stars)\n")
  cat("- Alternative: terra::merge() pour fusion physique (plus lent, plus lourd)\n")
  
  # Création des tif complet
  cat("\n=== Fusion physique du MNT (optionnel) ===\n")
  mnt_merge <- terra::merge(sprc(mnt_tiles))
  writeRaster(mnt_merge, file.path(data_dir, "mnt_complet.tif"), overwrite = TRUE)
  cat("MNT complet écrit:", file.path(data_dir, "mnt_complet.tif"), "\n")
  
  cat("\n=== Fusion physique du MNH (optionnel) ===\n")
  mnh_merge <- terra::merge(sprc(mnh_tiles))
  writeRaster(mnh_merge, file.path(data_dir, "mnh_complet.tif"), overwrite = TRUE)
  cat("MNH complet écrit:", file.path(data_dir, "mnh_complet.tif"), "\n")
  
  # Visualisation du MNT complet
  if (exists("mnt_vrt")) {
    plot(mnt_vrt, main = "MNT complet (VRT)", col = terrain.colors(50))
  }
}
```


### Quiz lasR

```{r quiz-lasr, echo=FALSE}
quiz(
  question("Quel est l'avantage principal de lasR par rapport à lidR ?",
    answer("Plus de fonctionnalités"),
    answer("Traitement plus rapide et moins de mémoire utilisée", correct = TRUE),
    answer("Interface graphique"),
    answer("Support de plus de formats"),
    allow_retry = TRUE
  ),
  question("Comment chaîne-t-on les opérations dans lasR ?",
    answer("Avec des pipes %>%"),
    answer("Avec l'opérateur +", correct = TRUE),
    answer("Avec des listes"),
    answer("Avec des fonctions imbriquées"),
    allow_retry = TRUE
  )
)
```

## Section 3 : Segmentation d'Arbres Individuels

*Basé sur l'article [Tree segmentation](https://lidar.pages-forge.inrae.fr/lidaRtRee/articles/tree.detection.html) de lidaRtRee*

### Principe

La **segmentation d'arbres individuels** (ITD - Individual Tree Detection) permet d'identifier et caractériser chaque arbre à partir du nuage de points LiDAR. Avec **lasR**, le traitement se fait via un pipeline optimisé qui enchaîne :

1. **Triangulation** : maillage TIN des premiers retours (`triangulate()`)
2. **Rastérisation** : génération du CHM haute résolution (`rasterize()`)
3. **Remplissage des puits** : correction des artefacts du CHM (`pit_fill()`)
4. **Détection des maxima locaux** : identification des cimes (`local_maximum_raster()`)
5. **Croissance de région** : délimitation des houppiers (`region_growing()`)

```
                    Pipeline ITD lasR

  Nuage LiDAR ──► triangulate() ──► rasterize() ──► pit_fill()
  (points)           (TIN)            (CHM)         (CHM lissé)
                                                         │
                                                         ▼
                   region_growing() ◄── local_maximum_raster()
                     (houppiers)            (cimes)
                          │                    │
                          ▼                    ▼
                    crowns_*.tif          seeds_*.gpkg
```

### Exercice 3.1 : Segmentation d'arbres avec lasR

Utilisez lasR pour détecter et segmenter les arbres individuels sur les données LiDAR.


```
==========================================================================
 PROBLÈME DES EFFETS DE BORD
==========================================================================
Sans buffer, les arbres à la frontière entre 2 tuiles sont mal segmentés :

     Tuile A          │         Tuile B
                      │
        ████          │          ████
      ████████   ◄────┼────►   ████████
        ████          │          ████
          │           │           │
       Arbre 1    COUPÉ !     Arbre 2
                  en deux

 Solution : traiter avec un BUFFER qui déborde sur les tuiles voisines

     Tuile A + buffer         Tuile B + buffer
     ┌─────────────────┐     ┌─────────────────┐
     │     ████        │     │        ████     │
     │   ████████      │     │      ████████   │
     │     ████        │     │        ████     │
     │       │    zone │     │ zone    │       │
     │    Arbre 1  buffer    buffer  Arbre 2   │
     └─────────────────┘     └─────────────────┘

 lasR ne garde que les résultats dans la zone SANS buffer (déduplication auto)
```

```{r ex-3-1-setup}
library(terra)
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
# Normaliser le chemin pour lasR (C++ ne gère pas le tilde)
data_dir <- normalizePath(data_dir, mustWork = FALSE)
fichiers_laz <- list.files(file.path(data_dir, "lidar_hd"),
                           pattern = "\\.laz$", full.names = TRUE, recursive = TRUE)
```

```{r ex-3-1, exercise=TRUE, exercise.timelimit=2400, exercise.setup="ex-3-1-setup"}
# =============================================================================
# GESTION MÉMOIRE - Important pour les gros jeux de données
# =============================================================================
gc()  # Forcer le garbage collection avant traitement
cat("=== Gestion mémoire ===\n")
cat("Mémoire utilisée avant:", round(sum(gc()[, 2]), 1), "MB\n\n")

# Limiter l'utilisation mémoire de terra (50% de la RAM disponible)
# terra::terraOptions(memfrac = 0.5)

# Nombre de cores - RÉDUIRE si problèmes de mémoire
# Chaque core charge des données en mémoire
N_CORES <- 4L  # Réduit de 6 à 4 pour économiser la mémoire

cat("=== Segmentation d'arbres avec lasR ===\n\n")

cat("Pipeline ITD (Individual Tree Detection):\n")
cat("1. reader_las()          - Lecture des fichiers LAS/LAZ\n")
cat("2. triangulate(ground)   - Maillage TIN du sol (DTM)\n")
cat("3. rasterize(DTM)        - DTM à 1m de résolution\n")
cat("4. transform_with(DTM)   - Normalisation des hauteurs (Z = hauteur)\n")
cat("5. triangulate(first)    - Maillage TIN des premiers retours\n")
cat("6. rasterize(CHM)        - CHM à 0.5m de résolution\n")
cat("7. pit_fill()            - Remplissage des trous\n")
cat("8. local_maximum_raster()- Détection des cimes\n")
cat("9. region_growing()      - Segmentation des houppiers\n\n")

cat("Cores utilisés:", N_CORES, "(réduit pour économiser la mémoire)\n")
cat("Stratégie: concurrent_files()\n\n")

library(lidR)
# On crée le catalogue
if (length(fichiers_laz) > 0) {
  ctg <- readLAScatalog(fichiers_laz)
} else {
  ctg <- NULL
}

# On crée un répertoire résultat des calculs
result_itd <- file.path(data_dir, "result_itd")
if (!dir.exists(result_itd)) {
  dir.create(result_itd, recursive = TRUE)
}

# Vérifier que lasR est disponible
if (!requireNamespace("lasR", quietly = TRUE)) {
  cat("lasR n'est pas installé. Installez-le avec:\n")
  cat("install.packages('lasR', repos = 'https://r-lidar.r-universe.dev')\n")
}

if (length(fichiers_laz) == 0) {
  cat("Données LiDAR non trouvées. Exécutez d'abord le Tutorial 01.\n")
} else {
  library(lasR)

  # ==========================================================================
  # PIPELINE ITD lasR COMPLET AVEC NORMALISATION
  # ==========================================================================
  # IMPORTANT: Les données LiDAR brutes ont Z = altitude (ex: 1200m)

  # Pour la détection d'arbres, on a besoin de Z = hauteur (ex: 25m)
  # Solution: créer un DTM puis normaliser avec transform_with()

  # 1. Triangulation du sol pour créer le DTM
  dtm_tri <- triangulate(filter = keep_ground())

  # 2. Rasteriser le DTM à 1m de résolution
  dtm <- lasR::rasterize(1, dtm_tri,
                         ofile = file.path(result_itd, "dtm_*.tif"))

  # 3. Normaliser les hauteurs : Z_nouveau = Z_original - DTM
  # On utilise la triangulation (pas le raster) pour une interpolation exacte
  # Après cette étape, Z représente la hauteur par rapport au sol
  normalize <- transform_with(dtm_tri)

  # 4. Triangulation des premiers retours (sur données normalisées)
  chm_tri <- triangulate(filter = keep_first())

  # 5. Créer le CHM à 0.5m de résolution
  chm <- lasR::rasterize(0.5, chm_tri,
                         ofile = file.path(result_itd, "chm_*.tif"))

  # 6. Remplissage des puits dans le CHM
  chm_filled <- pit_fill(chm,
                         ofile = file.path(result_itd, "c_filled_*.tif"))

  # 7. Détection des maxima locaux (cimes des arbres)
  # Fenêtre de 3m - ajuster selon la densité du peuplement
  # Hauteur minimum 5m (filtre les arbustes)
  seeds <- local_maximum_raster(chm_filled, ws = 3, min_height = 5,
                                ofile = file.path(result_itd, "seeds_*.gpkg"))

  # 8. Segmentation par croissance de région
  tree <- region_growing(chm_filled, seeds,
                         ofile = file.path(result_itd, "crowns_*.tif"))

  # Pipeline ITD complet avec normalisation
  pipeline_itd <- reader_las() +
    dtm_tri +      # Triangulation sol
    dtm +          # Raster DTM
    normalize +    # Normalisation Z = hauteur
    chm_tri +      # Triangulation premiers retours
    chm +          # Raster CHM
    chm_filled +   # CHM sans trous
    seeds +        # Cimes détectées
    tree           # Houppiers segmentés

  # Afficher le pipeline
  print(pipeline_itd)

  # ==========================================================================
  # GESTION DES EFFETS DE BORD (buffer)
  # ==========================================================================
  # Problème : les arbres à cheval sur 2 tuiles sont mal segmentés
  # Solution : traiter chaque tuile avec un buffer, puis ne garder que
  #            les résultats dans la zone centrale
  #
  # Buffer recommandé : diamètre max des houppiers (15-30m en forêt tempérée)
  BUFFER_SIZE <- 20  # mètres

  # Exécution avec stratégie concurrent_files et buffer
  cat("\n=== Exécution sur", length(fichiers_laz), "dalles LiDAR ===\n")
  cat("Stratégie: concurrent_files(", N_CORES, ")\n")
  cat("Buffer:", BUFFER_SIZE, "m (évite les effets de bord)\n\n")

  ans <- lasR::exec(pipeline_itd, on = ctg,
                    buffer = BUFFER_SIZE,
                    ncores = concurrent_files(N_CORES))

  # Affiche le resultat
  print(ans)

  cat("\nAvantage: Une seule lecture des fichiers pour tous les produits ITD !")
  cat("\nStratégie concurrent_files:", N_CORES, "fichiers traités en parallèle\n")

  cat("\n=== Fichiers générés dans result_itd/ ===\n")
  cat("- dtm_*.tif : tuiles DTM (altitude du sol)\n")
  cat("- chm_*.tif : tuiles CHM (hauteur de canopée)\n")
  cat("- c_filled_*.tif : tuiles CHM sans trous\n")
  cat("- crowns_*.tif : tuiles de segmentation\n")
  cat("- seeds_*.gpkg : cimes détectées par tuile\n")
}
```

### Exercice 3.2 : Fusion VRT et visualisation des résultats

Après l'exécution du pipeline ITD, fusionnez les tuiles en rasters virtuels (VRT)
et visualisez les résultats sur une zone de 100m × 100m.

```{r ex-3-2-setup}
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
data_dir <- normalizePath(data_dir, mustWork = FALSE)
```

```{r ex-3-2, exercise=TRUE, exercise.timelimit=300, exercise.setup="ex-3-2-setup"}
library(terra)
library(sf)

# ==========================================================================
# FUSION DES TUILES EN RASTER VIRTUEL (VRT)
# ==========================================================================
cat("=== Création des rasters virtuels (VRT) ===\n\n")

result_itd <- file.path(data_dir, "result_itd")

dtm_tiles <- list.files(result_itd, pattern = "^dtm_.*\\.tif$", full.names = TRUE)
chm_tiles <- list.files(result_itd, pattern = "^chm_.*\\.tif$", full.names = TRUE)
c_filled_tiles <- list.files(result_itd, pattern = "^c_filled_.*\\.tif$", full.names = TRUE)
crown_tiles <- list.files(result_itd, pattern = "^crowns_.*\\.tif$", full.names = TRUE)
seed_files <- list.files(result_itd, pattern = "^seeds_.*\\.gpkg$", full.names = TRUE)

cat("Tuiles trouvées:\n")
cat("- DTM:", length(dtm_tiles), "\n")
cat("- CHM:", length(chm_tiles), "\n")
cat("- CHM filled:", length(c_filled_tiles), "\n")
cat("- Crowns:", length(crown_tiles), "\n")
cat("- Seeds:", length(seed_files), "\n\n")

if (length(chm_tiles) == 0) {
  cat("Aucune tuile trouvée. Exécutez d'abord l'exercice 3.1.\n")
} else {
  # Créer les VRT avec terra::vrt()
  dtm_vrt <- vrt(dtm_tiles, file.path(data_dir, "dtm_complet.vrt"), overwrite = TRUE)
  cat("VRT DTM créé:", file.path(data_dir, "dtm_complet.vrt"), "\n")
  cat("  Dimensions:", nrow(dtm_vrt), "x", ncol(dtm_vrt), "pixels\n")
  cat("  Résolution:", res(dtm_vrt)[1], "m\n")

  chm_vrt <- vrt(chm_tiles, file.path(data_dir, "chm_complet.vrt"), overwrite = TRUE)
  cat("VRT CHM créé:", file.path(data_dir, "chm_complet.vrt"), "\n")
  cat("  Dimensions:", nrow(chm_vrt), "x", ncol(chm_vrt), "pixels\n")
  cat("  Résolution:", res(chm_vrt)[1], "m\n")

  c_filled_vrt <- vrt(c_filled_tiles, file.path(data_dir, "c_filled_complet.vrt"), overwrite = TRUE)
  cat("VRT CHM filled créé:", file.path(data_dir, "c_filled_complet.vrt"), "\n")

  crowns_vrt <- vrt(crown_tiles, file.path(data_dir, "crowns_complet.vrt"), overwrite = TRUE)
  cat("VRT Crowns créé:", file.path(data_dir, "crowns_complet.vrt"), "\n")

  # Fusionner les seeds (points) en un seul fichier
  seeds_list <- lapply(seed_files, sf::st_read, quiet = TRUE)
  seeds_all <- do.call(rbind, seeds_list)
  sf::st_write(seeds_all, file.path(data_dir, "seeds_complet.gpkg"),
               delete_dsn = TRUE, quiet = TRUE)
  cat("Seeds fusionnés:", nrow(seeds_all), "arbres détectés\n")

  cat("\n=== Avantages du VRT ===\n")
  cat("- Pas de duplication de données (fichier XML léger)\n")
  cat("- Lecture à la demande (seules les tuiles nécessaires sont chargées)\n")
  cat("- Compatible GDAL, QGIS, R (terra, stars)\n")

  # ==========================================================================
  # STATISTIQUES DU PEUPLEMENT
  # ==========================================================================
  cat("\n=== Statistiques du peuplement ===\n")
  cat("Nombre d'arbres:", nrow(seeds_all), "\n")
  cat("Hauteur moyenne:", round(mean(seeds_all$Z, na.rm = TRUE), 1), "m\n")
  cat("Hauteur max:", round(max(seeds_all$Z, na.rm = TRUE), 1), "m\n")
  cat("Hauteur min:", round(min(seeds_all$Z, na.rm = TRUE), 1), "m\n")

  # ==========================================================================
  # FUSION PHYSIQUE (optionnel - pour export)
  # ==========================================================================
  cat("\n=== Fusion physique des rasters ===\n")
  dtm_merge <- terra::merge(sprc(dtm_tiles))
  writeRaster(dtm_merge, file.path(data_dir, "dtm_complet.tif"), overwrite = TRUE)
  cat("DTM complet:", file.path(data_dir, "dtm_complet.tif"), "\n")

  chm_merge <- terra::merge(sprc(chm_tiles))
  writeRaster(chm_merge, file.path(data_dir, "chm_complet.tif"), overwrite = TRUE)
  cat("CHM complet:", file.path(data_dir, "chm_complet.tif"), "\n")

  crown_merge <- terra::merge(sprc(crown_tiles))
  writeRaster(crown_merge, file.path(data_dir, "crown_complet.tif"), overwrite = TRUE)
  cat("Crowns complet:", file.path(data_dir, "crown_complet.tif"), "\n")

  # ==========================================================================
  # VISUALISATION : ZOOM 100m x 100m CENTRÉ (2x2 graphiques)
  # ==========================================================================
  col_elev <- grDevices::colorRampPalette(c("darkgreen", "yellow", "brown", "white"))(25)
  col_height <- grDevices::colorRampPalette(c("blue", "cyan2", "yellow", "red"))(25)
  col_crowns <- grDevices::colorRampPalette(c("purple", "blue", "cyan2", "yellow", "red", "green"))(50)

  # Calculer le centre de l'emprise
  e <- terra::ext(chm_vrt)
  center_x <- (e$xmin + e$xmax) / 2
  center_y <- (e$ymin + e$ymax) / 2

  # Créer une emprise de 100m x 100m centrée
  zoom_ext <- terra::ext(
    center_x - 50, center_x + 50,
    center_y - 50, center_y + 50
  )

  # Cropper les rasters sur la zone de zoom
  dtm_zoom <- terra::crop(dtm_vrt, zoom_ext)
  chm_zoom <- terra::crop(chm_vrt, zoom_ext)
  chm_filled_zoom <- terra::crop(c_filled_vrt, zoom_ext)
  crowns_zoom <- terra::crop(crowns_vrt, zoom_ext)

  # Filtrer les cimes dans l'emprise de zoom (utiliser bbox du raster croppé)
  seeds_zoom <- sf::st_crop(seeds_all, sf::st_bbox(chm_zoom))

  cat("\n=== Visualisation : zoom 100m x 100m centré ===\n")
  cat("Centre:", round(center_x), ",", round(center_y), "\n")
  cat("Arbres dans la zone:", nrow(seeds_zoom), "\n\n")

  # Affichage 2x2 : DTM + CHM en haut, CHM filled + Crowns en bas
  par(mfrow = c(2, 2), mar = c(2, 2, 3, 4))

  # Ligne 1 : DTM et CHM
  plot(dtm_zoom, main = "DTM - Altitude sol (1m)", col = col_elev)
  plot(chm_zoom, main = "CHM - Hauteur canopée (0.5m)", col = col_height)

  # Ligne 2 : CHM filled et Houppiers
  plot(chm_filled_zoom, main = "CHM filled (0.5m)", col = col_height)
  plot(crowns_zoom %% 8, main = "Houppiers + cimes",
       col = col_crowns[sample.int(50, 1000, TRUE)], legend = FALSE)
  # Ajouter les cimes des arbres
  if (nrow(seeds_zoom) > 0) {
    plot(sf::st_geometry(seeds_zoom), add = TRUE, pch = 3, col = "white", cex = 0.8)
  }

  # Nettoyage mémoire
  invisible(gc())
  cat("=== Mémoire libérée ===\n")
}
```

### Exercice 3.3 : Extraction des métriques d'arbres (parallélisé par tuiles)

Cet exercice traite chaque tuile en parallèle pour calculer les métriques
d'arbres équivalentes à `tree_extraction()` de lidaRtRee.

**Avantage** : Traiter les tuiles individuellement est beaucoup plus rapide
que charger le VRT complet, car :
- Chaque tuile est plus petite → vectorisation rapide
- Parallélisation sur plusieurs tuiles simultanément
- Moins de mémoire utilisée

```{r ex-3-3-setup}
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
data_dir <- normalizePath(data_dir, mustWork = FALSE)
result_itd <- file.path(data_dir, "result_itd")
```

```{r ex-3-3, exercise=TRUE, exercise.timelimit=2400, exercise.setup="ex-3-3-setup"}
library(terra)
library(sf)

# ==========================================================================
# LISTER LES TUILES GÉNÉRÉES PAR L'EXERCICE 3.1
# ==========================================================================
cat("=== Recherche des tuiles ===\n\n")

chm_tiles <- list.files(result_itd, pattern = "^c_filled_.*\\.tif$", full.names = TRUE)
crown_tiles <- list.files(result_itd, pattern = "^crowns_.*\\.tif$", full.names = TRUE)
seed_files <- list.files(result_itd, pattern = "^seeds_.*\\.gpkg$", full.names = TRUE)

cat("Tuiles CHM filled:", length(chm_tiles), "\n")
cat("Tuiles Crowns:", length(crown_tiles), "\n")
cat("Fichiers Seeds:", length(seed_files), "\n\n")

if (length(crown_tiles) == 0) {
  cat("Aucune tuile trouvée. Exécutez d'abord l'exercice 3.1.\n")
} else {

  # ==========================================================================
  # FONCTION DE TRAITEMENT D'UNE TUILE
  # ==========================================================================
  # Cette fonction traite une tuile et retourne les métriques des arbres

  process_tile <- function(i, chm_tiles, crown_tiles, seed_files) {
    # Charger les données de la tuile
    chm <- terra::rast(chm_tiles[i])
    crowns <- terra::rast(crown_tiles[i])
    seeds <- sf::st_read(seed_files[i], quiet = TRUE)

    if (nrow(seeds) == 0) return(NULL)

    pixel_area <- terra::res(chm)[1] * terra::res(chm)[2]

    # 1. Vectoriser les houppiers de cette tuile
    crown_polys <- terra::as.polygons(crowns)
    crown_sf <- sf::st_as_sf(crown_polys)
    names(crown_sf)[1] <- "id"

    if (nrow(crown_sf) == 0) return(NULL)

    # 2. Calculer surface et volume
    if (requireNamespace("exactextractr", quietly = TRUE)) {
      zonal_stats <- exactextractr::exact_extract(chm, crown_sf,
                                                   fun = c("count", "sum"),
                                                   progress = FALSE)
      crown_sf$surface <- zonal_stats$count * pixel_area
      crown_sf$volume <- zonal_stats$sum * pixel_area
    } else {
      chm_vals <- terra::values(chm)[, 1]
      crown_vals <- terra::values(crowns)[, 1]
      valid <- !is.na(crown_vals) & crown_vals > 0 & !is.na(chm_vals)

      surf_table <- table(crown_vals[valid])
      surf_df <- data.frame(id = as.integer(names(surf_table)),
                            surface = as.numeric(surf_table) * pixel_area)
      vol_agg <- aggregate(chm_vals[valid], by = list(id = crown_vals[valid]), FUN = sum)
      vol_df <- data.frame(id = vol_agg$id, volume = vol_agg$x * pixel_area)

      crown_sf <- merge(crown_sf, surf_df, by = "id", all.x = TRUE)
      crown_sf <- merge(crown_sf, vol_df, by = "id", all.x = TRUE)
    }

    # 3. Associer les seeds aux segments
    # Note: les seeds sont des POINT Z, la hauteur est dans la géométrie
    coords <- sf::st_coordinates(seeds)
    seeds_vect <- terra::vect(seeds)
    ids_extracted <- terra::extract(crowns, seeds_vect)

    metrics <- data.frame(
      id = ids_extracted[, 2],
      x = coords[, "X"],
      y = coords[, "Y"],
      height = coords[, "Z"]
    )

    # 4. Fusionner avec surface et volume
    crown_data <- sf::st_drop_geometry(crown_sf[, c("id", "surface", "volume")])
    metrics <- merge(metrics, crown_data, by = "id", all.x = TRUE)

    # 5. Ajouter géométrie WKT
    bbox_max <- max(abs(sf::st_bbox(crown_sf)))
    n_digits <- ceiling(log10(bbox_max)) + 2
    crown_sf$crown_geom <- sf::st_as_text(sf::st_geometry(crown_sf), digits = n_digits)

    metrics <- merge(metrics,
                     sf::st_drop_geometry(crown_sf[, c("id", "crown_geom")]),
                     by = "id", all.x = TRUE)

    # Convertir en sf
    sf::st_as_sf(metrics, coords = c("x", "y"), crs = terra::crs(chm))
  }

  # ==========================================================================
  # TRAITEMENT PARALLÈLE DES TUILES
  # ==========================================================================
  cat("=== Traitement des tuiles ===\n")
  t0 <- Sys.time()

  n_tiles <- length(crown_tiles)

  if (requireNamespace("future.apply", quietly = TRUE) && n_tiles > 1) {
    # Traitement parallèle
    N_WORKERS <- min(4, n_tiles)
    future::plan(future::multisession, workers = N_WORKERS)

    cat("Méthode: future.apply (", N_WORKERS, " workers)\n", sep = "")
    cat("Traitement de", n_tiles, "tuiles en parallèle...\n\n")

    results <- future.apply::future_lapply(
      seq_len(n_tiles),
      function(i) process_tile(i, chm_tiles, crown_tiles, seed_files),
      future.seed = TRUE
    )

    future::plan(future::sequential)

  } else {
    # Traitement séquentiel
    cat("Méthode: séquentielle\n")
    cat("Traitement de", n_tiles, "tuiles...\n\n")

    results <- lapply(
      seq_len(n_tiles),
      function(i) {
        cat("  Tuile", i, "/", n_tiles, "\r")
        process_tile(i, chm_tiles, crown_tiles, seed_files)
      }
    )
  }

  t1 <- Sys.time()

  # ==========================================================================
  # FUSION DES RÉSULTATS
  # ==========================================================================
  cat("\n=== Fusion des résultats ===\n")

  # Supprimer les résultats NULL
  results <- results[!sapply(results, is.null)]

  if (length(results) > 0) {
    trees_all <- do.call(rbind, results)

    cat("Temps total:", round(difftime(t1, t0, units = "secs"), 1), "secondes\n")
    cat("Tuiles traitées:", length(results), "/", n_tiles, "\n\n")

    # Sauvegarder
    output_file <- file.path(data_dir, "tree_metrics_complet.gpkg")
    sf::st_write(trees_all, output_file, delete_dsn = TRUE, quiet = TRUE)
    cat("Fichier:", output_file, "\n\n")

    # ==========================================================================
    # RÉSULTATS
    # ==========================================================================
    cat("=== Résultats : Métriques des arbres ===\n")
    cat("Nombre d'arbres:", nrow(trees_all), "\n")
    cat("Hauteur moyenne:", round(mean(trees_all$height, na.rm = TRUE), 1), "m\n")
    cat("Hauteur max:", round(max(trees_all$height, na.rm = TRUE), 1), "m\n")
    cat("Surface moyenne houppier:", round(mean(trees_all$surface, na.rm = TRUE), 1), "m²\n")
    cat("Volume moyen houppier:", round(mean(trees_all$volume, na.rm = TRUE), 1), "m³\n")

    cat("\n=== Premiers arbres ===\n")
    print(head(sf::st_drop_geometry(trees_all[, c("id", "height", "surface", "volume")])))

    cat("\n=== Avantages du traitement par tuiles ===\n")
    cat("- Parallélisation efficace (", N_WORKERS, " tuiles simultanées)\n", sep = "")
    cat("- Mémoire réduite (une tuile à la fois par worker)\n")
    cat("- Scalable : fonctionne avec des centaines de tuiles\n")
  } else {
    cat("Aucun arbre détecté.\n")
  }
}
```

### Quiz Segmentation

```{r quiz-segmentation, echo=FALSE}
quiz(
  question("Quel paramètre contrôle la hauteur minimale des arbres détectés ?",
    answer("sigma"),
    answer("nl_size"),
    answer("hmin", correct = TRUE),
    answer("crown_prop"),
    allow_retry = TRUE
  ),
  question("À quoi sert le filtre médian (nl_filter) ?",
    answer("Accélérer le traitement"),
    answer("Réduire le bruit du MNH avant détection", correct = TRUE),
    answer("Augmenter la résolution"),
    answer("Convertir les coordonnées"),
    allow_retry = TRUE
  ),
  question("Que contient la sortie de tree_extraction() ?",
    answer("Un raster de hauteurs"),
    answer("Un nuage de points"),
    answer("Un objet sf avec les attributs de chaque arbre", correct = TRUE),
    answer("Une liste de fichiers"),
    allow_retry = TRUE
  )
)
```

## Section 4 : Trouées et Lisières

*Basé sur l'article [Gaps and edges detection](https://lidar.pages-forge.inrae.fr/lidaRtRee/articles/gaps.edges.detection.html) de lidaRtRee*

### Principe

Les **trouées** (gaps) et **lisières** (edges) sont des éléments clés de la structure forestière horizontale :

- **Trouées** : Zones ouvertes dans la canopée où la végétation est basse
- **Lisières** : Interfaces entre zones forestières et non-forestières

La fonction `gap_detection()` de lidaRtRee utilise deux critères :

1. **Critère de hauteur** : hauteur de végétation < seuil (ex: 1 m)
2. **Critère de distance** : distance à la végétation environnante > ratio × hauteur végétation

```
            Critères de détection des trouées

  Coupe transversale:
                    ▲ hauteur végétation
      ████          │          ████
      ████          │          ████
      ████    ◄─────┼─────►    ████
      ████    distance à la    ████
      ████    végétation       ████
  ────────────────────────────────────
             TROUÉE

  Si distance > ratio × hauteur → TROUÉE
  Sinon → Juste une zone basse (pas une vraie trouée)
```

### Exercice 4.1 : Détection des trouées sur le catalogue (parallélisé)

Détectez les trouées sur l'ensemble du catalogue LiDAR en utilisant le CHM généré
à la section 3, avec traitement parallélisé par tuile.

```{r ex-4-1-setup}
library(lidaRtRee)
library(terra)
library(sf)
library(future)
library(future.apply)

# Répertoire des données
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
data_dir <- normalizePath(data_dir, mustWork = FALSE)

# Lister les tuiles CHM filled (générées en section 3)
chm_tiles <- list.files(file.path(data_dir, "result_itd"),
                        pattern = "^c_filled_.*\\.tif$",
                        full.names = TRUE)
```

```{r ex-4-1, exercise=TRUE, exercise.timelimit=10000, exercise.setup="ex-4-1-setup"}
library(lidaRtRee)
library(terra)
library(sf)
library(future)
library(future.apply)

cat("=== Détection des trouées sur le catalogue ===\n\n")
cat("Tuiles CHM à traiter:", length(chm_tiles), "\n\n")

# Configuration parallélisation
plan(multisession, workers = 4)

# Paramètres de détection
GAP_MAX_HEIGHT <- 1      # Hauteur max pour être une trouée (m)
GAP_RATIO <- 2           # Distance > ratio × hauteur voisine
MIN_GAP_SURFACE <- 50    # Surface minimum (m²)

# Répertoire pour les masques de trouées (pour réutilisation en 4.2)
gap_mask_dir <- file.path(data_dir, "result_gaps")
dir.create(gap_mask_dir, showWarnings = FALSE, recursive = TRUE)

# Fonction de traitement par tuile
process_gaps_tile <- function(chm_path, tile_id, output_dir) {
  tile_name <- tools::file_path_sans_ext(basename(chm_path))
  mask_file <- file.path(output_dir, paste0("gap_mask_", tile_name, ".tif"))
  gpkg_file <- file.path(output_dir, paste0("gaps_", tile_name, ".gpkg"))

  # Si le masque existe déjà, recharger les données existantes
  if (file.exists(mask_file)) {
    gap_sf <- NULL
    if (file.exists(gpkg_file)) {
      gap_sf <- tryCatch(
        sf::st_read(gpkg_file, quiet = TRUE),
        error = function(e) NULL
      )
    }
    return(list(sf = gap_sf, mask_file = mask_file, skipped = TRUE))
  }

  # Charger le CHM
  chm <- terra::rast(chm_path)

  # Nettoyer les valeurs
  chm[is.na(chm)] <- 0
  chm[chm < 0] <- 0

  # Détection des trouées
  gaps <- gap_detection(
    chm,
    ratio = GAP_RATIO,
    gap_max_height = GAP_MAX_HEIGHT,
    min_gap_surface = MIN_GAP_SURFACE,
    gap_reconstruct = TRUE
  )

  # Sauvegarder le masque binaire des trouées (pour 4.2)
  gap_binary <- gaps$gap_id > 0
  terra::writeRaster(gap_binary, mask_file, overwrite = TRUE)

  # Vectoriser les trouées (gap_id > 0)
  gap_mask <- gaps$gap_id
  gap_mask[gap_mask == 0] <- NA

  if (all(is.na(values(gap_mask)))) {
    return(list(sf = NULL, mask_file = mask_file, skipped = FALSE))
  }

  # Convertir en polygones
  gap_polys <- terra::as.polygons(gap_mask, dissolve = TRUE)
  gap_sf <- sf::st_as_sf(gap_polys)
  names(gap_sf)[1] <- "gap_id"

  # Ajouter les attributs
  gap_sf$tile_id <- tile_id
  gap_sf$area_m2 <- as.numeric(sf::st_area(gap_sf))

  # Décaler les IDs pour éviter les doublons entre tuiles
  gap_sf$gap_id <- gap_sf$gap_id + (tile_id - 1) * 10000

  # Sauvegarder les polygones pour reprise ultérieure
  sf::st_write(gap_sf, gpkg_file, delete_dsn = TRUE, quiet = TRUE)

  list(sf = gap_sf, mask_file = mask_file, skipped = FALSE)
}

# Traitement parallèle
cat("Traitement parallèle en cours...\n")
start_time <- Sys.time()

results <- future_lapply(seq_along(chm_tiles), function(i) {
  process_gaps_tile(chm_tiles[i], i, gap_mask_dir)
}, future.seed = TRUE)

elapsed <- as.numeric(difftime(Sys.time(), start_time, units = "secs"))

# Extraire les SF et les fichiers de masque
sf_list <- lapply(results, `[[`, "sf")
sf_list <- sf_list[!sapply(sf_list, is.null)]
mask_files <- sapply(results, `[[`, "mask_file")
skipped <- sapply(results, `[[`, "skipped")

# Filtrer les fichiers de masque existants
mask_files_exist <- mask_files[file.exists(mask_files)]

# Créer le VRT des masques (pour réutilisation en 4.2)
# Utiliser normalizePath pour résoudre les chemins (évite problèmes avec ~)
gap_mask_vrt <- normalizePath(file.path(data_dir, "gap_mask_complet.vrt"), mustWork = FALSE)
if (length(mask_files_exist) > 0) {
  mask_files_normalized <- normalizePath(mask_files_exist)
  terra::vrt(mask_files_normalized, gap_mask_vrt, overwrite = TRUE)
  cat("VRT créé:", gap_mask_vrt, "\n")
} else {
  cat("Aucun fichier de masque trouvé, VRT non créé\n")
}

cat("\n=== Résultats ===\n")
cat("Temps de traitement:", round(elapsed, 1), "s\n")
cat("Tuiles totales:", length(chm_tiles), "\n")
cat("Tuiles sautées (déjà traitées):", sum(skipped), "\n")
cat("Tuiles nouvellement traitées:", sum(!skipped), "\n")
cat("Fichiers de masque existants:", length(mask_files_exist), "\n")
cat("Tuiles avec trouées:", length(sf_list), "\n")

# Sauvegarder les polygones par tuile pour l'exercice 4.2
gaps_by_tile <- file.path(data_dir, "result_gaps", "gaps_by_tile.rds")
saveRDS(sf_list, gaps_by_tile)
cat("Polygones par tuile sauvegardés:", gaps_by_tile, "\n")

plan(sequential)
```

### Exercice 4.2 : Fusion des polygones de trouées

Fusionnez les polygones de trouées détectés par tuile en un seul fichier
et analysez la distribution des surfaces.

```{r ex-4-2-setup}
library(sf)

# Répertoire des données
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
data_dir <- normalizePath(data_dir, mustWork = FALSE)

# Charger les polygones par tuile (générés en 4.1)
gaps_by_tile <- file.path(data_dir, "result_gaps", "gaps_by_tile.rds")
sf_list <- readRDS(gaps_by_tile)
```

```{r ex-4-2, exercise=TRUE, exercise.timelimit=120, exercise.setup="ex-4-2-setup"}
library(sf)

cat("=== Fusion des polygones de trouées ===\n\n")
cat("Tuiles à fusionner:", length(sf_list), "\n\n")

# Fusionner les polygones de trouées
if (length(sf_list) > 0) {
  gaps_all <- do.call(rbind, sf_list)

  cat("--- STATISTIQUES ---\n")
  cat("Trouées détectées:", nrow(gaps_all), "\n")
  cat("Surface totale:", round(sum(gaps_all$area_m2) / 10000, 2), "ha\n")
  cat("Surface moyenne:", round(mean(gaps_all$area_m2), 1), "m²\n")
  cat("Surface médiane:", round(median(gaps_all$area_m2), 1), "m²\n")
  cat("Surface max:", round(max(gaps_all$area_m2), 1), "m²\n")

  # Sauvegarder en gpkg
  output_file <- file.path(data_dir, "gaps_complet.gpkg")
  sf::st_write(gaps_all, output_file, delete_dsn = TRUE, quiet = TRUE)
  cat("\nSauvegardé:", output_file, "\n")

  # Distribution par classe de surface
  classes <- c(0, 50, 100, 500, 2000, Inf)
  gaps_all$classe <- cut(gaps_all$area_m2, breaks = classes,
                          labels = c("<50", "50-100", "100-500", "500-2000", ">2000"))
  cat("\n--- DISTRIBUTION PAR CLASSE DE SURFACE ---\n")
  print(table(gaps_all$classe))

  # Visualisation
  par(mfrow = c(1, 1))
  plot(sf::st_geometry(gaps_all), col = "forestgreen",
       main = paste("Trouées détectées (n =", nrow(gaps_all), ")"), border = NA)
} else {
  cat("Aucune trouée détectée.\n")
}
```

### Exercice 4.3 : Détection des lisières sur le catalogue (parallélisé)

Détectez les lisières forestières sur l'ensemble du catalogue en réutilisant
les masques de trouées générés en 4.1, avec traitement parallélisé par tuile.

```{r ex-4-3-setup}
library(lidaRtRee)
library(terra)
library(sf)
library(future)
library(future.apply)

# Répertoire des données
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
data_dir <- normalizePath(data_dir, mustWork = FALSE)

# Lister les tuiles de masques de trouées (générées en 4.1)
gap_mask_tiles <- list.files(file.path(data_dir, "result_gaps"),
                              pattern = "^gap_mask_.*\\.tif$",
                              full.names = TRUE)
```

```{r ex-4-3, exercise=TRUE, exercise.timelimit=3000, exercise.setup="ex-4-3-setup"}
library(lidaRtRee)
library(terra)
library(sf)
library(future)
library(future.apply)

cat("=== Détection des lisières sur le catalogue ===\n\n")
cat("Réutilisation des masques de trouées de l'exercice 4.1\n")
cat("Tuiles de masques à traiter:", length(gap_mask_tiles), "\n\n")

# Configuration parallélisation
plan(multisession, workers = 4)

# Fonction de traitement par tuile
process_edges_tile <- function(mask_path, tile_id) {
  # Charger le masque de trouées (généré en 4.1)
  gap_mask <- terra::rast(mask_path)

  # Détection des lisières (internes = côté forêt)
  edges <- edge_detection(gap_mask, inside = TRUE)

  # Statistiques pour cette tuile
  total_pixels <- sum(!is.na(values(gap_mask)))
  edge_pixels <- sum(values(edges), na.rm = TRUE)

  if (edge_pixels == 0) {
    return(NULL)
  }

  # Vectoriser les lisières
  edges[edges == 0] <- NA
  edge_polys <- terra::as.polygons(edges)

  if (nrow(edge_polys) == 0) {
    return(NULL)
  }

  edge_sf <- sf::st_as_sf(edge_polys)
  names(edge_sf)[1] <- "edge_id"

  # Ajouter les attributs
  edge_sf$tile_id <- tile_id
  edge_sf$length_m <- as.numeric(sf::st_length(sf::st_cast(edge_sf, "MULTILINESTRING")))
  edge_sf$edge_id <- edge_sf$edge_id + (tile_id - 1) * 10000

  # Statistiques de la tuile
  attr(edge_sf, "tile_stats") <- list(
    total_pixels = total_pixels,
    edge_pixels = edge_pixels,
    edge_pct = edge_pixels / total_pixels * 100
  )

  edge_sf
}

# Traitement parallèle
cat("Traitement parallèle en cours...\n")
start_time <- Sys.time()

results <- future_lapply(seq_along(gap_mask_tiles), function(i) {
  process_edges_tile(gap_mask_tiles[i], i)
}, future.seed = TRUE)

# Filtrer les résultats NULL
results <- results[!sapply(results, is.null)]

# Fusionner tous les résultats
if (length(results) > 0) {
  # Collecter les stats avant fusion
  all_stats <- lapply(results, function(r) attr(r, "tile_stats"))
  total_pixels_all <- sum(sapply(all_stats, `[[`, "total_pixels"))
  edge_pixels_all <- sum(sapply(all_stats, `[[`, "edge_pixels"))

  edges_all <- do.call(rbind, results)

  elapsed <- as.numeric(difftime(Sys.time(), start_time, units = "secs"))

  cat("\n=== Résultats ===\n")
  cat("Temps de traitement:", round(elapsed, 1), "s\n")
  cat("Tuiles traitées:", length(gap_mask_tiles), "\n")
  cat("Polygones de lisières:", nrow(edges_all), "\n")
  cat("Pourcentage de lisières:", round(edge_pixels_all / total_pixels_all * 100, 2), "%\n")

  # Sauvegarder en gpkg
  output_file <- file.path(data_dir, "edges_complet.gpkg")
  sf::st_write(edges_all, output_file, delete_dsn = TRUE, quiet = TRUE)
  cat("\nFichier sauvegardé:", output_file, "\n")

  # Visualisation
  par(mfrow = c(1, 1))
  plot(sf::st_geometry(edges_all), col = "red",
       main = paste("Lisières détectées (", round(edge_pixels_all / total_pixels_all * 100, 2), "%)"),
       border = NA)
} else {
  cat("Aucune lisière détectée.\n")
}

plan(sequential)
```

### Exercice 4.4 : Statistiques des trouées

Analysez la distribution des tailles de trouées.

```{r ex-4-4-setup}
library(lidaRtRee)
library(terra)
data(chm_chablais3)
chm <- terra::rast(chm_chablais3)
chm[is.na(chm)] <- 0
chm[chm < 0] <- 0
gaps <- gap_detection(chm, ratio = NULL, gap_max_height = 1, min_gap_surface = 0)
```

```{r ex-4-4, exercise=TRUE, exercise.timelimit=60, exercise.setup="ex-4-4-setup"}
library(terra)

# Extraire les surfaces de trouées
gap_ids <- unique(values(gaps$gap_id))
gap_ids <- gap_ids[!is.na(gap_ids) & gap_ids > 0]

# Calculer la surface de chaque trouée
res_pixel <- res(gaps$gap_surface)[1]
gaps_df <- data.frame(
  id = gap_ids,
  surface_m2 = sapply(gap_ids, function(id) {
    sum(values(gaps$gap_id) == id, na.rm = TRUE) * res_pixel^2
  })
)

cat("=== Distribution des tailles de trouées ===\n\n")
cat("Nombre total de trouées:", nrow(gaps_df), "\n")
cat("Surface min:", round(min(gaps_df$surface_m2), 1), "m²\n")
cat("Surface max:", round(max(gaps_df$surface_m2), 1), "m²\n")
cat("Surface médiane:", round(median(gaps_df$surface_m2), 1), "m²\n")
cat("Surface moyenne:", round(mean(gaps_df$surface_m2), 1), "m²\n")

# Classes de surface (pour indicateurs nemeton)
classes <- c(0, 25, 100, 500, 2000, Inf)
gaps_df$classe <- cut(gaps_df$surface_m2, breaks = classes,
                       labels = c("<25", "25-100", "100-500", "500-2000", ">2000"))

cat("\nDistribution par classe:\n")
print(table(gaps_df$classe))

# Histogramme
hist(log10(gaps_df$surface_m2), breaks = 20,
     main = "Distribution des surfaces de trouées",
     xlab = "log10(Surface en m²)", col = "forestgreen")
```

### Quiz Trouées et Lisières

```{r quiz-gaps, echo=FALSE}
quiz(
  question("Que signifie le paramètre ratio=2 dans gap_detection() ?",
    answer("Surface minimum de 2 m²"),
    answer("Distance à la végétation > 2× hauteur de cette végétation", correct = TRUE),
    answer("Hauteur maximum de 2 m"),
    answer("2 trouées minimum"),
    allow_retry = TRUE
  ),
  question("Quelle méthode détecte les lisières à l'intérieur de la forêt ?",
    answer("Dilatation morphologique"),
    answer("Érosion morphologique", correct = TRUE),
    answer("Filtrage médian"),
    answer("Segmentation watershed"),
    allow_retry = TRUE
  ),
  question("Quel indicateur nemeton utilise les trouées forestières ?",
    answer("C1 - Carbone"),
    answer("B2 - Structure biodiversité", correct = TRUE),
    answer("P1 - Volume"),
    answer("W1 - TWI"),
    allow_retry = TRUE
  )
)
```

## Section 5 : Métriques de Structure Forestière

*Basé sur l'article [Forest structure metrics extraction](https://lidar.pages-forge.inrae.fr/lidaRtRee/articles/forest.structure.metrics.html) de lidaRtRee*

### Principe

L'extraction de **métriques de structure forestière** à partir des données LiDAR permet de caractériser la complexité verticale et horizontale des peuplements. lidaRtRee propose plusieurs familles de métriques :

1. **Métriques 2D (CHM)** : statistiques sur le MNH lissé à différentes échelles
2. **Métriques de trouées** : proportion de surface par classe de taille
3. **Métriques d'arbres** : densité, hauteur moyenne, indice de Gini
4. **Métriques 1D (nuage de points)** : percentiles, densité par strate

```
            Familles de métriques lidaRtRee

  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐
  │   Métriques 2D  │  │ Métriques arbres│  │  Métriques 1D   │
  │     (CHM)       │  │  (segmentation) │  │ (nuage points)  │
  ├─────────────────┤  ├─────────────────┤  ├─────────────────┤
  │ - CHM lissé σ   │  │ - Densité /ha   │  │ - Percentiles   │
  │ - % couverture  │  │ - H moyenne     │  │ - Densité/strate│
  │ - Écart-type    │  │ - Gini          │  │ - Intensité     │
  └─────────────────┘  └─────────────────┘  └─────────────────┘
```

### Exercice 5.1a : Normalisation des fichiers LAZ avec lasR (parallélisé)

Normalisez les fichiers LAZ bruts en utilisant le package `lasR` qui offre
un traitement parallélisé natif et performant.

```{r ex-5-1a-setup}
library(lasR)
library(sf)

if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
# Résoudre le chemin complet (évite les problèmes avec ~)
data_dir <- normalizePath(data_dir, mustWork = FALSE)

# Répertoire des fichiers LAZ bruts (téléchargés)
laz_raw_dir <- file.path(data_dir, "lidar_hd")
laz_raw_files <- list.files(laz_raw_dir, pattern = "\\.la[sz]$", full.names = TRUE, recursive = TRUE)

# Répertoire de sortie pour les fichiers normalisés
laz_norm_dir <- file.path(data_dir, "result_laz_normalized")
dir.create(laz_norm_dir, showWarnings = FALSE, recursive = TRUE)
```

```{r ex-5-1a, exercise=TRUE, exercise.timelimit=2400, exercise.setup="ex-5-1a-setup"}
library(lasR)

cat("=== Normalisation des fichiers LAZ avec lasR ===\n\n")

# ==========================================================================
# 1. VÉRIFICATION DES FICHIERS D'ENTRÉE
# ==========================================================================
cat("--- 1. Fichiers LAZ bruts ---\n")

if (length(laz_raw_files) == 0) {
  stop("Aucun fichier LAZ brut trouvé. Exécutez d'abord le téléchargement (section 2).")
}

cat("Fichiers trouvés:", length(laz_raw_files), "\n")
for (f in laz_raw_files) {
  cat("  -", basename(f), "\n")
}
cat("\n")

# ==========================================================================
# 2. CONSTRUCTION DU PIPELINE LASR
# ==========================================================================
cat("--- 2. Construction du pipeline lasR ---\n\n")

# Nombre de cœurs disponibles
n_cores <- parallel::detectCores() - 1
n_cores <- max(1, min(n_cores, 4))  # Entre 1 et 4 cœurs
cat("Cœurs utilisés:", n_cores, "\n\n")

cat("Pipeline de normalisation:\n")
cat("  1. reader_las()      - Lecture des fichiers LAZ\n")
cat("  2. triangulate()     - Triangulation TIN des points sol\n")
cat("  3. transform_with()  - Soustraction du DTM (normalisation)\n")
cat("  4. write_las()       - Écriture des fichiers normalisés\n\n")

# ==========================================================================
# 3. EXÉCUTION DU PIPELINE (PARALLÉLISÉ)
# ==========================================================================
cat("--- 3. Normalisation (parallélisée) ---\n")

# Identifier les fichiers déjà normalisés
files_to_process <- character(0)
files_skipped <- character(0)

for (f in laz_raw_files) {
  # Nom du fichier normalisé attendu
  base_name <- tools::file_path_sans_ext(basename(f))
  norm_file <- file.path(laz_norm_dir, paste0(base_name, "_norm.laz"))

  if (file.exists(norm_file)) {
    files_skipped <- c(files_skipped, f)
  } else {
    files_to_process <- c(files_to_process, f)
  }
}

cat("Fichiers à traiter:", length(files_to_process), "\n")
cat("Fichiers ignorés (déjà normalisés):", length(files_skipped), "\n\n")

if (length(files_skipped) > 0) {
  cat("Fichiers ignorés:\n")
  for (f in files_skipped) {
    cat("  - [SKIP]", basename(f), "\n")
  }
  cat("\n")
}

if (length(files_to_process) > 0) {
  cat("Traitement en cours...\n")
  start_time <- Sys.time()

  # Construction du pipeline lasR
  tri <- triangulate(filter = keep_ground())
  pipeline <- reader_las() +
    tri +
    transform_with(tri, operator = "-") +
    write_las(ofile = paste0(laz_norm_dir, "/*_norm.laz"))

  # Exécution parallélisée sur les fichiers restants

  ans <- exec(pipeline, on = files_to_process, ncores = n_cores, progress = TRUE)

  elapsed <- as.numeric(difftime(Sys.time(), start_time, units = "secs"))
  cat("\nTemps de traitement:", round(elapsed, 1), "s\n")
  cat("Vitesse:", round(length(files_to_process) / elapsed * 60, 1), "fichiers/min\n\n")
} else {
  cat("Tous les fichiers sont déjà normalisés.\n\n")
}

# ==========================================================================
# 4. VÉRIFICATION DES RÉSULTATS
# ==========================================================================
cat("--- 4. Résultats ---\n\n")

norm_files <- list.files(laz_norm_dir, pattern = "\\.laz$", full.names = TRUE)
cat("Fichiers normalisés créés:", length(norm_files), "\n")

total_size_norm <- sum(file.size(norm_files)) / (1024 * 1024)
cat("Taille totale (normalisés):", round(total_size_norm, 1), "Mo\n\n")

for (f in norm_files) {
  cat("  -", basename(f), "-", round(file.size(f) / (1024 * 1024), 1), "Mo\n")
}

# ==========================================================================
# 5. COMPRESSION LAZ ET STATISTIQUES
# ==========================================================================
cat("\n--- 5. Compression LAZ ---\n\n")

# Comparer avec les fichiers bruts
total_size_raw <- sum(file.size(laz_raw_files)) / (1024 * 1024)

cat("Taille fichiers bruts:", round(total_size_raw, 1), "Mo\n")
cat("Taille fichiers normalisés:", round(total_size_norm, 1), "Mo\n")

if (total_size_raw > 0) {
  ratio <- total_size_norm / total_size_raw * 100
  cat("Ratio:", round(ratio, 1), "%\n\n")
}

cat("Format de sortie: LAZ (compression LASzip)\n")
cat("Avantages du LAZ:\n")
cat("  - Compression sans perte (lossless)\n")
cat("  - Réduction typique: 7-20% de la taille LAS\n")
cat("  - Compatible avec tous les outils LiDAR\n")
cat("  - Décompression à la volée lors de la lecture\n")

cat("\nRépertoire de sortie:", laz_norm_dir, "\n")
```

### Exercice 5.1b : Extraction des métriques ABA sur les placettes (parallélisé)

Extrayez les métriques `aba_metrics()` de lidaRtRee sur les placettes terrain
sauvegardées dans le tutoriel T01, en utilisant les fichiers normalisés.

*Basé sur le tutoriel [Area-based 1: Data preparation](https://lidar.pages-forge.inrae.fr/lidaRtRee/articles/area-based.1.data.preparation.html)*

```{r ex-5-1b-setup}
library(lidaRtRee)
library(lidR)
library(sf)
library(future)
library(future.apply)

if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
# Résoudre le chemin complet (évite les problèmes avec ~)
data_dir <- normalizePath(data_dir, mustWork = FALSE)

# Fichiers normalisés par lasR (exercice 5.1a)
laz_norm_dir <- file.path(data_dir, "result_laz_normalized")
laz_files <- list.files(laz_norm_dir, pattern = "\\.laz$", full.names = TRUE)

# Fichier des placettes terrain (créé dans T01)
placettes_gpkg <- file.path(data_dir, "placettes_lidar.gpkg")
```

```{r ex-5-1b, exercise=TRUE, exercise.timelimit=2400, exercise.setup="ex-5-1b-setup"}
library(lidaRtRee)
library(lidR)
library(sf)
library(future)
library(future.apply)

cat("=== Extraction des métriques ABA sur les placettes terrain ===\n\n")

# ==========================================================================
# 1. CHARGEMENT DU CATALOGUE LIDAR
# ==========================================================================
cat("--- 1. Chargement du catalogue LiDAR ---\n")

if (length(laz_files) == 0) {
  stop("Aucun fichier LAZ normalisé trouvé. Exécutez d'abord l'exercice 5.1a.")
}

cat("Source:", laz_norm_dir, "\n")
ctg <- readLAScatalog(laz_files)
opt_progress(ctg) <- FALSE

cat("Fichiers LAZ:", length(laz_files), "\n")
cat("Emprise:", round(st_bbox(ctg)[c("xmin", "ymin", "xmax", "ymax")]), "\n")
cat("Surface totale:", round(st_area(st_as_sfc(st_bbox(ctg))) / 10000, 2), "ha\n\n")

# ==========================================================================
# 2. CHARGEMENT DES PLACETTES TERRAIN
# ==========================================================================
cat("--- 2. Chargement des placettes terrain ---\n")

if (!file.exists(placettes_gpkg)) {
  stop("Fichier placettes_lidar.gpkg non trouvé. Exécutez d'abord l'exercice 6.1 du tutoriel T01.")
}

# Charger les placettes
plots_sf <- st_read(placettes_gpkg, layer = "placettes_metrics", quiet = TRUE)

# Créer un identifiant unique si non présent
if (!"plot_id" %in% names(plots_sf)) {
  plots_sf$plot_id <- seq_len(nrow(plots_sf))
}
cat("Placettes chargées:", nrow(plots_sf), "\n")

# Filtrer les placettes dans l'emprise du catalogue
ctg_bbox <- st_as_sfc(st_bbox(ctg))
plots_in_extent <- plots_sf[st_intersects(plots_sf, ctg_bbox, sparse = FALSE), ]
cat("Placettes dans l'emprise du catalogue:", nrow(plots_in_extent), "\n")

if (nrow(plots_in_extent) == 0) {
  stop("Aucune placette dans l'emprise du catalogue LiDAR.")
}

# Paramètres des placettes
PLOT_RADIUS <- 15  # Rayon standard (m)

cat("Rayon placettes:", PLOT_RADIUS, "m\n")
cat("Surface placette:", round(pi * PLOT_RADIUS^2, 0), "m² (",
    round(pi * PLOT_RADIUS^2 / 10000, 4), "ha)\n\n")

# ==========================================================================
# 3. EXTRACTION DES MÉTRIQUES EN PARALLÈLE
# ==========================================================================
cat("--- 3. Extraction des métriques (parallélisé) ---\n")

# Configuration parallélisation
plan(multisession, workers = 4)

# Fichier de cache pour reprise
cache_file <- file.path(data_dir, "aba_metrics_placettes.rds")

if (file.exists(cache_file)) {
  cat("Chargement depuis le cache...\n")
  metrics_df <- readRDS(cache_file)
  cat("Métriques chargées:", nrow(metrics_df), "placettes\n\n")
} else {
  cat("Traitement en cours...\n")
  start_time <- Sys.time()

  # Fonction d'extraction par placette
  extract_plot_metrics <- function(plot_id, x, y, radius, ctg) {
    tryCatch({
      # Extraire le nuage de points circulaire
      las <- clip_circle(ctg, x, y, radius)

      if (is.null(las) || npoints(las) < 10) {
        return(NULL)
      }

      # Calculer les métriques ABA avec lidaRtRee
      metrics <- aba_metrics(
        z = las$Z,
        i = las$Intensity,
        rn = las$ReturnNumber,
        c = las$Classification,
        hmin = 2
      )

      # Ajouter les métadonnées
      metrics$plot_id <- plot_id
      metrics$X <- x
      metrics$Y <- y
      metrics$n_points <- npoints(las)

      as.data.frame(metrics)
    }, error = function(e) NULL)
  }

  # Extraction parallèle
  coords <- st_coordinates(plots_in_extent)
  results <- future_lapply(seq_len(nrow(plots_in_extent)), function(i) {
    extract_plot_metrics(
      plot_id = plots_in_extent$plot_id[i],
      x = coords[i, 1],
      y = coords[i, 2],
      radius = PLOT_RADIUS,
      ctg = ctg
    )
  }, future.seed = TRUE)

  # Combiner les résultats
  results <- results[!sapply(results, is.null)]
  metrics_df <- do.call(rbind, results)

  elapsed <- as.numeric(difftime(Sys.time(), start_time, units = "secs"))
  cat("Temps de traitement:", round(elapsed, 1), "s\n")
  cat("Placettes traitées:", nrow(metrics_df), "/", nrow(plots_in_extent), "\n\n")

  # Sauvegarder en cache
  saveRDS(metrics_df, cache_file)
  cat("Cache sauvegardé:", cache_file, "\n\n")
}

plan(sequential)

# ==========================================================================
# 4. STATISTIQUES ET VISUALISATION
# ==========================================================================
cat("--- 4. Statistiques des métriques extraites ---\n\n")

cat("Métriques de hauteur:\n")
cat("  zmax  - moy:", round(mean(metrics_df$zmax, na.rm = TRUE), 2), "m,",
    "sd:", round(sd(metrics_df$zmax, na.rm = TRUE), 2), "m\n")
cat("  zmean - moy:", round(mean(metrics_df$zmean, na.rm = TRUE), 2), "m,",
    "sd:", round(sd(metrics_df$zmean, na.rm = TRUE), 2), "m\n")
cat("  zq95  - moy:", round(mean(metrics_df$zq95, na.rm = TRUE), 2), "m,",
    "sd:", round(sd(metrics_df$zq95, na.rm = TRUE), 2), "m\n\n")

cat("Percentiles (moyennes):\n")
cat("  zq25:", round(mean(metrics_df$zq25, na.rm = TRUE), 2), "m\n")
cat("  zq50:", round(mean(metrics_df$zq50, na.rm = TRUE), 2), "m\n")
cat("  zq75:", round(mean(metrics_df$zq75, na.rm = TRUE), 2), "m\n")
cat("  zq95:", round(mean(metrics_df$zq95, na.rm = TRUE), 2), "m\n\n")

cat("Couverture canopée (moyennes):\n")
cat("  > 2m:", round(mean(metrics_df$pzabove2, na.rm = TRUE) * 100, 1), "%\n")
cat("  > 5m:", round(mean(metrics_df$pzabove5, na.rm = TRUE) * 100, 1), "%\n\n")

cat("Nombre de métriques par placette:", ncol(metrics_df) - 4, "\n")

# ==========================================================================
# 5. COMPARAISON AVEC LES MÉTRIQUES TERRAIN
# ==========================================================================
cat("\n--- 5. Comparaison avec les métriques existantes ---\n\n")

# Joindre les métriques extraites aux placettes terrain
plots_with_metrics <- merge(
  st_drop_geometry(plots_in_extent),
  metrics_df,
  by = "plot_id",
  suffixes = c("_terrain", "_extrait")
)

if ("zq95" %in% names(plots_in_extent) && "zq95" %in% names(metrics_df)) {
  cat("Corrélation zq95 (terrain vs extrait):",
      round(cor(plots_with_metrics$zq95_terrain, plots_with_metrics$zq95_extrait,
                use = "complete.obs"), 3), "\n")
}

# Visualisation
par(mfrow = c(2, 2))

hist(metrics_df$zq95, breaks = 15, col = "forestgreen",
     main = "Distribution zq95 (extrait)", xlab = "Hauteur (m)")

hist(metrics_df$pzabove2 * 100, breaks = 15, col = "darkgreen",
     main = "Couverture > 2m", xlab = "Couverture (%)")

plot(metrics_df$zq95, metrics_df$pzabove2 * 100, pch = 16, cex = 1.2,
     col = rgb(0, 0.5, 0, 0.7),
     main = "zq95 vs Couverture", xlab = "zq95 (m)", ylab = "Couverture > 2m (%)")

# Carte des placettes
plot(metrics_df$X, metrics_df$Y, pch = 19, cex = 2,
     col = hcl.colors(100, "Greens")[cut(metrics_df$zq95, 100)],
     main = "Carte zq95 par placette", xlab = "X", ylab = "Y", asp = 1)
```

### Exercice 5.2 : Cartographie des métriques d'arbres avec raster_metrics()

Utilisez `raster_metrics()` avec `std_tree_metrics()` pour créer une carte
de métriques d'arbres agrégées par pixel (résolution 25m), comme dans le
workflow ABA de lidaRtRee.

*Basé sur le tutoriel [Area-based 3: Mapping and inference](https://lidar.pages-forge.inrae.fr/lidaRtRee/articles/area-based.3.mapping.and.inference.html)*

```{r ex-5-2-setup}
library(lidaRtRee)
library(terra)
library(sf)

if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
data_dir <- normalizePath(data_dir, mustWork = FALSE)

# Charger les arbres extraits en section 3.3 (avec height, area_m2)
trees_gpkg <- file.path(data_dir, "tree_metrics_complet.gpkg")

if (file.exists(trees_gpkg)) {
  trees <- sf::st_read(trees_gpkg, quiet = TRUE)
  # Adapter les noms pour std_tree_metrics (h, s, v)
  trees$h <- trees$height
  trees$s <- trees$area_m2
  trees$v <- trees$s * trees$h * 0.5  # volume conique approximatif
} else {
  # Fallback sur données exemple
  data(chm_chablais3)
  chm <- terra::rast(chm_chablais3)
  segments <- tree_segmentation(chm, nl_filter = "Median", nl_size = 3,
                                 hmin = 5, crown_prop = 0.5, crown_hmin = 5)
  trees <- tree_extraction(segments, crown = TRUE)
}
```

```{r ex-5-2, exercise=TRUE, exercise.timelimit=300, exercise.setup="ex-5-2-setup"}
library(lidaRtRee)
library(terra)
library(sf)

cat("=== Cartographie des métriques d'arbres (workflow ABA) ===\n\n")

# Résolution de la grille de sortie (25m = taille typique placette ABA)
resolution <- 25
area_ha <- resolution^2 / 10000  # Surface d'un pixel en ha

cat("Paramètres:\n")
cat("  Résolution:", resolution, "m\n")
cat("  Surface pixel:", round(area_ha, 4), "ha\n")
cat("  Arbres détectés:", nrow(trees), "\n\n")

# ==========================================================================
# AGRÉGATION DES MÉTRIQUES PAR PIXEL AVEC raster_metrics()
# ==========================================================================
cat("--- Calcul des métriques par pixel (raster_metrics) ---\n")

# Fonction d'agrégation utilisant std_tree_metrics
metrics_map <- raster_metrics(

  trees,
  res = resolution,
  fun = function(x) {
    if (nrow(x) == 0) return(NULL)
    std_tree_metrics(x, area_ha = area_ha)
  },
  output = "raster"
)

cat("Carte de métriques créée:\n")
cat("  Dimensions:", nrow(metrics_map), "x", ncol(metrics_map), "pixels\n")
cat("  Métriques:", nlyr(metrics_map), "\n")
cat("  Noms:", paste(names(metrics_map)[1:5], collapse = ", "), "...\n\n")

# ==========================================================================
# STATISTIQUES DES MÉTRIQUES CARTOGRAPHIÉES
# ==========================================================================
cat("--- Statistiques des métriques cartographiées ---\n\n")

cat("Densité d'arbres (Tree_density):\n")
cat("  Moyenne:", round(mean(values(metrics_map$Tree_density), na.rm = TRUE), 0), "/ha\n")
cat("  Écart-type:", round(sd(values(metrics_map$Tree_density), na.rm = TRUE), 0), "/ha\n\n")

cat("Hauteur moyenne (Tree_meanH):\n")
cat("  Moyenne:", round(mean(values(metrics_map$Tree_meanH), na.rm = TRUE), 2), "m\n")
cat("  Écart-type:", round(sd(values(metrics_map$Tree_meanH), na.rm = TRUE), 2), "m\n\n")

cat("Indice de Gini (Tree_giniH):\n")
cat("  Moyenne:", round(mean(values(metrics_map$Tree_giniH), na.rm = TRUE), 3), "\n")
cat("  Interprétation: 0 = homogène, 1 = très hétérogène\n\n")

# ==========================================================================
# VISUALISATION
# ==========================================================================
cat("--- Visualisation ---\n")

par(mfrow = c(2, 2))

# Densité d'arbres
plot(metrics_map$Tree_density, main = "Densité d'arbres (/ha)",
     col = hcl.colors(50, "YlGn", rev = TRUE))

# Hauteur moyenne
plot(metrics_map$Tree_meanH, main = "Hauteur moyenne (m)",
     col = hcl.colors(50, "Greens", rev = TRUE))

# Gini (hétérogénéité)
plot(metrics_map$Tree_giniH, main = "Indice de Gini",
     col = hcl.colors(50, "RdYlGn", rev = TRUE))

# Arbres > 20m
plot(metrics_map$TreeSup20_density, main = "Arbres > 20m (/ha)",
     col = hcl.colors(50, "Blues", rev = TRUE))

cat("\nCette carte de métriques peut être utilisée pour:\n")
cat("- Prédire des paramètres forestiers (G, V, biomasse) avec aba_predict()\n")
cat("- Stratifier la forêt par types de peuplements\n")
cat("- Identifier les zones à fort potentiel ou dégradées\n")
```

### Exercice 5.3 : Métriques multi-échelles du CHM

Calculez les métriques du CHM à différentes échelles de lissage.

```{r ex-5-3-setup}
library(lidaRtRee)
library(terra)

if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
data_dir <- normalizePath(data_dir, mustWork = FALSE)

# Utiliser le VRT créé en section 3.2
chm_vrt <- file.path(data_dir, "c_filled_complet.vrt")
if (file.exists(chm_vrt)) {
  chm_full <- terra::rast(chm_vrt)
  # Cropper sur une zone de 500m x 500m au centre
  e <- terra::ext(chm_full)
  center_x <- (e$xmin + e$xmax) / 2
  center_y <- (e$ymin + e$ymax) / 2
  crop_ext <- terra::ext(center_x - 250, center_x + 250,
                         center_y - 250, center_y + 250)
  chm <- terra::crop(chm_full, crop_ext)
} else {
  # Fallback sur données exemple
  data(chm_chablais3)
  chm <- terra::rast(chm_chablais3)
}
chm[is.na(chm)] <- 0
chm[chm < 0] <- 0
```

```{r ex-5-3, exercise=TRUE, exercise.timelimit=300, exercise.setup="ex-5-3-setup"}
library(terra)

cat("=== Métriques multi-échelles du CHM ===\n\n")

# Activer le multithreading terra
n_threads <- max(1, parallel::detectCores() - 1)
terraOptions(threads = n_threads)
cat("Threads terra:", n_threads, "\n")
cat("Dimensions CHM:", nrow(chm), "x", ncol(chm), "pixels\n\n")

# Valeurs sigma pour le lissage gaussien
sigmas <- c(0, 0.5, 1, 2, 4, 8)

# Calculer les écarts-types du CHM lissé à chaque échelle
chm_stats <- list()
for (sigma in sigmas) {
  if (sigma == 0) {
    chm_smooth <- chm
  } else {
    # Lissage gaussien (approximation avec focal)
    w_size <- ceiling(sigma * 3) * 2 + 1
    weights <- matrix(1, w_size, w_size)
    chm_smooth <- focal(chm, w = weights, fun = "mean", na.rm = TRUE)
  }

  chm_stats[[paste0("sigma_", sigma)]] <- list(
    mean = mean(values(chm_smooth), na.rm = TRUE),
    sd = sd(values(chm_smooth), na.rm = TRUE),
    max = max(values(chm_smooth), na.rm = TRUE)
  )
}

cat("Statistiques par échelle de lissage:\n\n")
cat(sprintf("%-10s %8s %8s %8s\n", "Sigma", "Moyenne", "Écart-T", "Max"))
for (name in names(chm_stats)) {
  s <- chm_stats[[name]]
  sigma_val <- gsub("sigma_", "", name)
  cat(sprintf("%-10s %8.2f %8.2f %8.2f\n", sigma_val, s$mean, s$sd, s$max))
}

# Métriques de couverture par classe de hauteur
cat("\n\nCouverture par classe de hauteur:\n")
seuils <- c(0.5, 1, 5, 10, 20)
for (s in seuils) {
  pct <- sum(values(chm) > s, na.rm = TRUE) / sum(!is.na(values(chm))) * 100
  cat(sprintf("  > %2.0f m : %5.1f %%\n", s, pct))
}
```

### Tableau récapitulatif des métriques

| Métrique | Fonction lidaRtRee | Description | Indicateur nemeton |
|----------|-------------------|-------------|-------------------|
| zmax, zmean, zsd | `aba_metrics()` | Statistiques de hauteur | P1, C1, B2 |
| zq25, zq50, zq75, zq95 | `aba_metrics()` | Percentiles | P1 |
| pzabove2, pzabove5 | `aba_metrics()` | Couverture canopée | A1, C1 |
| N_ha, N_sup10 | `std_tree_metrics()` | Densité d'arbres | P1, E1 |
| H_mean, H_dom | `std_tree_metrics()` | Hauteur moyenne/dominante | P1, P3 |
| Gini | `std_tree_metrics()` | Hétérogénéité (inégalité) | B2 |
| Simpson | calcul manuel | Diversité des classes de hauteur | B2 |
| gap_surface | `gap_detection()` | Surface en trouées | B2 |
| edge_pct | `edge_detection()` | % de lisières | L1 |

### Quiz Métriques

```{r quiz-metrics, echo=FALSE}
quiz(
  question("Que mesure l'indice de Gini sur les hauteurs d'arbres ?",
    answer("La hauteur moyenne"),
    answer("L'inégalité/hétérogénéité des hauteurs", correct = TRUE),
    answer("La densité d'arbres"),
    answer("La couverture du sol"),
    allow_retry = TRUE
  ),
  question("Quelle métrique est la plus utile pour estimer la biomasse ?",
    answer("Gini"),
    answer("pzabove2"),
    answer("zq95 (percentile 95)", correct = TRUE),
    answer("N_ha"),
    allow_retry = TRUE
  ),
  question("À quoi sert le lissage multi-échelles du CHM ?",
    answer("Accélérer le traitement"),
    answer("Capturer la structure à différentes résolutions spatiales", correct = TRUE),
    answer("Corriger les erreurs GPS"),
    answer("Convertir les unités"),
    allow_retry = TRUE
  )
)
```


## Section 6 : Approche ABA - Préparation des Données

*Basé sur l'article [Area-based 1: Data preparation](https://lidar.pages-forge.inrae.fr/lidaRtRee/articles/area-based.1.data.preparation.html) de lidaRtRee*

### Principe de l'approche ABA

L'**approche basée sur les surfaces** (Area-Based Approach - ABA) est la méthode standard pour prédire des paramètres forestiers à partir de données LiDAR. Elle comprend trois étapes :

1. **Préparation des données** : extraction des métriques LiDAR sur les placettes terrain
2. **Calibration du modèle** : régression entre métriques LiDAR et mesures terrain
3. **Cartographie** : application du modèle sur l'ensemble de la zone

```
            Flux de travail ABA

  PLACETTES TERRAIN          DONNÉES LIDAR
        │                          │
        ▼                          ▼
  ┌───────────┐            ┌───────────────┐
  │ G, V, N   │            │ Nuage points  │
  │ (mesurés) │            │ (normalisé)   │
  └─────┬─────┘            └───────┬───────┘
        │                          │
        │    ┌─────────────────┐   │
        └───►│ EXTRACTION      │◄──┘
             │ métriques/plot  │
             └────────┬────────┘
                      │
                      ▼
             ┌─────────────────┐
             │ CALIBRATION     │
             │ G = f(zq95,...) │
             └────────┬────────┘
                      │
                      ▼
             ┌─────────────────┐
             │ CARTOGRAPHIE    │
             │ Prédiction wall │
             │ to wall         │
             └─────────────────┘
```

### Exercice 6.1 : Chargement des placettes terrain

Chargez les données terrain des 28 placettes de notre zone d'étude depuis les
fichiers CSV du projet Quatre Montagnes.

*Basé sur le tutoriel [Area-based 1: Data preparation](https://lidar.pages-forge.inrae.fr/lidaRtRee/articles/area-based.1.data.preparation.html)*

```{r ex-6-1-setup}
library(lidaRtRee)
library(sf)
library(purrr)
library(dplyr)
library(stringr)

# Répertoire des données du package
pkg_data_dir <- system.file("", package = "nemeton")
if (pkg_data_dir == "") {

  pkg_data_dir <- "/home/pascal/Téléchargements/nemeton"
}
field_dir <- file.path(pkg_data_dir, "data", "aba.model", "field")

# Liste des 7 clusters dans notre zone d'étude (28 placettes)
plots_in_extent <- c("Verc-02", "Verc-05", "Verc-06", "Verc-C1",
                     "Verc-C2", "Verc-S4", "Verc-S7")
```

```{r ex-6-1, exercise=TRUE, exercise.timelimit=120, exercise.setup="ex-6-1-setup"}
library(lidaRtRee)
library(sf)
library(purrr)
library(dplyr)
library(stringr)

cat("=== Chargement des placettes terrain (zone d'étude) ===\n\n")

# Paramètres d'inventaire
p_radius <- 15
dbh_min <- 7.5
plot_area_ha <- pi * p_radius^2 / 10000

cat("Paramètres:\n")
cat("  Rayon placettes:", p_radius, "m\n")
cat("  Surface:", round(pi * p_radius^2, 0), "m² (", round(plot_area_ha, 4), "ha)\n")
cat("  DHP minimum:", dbh_min, "cm\n\n")

# ==========================================================================
# 1. CHARGER LES COORDONNÉES DES PLACETTES (purrr)
# ==========================================================================
cat("--- 1. Chargement des coordonnées ---\n")

plots <- dir(field_dir, pattern = "_PiquetsTerrain\\.csv$", full.names = TRUE) |>
  keep(~ any(str_detect(basename(.x), plots_in_extent))) |>
  map_dfr(~ read.table(.x, sep = ";", header = TRUE, stringsAsFactors = FALSE) |>
            select(Id, X, Y) |>
            mutate(cluster_id = sub("_PiquetsTerrain\\.csv$", "", basename(.x)))) |>
  filter(Id %in% c("p1", "p2", "p3", "p4")) |>
  mutate(plot_id = paste0(cluster_id, "-", substr(Id, 2, 2)))

cat("Clusters chargés:", n_distinct(plots$cluster_id), "\n")
cat("Placettes:", nrow(plots), "\n\n")

# ==========================================================================
# 2. CHARGER LES ARBRES ET CALCULER G, N, D (purrr + dplyr)
# ==========================================================================
cat("--- 2. Calcul des paramètres de peuplement ---\n")

trees <- dir(field_dir, pattern = "_ArbresTerrain\\.csv$", full.names = TRUE) |>
  keep(~ any(str_detect(basename(.x), plots$plot_id))) |>
  map_dfr(~ read.table(.x, sep = ";", header = TRUE, stringsAsFactors = FALSE) |>
            select(Diam, Aspect) |>
            mutate(plot_id = sub("_ArbresTerrain\\.csv$", "", basename(.x)))) |>
  filter(!is.na(Diam), Diam >= dbh_min, Aspect %in% c(1, 2))

# Calcul des paramètres de peuplement avec dplyr
stand_params <- trees |>
  group_by(plot_id) |>
  summarise(
    G_m2_ha = sum(pi * (Diam / 200)^2) / plot_area_ha,
    N_ha = n() / plot_area_ha,
    D_mean_cm = mean(Diam),
    .groups = "drop"
  )

# Fusionner et créer objet sf
plots_sf <- plots |>
  left_join(stand_params, by = "plot_id") |>
  st_as_sf(coords = c("X", "Y"), crs = 2154)

cat("Placettes avec données terrain:", sum(!is.na(plots_sf$G_m2_ha)), "\n\n")

# ==========================================================================
# 3. RÉSUMÉ
# ==========================================================================
cat("--- 3. Résumé des données terrain ---\n\n")

plots_sf |>
  st_drop_geometry() |>
  summarise(
    across(c(G_m2_ha, N_ha, D_mean_cm),
           list(min = ~ min(.x, na.rm = TRUE),
                max = ~ max(.x, na.rm = TRUE),
                moy = ~ mean(.x, na.rm = TRUE)))
  ) |>
  pivot_longer(everything(), names_to = c("var", "stat"), names_sep = "_") |>
  pivot_wider(names_from = stat, values_from = value) |>
  mutate(across(where(is.numeric), ~ round(.x, 1))) |>
  print()

cat("\nAperçu:\n")
print(head(st_drop_geometry(plots_sf)[, c("plot_id", "G_m2_ha", "N_ha", "D_mean_cm")]))
```

### Exercice 6.2 : Extraction des métriques LiDAR par placette

Extrayez les métriques LiDAR sur les 28 placettes avec `clouds_metrics()` et `aba_metrics()`,
en utilisant furrr pour la parallélisation.

```{r ex-6-2-setup}
library(lidaRtRee)
library(lidR)
library(sf)
library(purrr)
library(furrr)
library(dplyr)
library(stringr)

# Répertoire des données
pkg_data_dir <- system.file("", package = "nemeton")
if (pkg_data_dir == "") {
  pkg_data_dir <- "/home/pascal/Téléchargements/nemeton"
}
field_dir <- file.path(pkg_data_dir, "data", "aba.model", "field")
laz_dir <- file.path(pkg_data_dir, "data", "aba.model", "ALS", "plots.norm.laz")

# Placettes de notre zone d'étude
plots_in_extent <- c("Verc-02", "Verc-05", "Verc-06", "Verc-C1",
                     "Verc-C2", "Verc-S4", "Verc-S7")
p_radius <- 15
plot_area_ha <- pi * p_radius^2 / 10000
```

```{r ex-6-2, exercise=TRUE, exercise.timelimit=300, exercise.setup="ex-6-2-setup"}
library(lidaRtRee)
library(lidR)
library(sf)
library(purrr)
library(furrr)
library(dplyr)
library(stringr)

cat("=== Extraction des métriques LiDAR (28 placettes) ===\n\n")

# ==========================================================================
# 1. CHARGER LES NUAGES DE POINTS (furrr parallélisé)
# ==========================================================================
cat("--- 1. Chargement des nuages de points ---\n")

# Configuration parallélisation
n_workers <- min(4L, parallel::detectCores() - 1L)
plan(multisession, workers = n_workers)
cat("Workers:", n_workers, "\n")

# Lister et filtrer les fichiers LAZ (purrr)
laz_files <- dir(laz_dir, pattern = "\\.laz$", full.names = TRUE) |>
  keep(~ any(str_detect(basename(.x), plots_in_extent)))

cat("Fichiers LAZ:", length(laz_files), "\n")

# Charger les nuages en parallèle (furrr)
llas <- laz_files |>
  set_names(~ sub("\\.laz$", "", basename(.x))) |>
  future_map(~ {
    las <- readLAS(.x, select = "xyzirnc")
    las$Z[las$Z < 0] <- 0
    las
  }, .options = furrr_options(seed = TRUE))

cat("Nuages chargés:", length(llas), "\n\n")

# ==========================================================================
# 2. CALCULER LES MÉTRIQUES ABA
# ==========================================================================
cat("--- 2. Calcul des métriques avec clouds_metrics() ---\n")

# Fonction de métriques ABA (signature correcte)
metrics <- clouds_metrics(llas, ~ aba_metrics(Z, Intensity, ReturnNumber,
                                               Classification, hmin = 2)) |>
  as_tibble(rownames = "plot_id")

cat("Métriques calculées:", ncol(metrics) - 1, "variables\n")
cat("Placettes:", nrow(metrics), "\n\n")

# Résumé des métriques principales
metrics |>
  summarise(
    zmax_moy = mean(zmax),
    zmean_moy = mean(zmean),
    zq95_moy = mean(zq95),
    couv_2m = mean(pzabove2) * 100
  ) |>
  mutate(across(everything(), ~ round(.x, 2))) |>
  print()

# ==========================================================================
# 3. CHARGER LES DONNÉES TERRAIN ET FUSIONNER (purrr + dplyr)
# ==========================================================================
cat("\n--- 3. Fusion avec données terrain ---\n")

# Charger placettes
plots <- dir(field_dir, pattern = "_PiquetsTerrain\\.csv$", full.names = TRUE) |>
  keep(~ any(str_detect(basename(.x), plots_in_extent))) |>
  map_dfr(~ read.table(.x, sep = ";", header = TRUE, stringsAsFactors = FALSE) |>
            select(Id, X, Y) |>
            mutate(cluster_id = sub("_PiquetsTerrain\\.csv$", "", basename(.x)))) |>
  filter(Id %in% c("p1", "p2", "p3", "p4")) |>
  mutate(plot_id = paste0(cluster_id, "-", substr(Id, 2, 2)))

# Charger arbres et calculer G
stand_params <- dir(field_dir, pattern = "_ArbresTerrain\\.csv$", full.names = TRUE) |>
  keep(~ any(str_detect(basename(.x), plots$plot_id))) |>
  map_dfr(~ read.table(.x, sep = ";", header = TRUE, stringsAsFactors = FALSE) |>
            select(Diam, Aspect) |>
            mutate(plot_id = sub("_ArbresTerrain\\.csv$", "", basename(.x)))) |>
  filter(!is.na(Diam), Diam >= 7.5, Aspect %in% c(1, 2)) |>
  group_by(plot_id) |>
  summarise(G_m2_ha = sum(pi * (Diam / 200)^2) / plot_area_ha, .groups = "drop")

# Fusionner terrain + LiDAR
plots_aba <- plots |>
  select(plot_id) |>
  left_join(stand_params, by = "plot_id") |>
  inner_join(metrics, by = "plot_id")

cat("Données fusionnées:", nrow(plots_aba), "placettes\n\n")

# Revenir en mode séquentiel
plan(sequential)

# ==========================================================================
# 4. CORRÉLATIONS TERRAIN vs LIDAR
# ==========================================================================
cat("--- 4. Corrélations G vs métriques LiDAR ---\n\n")

vars_cor <- c("zmax", "zmean", "zq95", "pzabove2", "mCH")
cors <- vars_cor |>
  set_names() |>
  map_dbl(~ cor(plots_aba$G_m2_ha, plots_aba[[.x]], use = "complete.obs"))

cat("Corrélations avec G (m²/ha):\n")
iwalk(cors, ~ cat(sprintf("  %-10s: %+.3f\n", .y, .x)))

# Graphique
par(mfrow = c(1, 2))
plot(plots_aba$zq95, plots_aba$G_m2_ha, pch = 16, col = "forestgreen",
     xlab = "zq95 (m)", ylab = "G (m²/ha)", main = "G vs zq95")
abline(lm(G_m2_ha ~ zq95, data = plots_aba), col = "red", lwd = 2)

plot(plots_aba$pzabove2, plots_aba$G_m2_ha, pch = 16, col = "forestgreen",
     xlab = "Couverture > 2m", ylab = "G (m²/ha)", main = "G vs couverture")
abline(lm(G_m2_ha ~ pzabove2, data = plots_aba), col = "red", lwd = 2)
```

### Exercice 6.3 : Métriques BABA avec lasR (haute performance)

Pour les gros jeux de données, lasR permet le calcul BABA (Buffered Area-Based Approach)
sur les tuiles LAZ normalisées de notre zone d'étude.

```{r ex-6-3-setup}
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
data_dir <- normalizePath(data_dir, mustWork = FALSE)

# Fichiers LAZ normalisés (créés en section 5.1a)
laz_norm_dir <- file.path(data_dir, "result_laz_normalized")
```

```{r ex-6-3, exercise=TRUE, exercise.timelimit=300, exercise.setup="ex-6-3-setup"}
cat("=== BABA avec lasR ===\n\n")

cat("BABA = Buffered Area-Based Approach\n")
cat("Avantage: résolution de sortie ≠ taille de fenêtre de calcul\n\n")

if (!requireNamespace("lasR", quietly = TRUE)) {
  cat("lasR n'est pas installé. Installez-le avec:\n")
  cat("install.packages('lasR', repos = 'https://r-lidar.r-universe.dev')\n")
} else {
  library(lasR)

  # Lister les fichiers LAZ normalisés
  laz_files <- list.files(laz_norm_dir, pattern = "\\.laz$", full.names = TRUE)
  cat("Fichiers LAZ normalisés:", length(laz_files), "\n\n")

  # Pipeline BABA: résolution 10m, fenêtre 30m (rayon 15m comme placettes)
  pipeline_baba <- reader_las() +
    rasterize(
      res = c(10, 30),  # 10m sortie, 30m fenêtre (~900 m²)
      operators = c("max", "mean", "sd", "p95", "above2")
    )

  print(pipeline_baba)

  cat("\n\nParamètre res = c(10, 30) signifie:\n")
  cat("- Pixels de sortie: 10m × 10m\n")
  cat("- Fenêtre de calcul: 30m × 30m (~900 m²)\n")
  cat("- Compatible avec placettes de rayon 15m (~707 m²)\n")
  cat("- 9 pixels de sortie par fenêtre de calcul\n\n")

  if (length(laz_files) > 0) {
    cat("--- Exécution sur la zone d'étude ---\n")
    N_CORES <- min(4L, parallel::detectCores() - 1L)

    output_file <- file.path(data_dir, "metriques_baba.tif")

    # Ajouter l'écriture du raster
    pipeline_baba <- reader_las() +
      rasterize(
        res = c(10, 30),
        operators = c("max", "mean", "sd", "p95", "above2"),
        ofile = output_file
      )

    ans <- exec(pipeline_baba, on = laz_files, ncores = N_CORES, progress = TRUE)

    cat("\nFichier créé:", output_file, "\n")

    # Charger et afficher le résultat
    if (file.exists(output_file)) {
      baba <- terra::rast(output_file)
      cat("Dimensions:", nrow(baba), "x", ncol(baba), "pixels\n")
      cat("Couches:", nlyr(baba), "\n")

      # Visualisation
      par(mfrow = c(2, 2))
      plot(baba[[1]], main = "Hmax (m)", col = hcl.colors(50, "Greens", rev = TRUE))
      plot(baba[[2]], main = "Hmean (m)", col = hcl.colors(50, "Greens", rev = TRUE))
      plot(baba[[4]], main = "H p95 (m)", col = hcl.colors(50, "Greens", rev = TRUE))
      plot(baba[[5]], main = "Couverture > 2m", col = hcl.colors(50, "YlGn", rev = TRUE))
    }
  } else {
    cat("Exécutez d'abord l'exercice 5.1a pour créer les fichiers normalisés.\n")
  }
}
```

### Quiz Préparation ABA

```{r quiz-aba-prep, echo=FALSE}
quiz(
  question("Quelle est la surface d'une placette de rayon 15m ?",
    answer("225 m²"),
    answer("450 m²"),
    answer("~707 m²", correct = TRUE),
    answer("900 m²"),
    allow_retry = TRUE
  ),
  question("Que contient la fonction aba_metrics() ?",
    answer("Uniquement les hauteurs"),
    answer("Hauteurs, percentiles, couverture, intensité, ratios", correct = TRUE),
    answer("Uniquement les coordonnées"),
    answer("Les espèces d'arbres"),
    allow_retry = TRUE
  )
)
```

## Section 7 : Approche ABA - Calibration des Modèles

*Basé sur l'article [Area-based 2: Model calibration](https://lidar.pages-forge.inrae.fr/lidaRtRee/articles/area-based.2.model.calibration.html) de lidaRtRee*

### Principe de la calibration

La fonction `aba_build_model()` de lidaRtRee automatise la calibration des modèles ABA :

1. **Transformation Box-Cox** : normalisation de la variable cible
2. **Sélection de variables** : algorithme stepwise avec critère BIC
3. **Validation croisée spatiale** : leave-one-out avec prise en compte de l'autocorrélation
4. **Diagnostics** : R², RMSE, biais, graphiques

```
            Flux de calibration aba_build_model()

  Données d'entrée:
  ┌─────────────────────────────────────────────┐
  │ y = variable terrain (G, V, N, ...)         │
  │ X = matrice de métriques LiDAR              │
  │ xy = coordonnées (pour validation spatiale) │
  └─────────────────────────────────────────────┘
                      │
                      ▼
  ┌─────────────────────────────────────────────┐
  │ 1. Transformation Box-Cox de y              │
  │ 2. Sélection variables (stepwise BIC)       │
  │ 3. Ajustement modèle linéaire               │
  │ 4. Validation croisée leave-one-out         │
  └─────────────────────────────────────────────┘
                      │
                      ▼
  Sorties:
  ┌─────────────────────────────────────────────┐
  │ - Modèle calibré                            │
  │ - Statistiques (R², R²cv, RMSE, biais)      │
  │ - Valeurs prédites et résidus               │
  └─────────────────────────────────────────────┘
```

### Exercice 7.1 : Calibration avec aba_build_model()

Calibrez un modèle de prédiction de la surface terrière.

```{r ex-7-1-setup}
library(lidaRtRee)
library(sf)
# Charger et préparer les données
if (requireNamespace("lidaRtRee", quietly = TRUE)) {
  data("quatre_montagnes", package = "lidaRtRee", envir = environment())
  plots <- quatre_montagnes
  # Simuler des métriques LiDAR (pour démonstration)
  set.seed(42)
  n <- nrow(plots)
  metrics <- data.frame(
    zmax = plots$G_m2_ha * 0.8 + rnorm(n, 5, 3),
    zmean = plots$G_m2_ha * 0.4 + rnorm(n, 3, 2),
    zsd = runif(n, 3, 10),
    zq95 = plots$G_m2_ha * 0.7 + rnorm(n, 5, 4),
    pzabove2 = pmin(0.95, plots$G_m2_ha / 60 + rnorm(n, 0.1, 0.1)),
    imean = runif(n, 200, 400)
  )
  rownames(metrics) <- plots$plot_id
}
```

```{r ex-7-1, exercise=TRUE, exercise.timelimit=180, exercise.setup="ex-7-1-setup"}
library(lidaRtRee)

cat("=== Calibration du modèle ABA ===\n\n")

# Variable cible : Surface terrière (G en m²/ha)
variable <- "G_m2_ha"

cat("Variable cible:", variable, "\n")
cat("Nombre de placettes:", nrow(plots), "\n")
cat("Métriques disponibles:", paste(names(metrics), collapse = ", "), "\n\n")

# Calibration avec aba_build_model()
model_aba <- aba_build_model(
  y = plots[, variable],           # Variable terrain
  x = metrics,                      # Métriques LiDAR
  transform = "boxcox",             # Transformation Box-Cox
  nmax = 4,                         # Maximum 4 variables
  xy = plots[, c("X", "Y")]         # Coordonnées pour validation spatiale
)

# Afficher les statistiques
cat("=== Résultats de la calibration ===\n\n")
cat("Variables sélectionnées:", paste(model_aba$stats$variables, collapse = " + "), "\n\n")

cat("Statistiques:\n")
cat("  R² ajusté:", round(model_aba$stats$r2_adj, 3), "\n")
cat("  R² validation croisée:", round(model_aba$stats$r2_cv, 3), "\n")
cat("  RMSE:", round(model_aba$stats$rmse, 2), "m²/ha\n")
cat("  RMSE relatif:", round(model_aba$stats$rmse_rel * 100, 1), "%\n")
cat("  Biais:", round(model_aba$stats$bias, 2), "m²/ha\n")

# Graphique observé vs prédit
aba_plot(model_aba, main = paste("Modèle", variable))
```

### Exercice 7.2 : Calibration de plusieurs variables

Calibrez des modèles pour G, N et D_mean simultanément.

```{r ex-7-2-setup}
library(lidaRtRee)
if (requireNamespace("lidaRtRee", quietly = TRUE)) {
  data("quatre_montagnes", package = "lidaRtRee", envir = environment())
  plots <- quatre_montagnes
  set.seed(42)
  n <- nrow(plots)
  metrics <- data.frame(
    zmax = plots$G_m2_ha * 0.8 + rnorm(n, 5, 3),
    zmean = plots$G_m2_ha * 0.4 + rnorm(n, 3, 2),
    zsd = runif(n, 3, 10),
    zq95 = plots$G_m2_ha * 0.7 + rnorm(n, 5, 4),
    pzabove2 = pmin(0.95, plots$G_m2_ha / 60 + rnorm(n, 0.1, 0.1)),
    imean = runif(n, 200, 400)
  )
  rownames(metrics) <- plots$plot_id
}
```

```{r ex-7-2, exercise=TRUE, exercise.timelimit=180, exercise.setup="ex-7-2-setup"}
library(lidaRtRee)

cat("=== Calibration multi-variables ===\n\n")

# Variables à modéliser
variables <- c("G_m2_ha", "N_ha", "D_mean_cm")

# Calibrer un modèle pour chaque variable
models_aba <- list()
for (var in variables) {
  cat("Calibration de", var, "...\n")
  models_aba[[var]] <- aba_build_model(
    y = plots[, var],
    x = metrics,
    transform = "boxcox",
    nmax = 4,
    xy = plots[, c("X", "Y")]
  )
}

# Résumé des modèles
cat("\n=== Résumé des modèles ===\n\n")
cat(sprintf("%-12s %8s %8s %10s %8s\n",
            "Variable", "R²_adj", "R²_cv", "RMSE", "RMSE_%"))
cat(sprintf("%-12s %8s %8s %10s %8s\n",
            "--------", "------", "-----", "----", "------"))

for (var in variables) {
  s <- models_aba[[var]]$stats
  cat(sprintf("%-12s %8.3f %8.3f %10.2f %8.1f\n",
              var, s$r2_adj, s$r2_cv, s$rmse, s$rmse_rel * 100))
}

# Variables sélectionnées par modèle
cat("\n\nVariables sélectionnées:\n")
for (var in variables) {
  cat(var, ":", models_aba[[var]]$stats$variables, "\n")
}
```

### Exercice 7.3 : Diagnostics du modèle

Analysez les résidus et la qualité du modèle.

```{r ex-7-3-setup}
library(lidaRtRee)
if (requireNamespace("lidaRtRee", quietly = TRUE)) {
  data("quatre_montagnes", package = "lidaRtRee", envir = environment())
  plots <- quatre_montagnes
  set.seed(42)
  n <- nrow(plots)
  metrics <- data.frame(
    zmax = plots$G_m2_ha * 0.8 + rnorm(n, 5, 3),
    zmean = plots$G_m2_ha * 0.4 + rnorm(n, 3, 2),
    zsd = runif(n, 3, 10),
    zq95 = plots$G_m2_ha * 0.7 + rnorm(n, 5, 4),
    pzabove2 = pmin(0.95, plots$G_m2_ha / 60 + rnorm(n, 0.1, 0.1)),
    imean = runif(n, 200, 400)
  )
  rownames(metrics) <- plots$plot_id
  model_aba <- aba_build_model(plots$G_m2_ha, metrics, transform = "boxcox",
                                nmax = 4, xy = plots[, c("X", "Y")])
}
```
```{r ex-7-3, exercise=TRUE, exercise.timelimit=120, exercise.setup="ex-7-3-setup"}
library(lidaRtRee)

cat("=== Diagnostics du modèle ===\n\n")

# Extraire les valeurs du modèle
observed <- model_aba$values$observed
predicted <- model_aba$values$predicted
residuals <- model_aba$values$residual

# Statistiques des résidus
cat("Statistiques des résidus:\n")
cat("  Moyenne:", round(mean(residuals), 3), "(devrait être ~0)\n")
cat("  Écart-type:", round(sd(residuals), 2), "\n")
cat("  Min:", round(min(residuals), 2), "\n")
cat("  Max:", round(max(residuals), 2), "\n\n")

# Test de corrélation résidus vs observé
cor_test <- cor.test(residuals, observed)
cat("Corrélation résidus/observé:\n")
cat("  r =", round(cor_test$estimate, 3), "\n")
cat("  p-value =", format(cor_test$p.value, digits = 3), "\n")
cat("  (p > 0.05 = pas de biais systématique)\n\n")

# Graphiques de diagnostic
par(mfrow = c(2, 2))

# 1. Observé vs Prédit
plot(observed, predicted, pch = 19, col = "blue",
     xlab = "Observé", ylab = "Prédit",
     main = "Observé vs Prédit")
abline(0, 1, col = "red", lwd = 2)

# 2. Résidus vs Prédit
plot(predicted, residuals, pch = 19, col = "blue",
     xlab = "Prédit", ylab = "Résidus",
     main = "Résidus vs Prédit")
abline(h = 0, col = "red", lwd = 2)

# 3. Distribution des résidus
hist(residuals, breaks = 15, col = "lightblue",
     main = "Distribution des résidus", xlab = "Résidus")

# 4. QQ-plot
qqnorm(residuals, pch = 19, col = "blue", main = "QQ-plot des résidus")
qqline(residuals, col = "red", lwd = 2)
```

### Quiz Calibration ABA

```{r quiz-calibration, echo=FALSE}
quiz(
  question("Que fait la transformation Box-Cox ?",
    answer("Accélère le calcul"),
    answer("Normalise la distribution de la variable cible", correct = TRUE),
    answer("Sélectionne les variables"),
    answer("Calcule les coordonnées"),
    allow_retry = TRUE
  ),
  question("Pourquoi utiliser la validation croisée spatiale ?",
    answer("Pour accélérer le calcul"),
    answer("Pour tenir compte de l'autocorrélation spatiale des données", correct = TRUE),
    answer("Pour augmenter le R²"),
    answer("Pour réduire le nombre de variables"),
    allow_retry = TRUE
  ),
  question("Que signifie un R²cv inférieur au R²adj ?",
    answer("Le modèle est parfait"),
    answer("Il y a probablement du sur-ajustement", correct = TRUE),
    answer("Les données sont incorrectes"),
    answer("La transformation a échoué"),
    allow_retry = TRUE
  )
)
```


## Section 8 : Cartographie et Prédiction

*Basé sur l'article [Area-based 3: Mapping and inference](https://lidar.pages-forge.inrae.fr/lidaRtRee/articles/area-based.3.mapping.and.inference.html) de lidaRtRee*

### Principe de la cartographie ABA

Une fois les modèles calibrés, la fonction `aba_predict()` permet de les appliquer à une carte de métriques LiDAR pour produire des prédictions "wall-to-wall" (mur à mur) sur l'ensemble de la zone d'étude.

```
            Flux de cartographie aba_predict()

  Entrées:
  ┌─────────────────────────────────────────────┐
  │ model = modèle calibré (aba_build_model)    │
  │ metrics_map = raster multi-couches (lasR)   │
  │ stratum = couche de stratification (optim.) │
  └─────────────────────────────────────────────┘
                      │
                      ▼
  ┌─────────────────────────────────────────────┐
  │ 1. Application du modèle pixel par pixel    │
  │ 2. Transformation inverse (Box-Cox)         │
  │ 3. Stratification si plusieurs modèles      │
  └─────────────────────────────────────────────┘
                      │
                      ▼
  Sorties:
  ┌─────────────────────────────────────────────┐
  │ - Carte des prédictions (SpatRaster)        │
  │ - Valeurs en unités terrain (G, V, N, ...)  │
  └─────────────────────────────────────────────┘
```

### Exercice 8.1 : Prédiction avec aba_predict()

Appliquez le modèle calibré pour produire une carte de surface terrière.

```{r ex-8-1-setup}
library(lidaRtRee)
library(terra)
library(sf)

# Charger les données de calibration
if (requireNamespace("lidaRtRee", quietly = TRUE)) {
  data("quatre_montagnes", package = "lidaRtRee", envir = environment())
  plots <- quatre_montagnes

  # Simuler des métriques LiDAR corrélées aux données terrain
  set.seed(42)
  n <- nrow(plots)
  metrics <- data.frame(
    zmax = plots$G_m2_ha * 0.8 + rnorm(n, 5, 3),
    zmean = plots$G_m2_ha * 0.4 + rnorm(n, 3, 2),
    zsd = runif(n, 3, 10),
    zq95 = plots$G_m2_ha * 0.7 + rnorm(n, 5, 4),
    pzabove2 = pmin(0.95, plots$G_m2_ha / 60 + rnorm(n, 0.1, 0.1)),
    imean = runif(n, 200, 400)
  )
  rownames(metrics) <- plots$plot_id

  # Calibrer le modèle
  model_G <- aba_build_model(
    y = plots$G_m2_ha,
    x = metrics,
    transform = "boxcox",
    nmax = 4,
    xy = plots[, c("X", "Y")]
  )
}

# Créer une carte de métriques de démonstration
bbox_demo <- c(xmin = 896000, xmax = 902000, ymin = 6448000, ymax = 6452000)
metrics_map <- rast(nrows = 400, ncols = 600,
                    xmin = bbox_demo["xmin"], xmax = bbox_demo["xmax"],
                    ymin = bbox_demo["ymin"], ymax = bbox_demo["ymax"],
                    nlyrs = 6)
names(metrics_map) <- c("zmax", "zmean", "zsd", "zq95", "pzabove2", "imean")
n_cells <- ncell(metrics_map)

# Simuler des valeurs réalistes
set.seed(123)
values(metrics_map[["zmax"]]) <- runif(n_cells, 15, 40)
values(metrics_map[["zmean"]]) <- runif(n_cells, 8, 25)
values(metrics_map[["zsd"]]) <- runif(n_cells, 2, 12)
values(metrics_map[["zq95"]]) <- runif(n_cells, 12, 38)
values(metrics_map[["pzabove2"]]) <- runif(n_cells, 0.3, 0.95)
values(metrics_map[["imean"]]) <- runif(n_cells, 150, 450)
crs(metrics_map) <- "EPSG:2154"
```

```{r ex-8-1, exercise=TRUE, exercise.timelimit=180, exercise.setup="ex-8-1-setup"}
library(lidaRtRee)
library(terra)

cat("=== Cartographie avec aba_predict() ===\n\n")

# Vérifier que le modèle est calibré
cat("Modèle utilisé:\n")
cat("  Variable:", "G_m2_ha (Surface terrière)\n")
cat("  Variables sélectionnées:", paste(model_G$stats$variables, collapse = " + "), "\n")
cat("  R²cv:", round(model_G$stats$r2_cv, 3), "\n\n")

# Vérifier les couches de la carte de métriques
cat("Carte de métriques:\n")
cat("  Dimensions:", nrow(metrics_map), "x", ncol(metrics_map), "pixels\n")
cat("  Résolution:", res(metrics_map)[1], "m\n")
cat("  Couches:", paste(names(metrics_map), collapse = ", "), "\n\n")

# Appliquer le modèle pour produire la carte de prédiction
prediction_G <- aba_predict(model_G, metrics_map)

cat("=== Carte de prédiction générée ===\n\n")
cat("Statistiques de la prédiction:\n")
pred_values <- values(prediction_G)
cat("  Min:", round(min(pred_values, na.rm = TRUE), 1), "m²/ha\n")
cat("  Max:", round(max(pred_values, na.rm = TRUE), 1), "m²/ha\n")
cat("  Moyenne:", round(mean(pred_values, na.rm = TRUE), 1), "m²/ha\n")
cat("  Écart-type:", round(sd(pred_values, na.rm = TRUE), 1), "m²/ha\n")

# Visualisation
terra::plot(prediction_G,
            main = "Surface terrière prédite (G m²/ha)",
            col = hcl.colors(50, "YlGn"))
```

### Exercice 8.2 : Prédiction stratifiée

Lorsque des modèles sont calibrés séparément par type de peuplement, la prédiction doit être stratifiée.

```{r ex-8-2-setup}
library(lidaRtRee)
library(terra)
library(sf)

# Charger les données et créer deux modèles par strate
if (requireNamespace("lidaRtRee", quietly = TRUE)) {
  data("quatre_montagnes", package = "lidaRtRee", envir = environment())
  plots <- quatre_montagnes

  # Simuler une strate (public/privé ou résineux/feuillus)
  set.seed(42)
  plots$strate <- ifelse(plots$X > median(plots$X), "resineux", "feuillus")

  # Métriques LiDAR simulées
  n <- nrow(plots)
  metrics <- data.frame(
    zmax = plots$G_m2_ha * 0.8 + rnorm(n, 5, 3),
    zmean = plots$G_m2_ha * 0.4 + rnorm(n, 3, 2),
    zsd = runif(n, 3, 10),
    zq95 = plots$G_m2_ha * 0.7 + rnorm(n, 5, 4),
    pzabove2 = pmin(0.95, plots$G_m2_ha / 60 + rnorm(n, 0.1, 0.1)),
    imean = runif(n, 200, 400)
  )
  rownames(metrics) <- plots$plot_id

  # Calibrer un modèle par strate
  idx_res <- plots$strate == "resineux"
  idx_feu <- plots$strate == "feuillus"

  model_resineux <- aba_build_model(
    y = plots$G_m2_ha[idx_res],
    x = metrics[idx_res, ],
    transform = "boxcox", nmax = 3
  )

  model_feuillus <- aba_build_model(
    y = plots$G_m2_ha[idx_feu],
    x = metrics[idx_feu, ],
    transform = "boxcox", nmax = 3
  )
}

# Créer carte de métriques avec couche de strate
bbox_demo <- c(xmin = 896000, xmax = 902000, ymin = 6448000, ymax = 6452000)
metrics_map <- rast(nrows = 200, ncols = 300,
                    xmin = bbox_demo["xmin"], xmax = bbox_demo["xmax"],
                    ymin = bbox_demo["ymin"], ymax = bbox_demo["ymax"],
                    nlyrs = 7)
names(metrics_map) <- c("zmax", "zmean", "zsd", "zq95", "pzabove2", "imean", "strate")
n_cells <- ncell(metrics_map)

set.seed(123)
values(metrics_map[["zmax"]]) <- runif(n_cells, 15, 40)
values(metrics_map[["zmean"]]) <- runif(n_cells, 8, 25)
values(metrics_map[["zsd"]]) <- runif(n_cells, 2, 12)
values(metrics_map[["zq95"]]) <- runif(n_cells, 12, 38)
values(metrics_map[["pzabove2"]]) <- runif(n_cells, 0.3, 0.95)
values(metrics_map[["imean"]]) <- runif(n_cells, 150, 450)
# Strate: 1 = résineux (est), 2 = feuillus (ouest)
coords <- crds(metrics_map)
values(metrics_map[["strate"]]) <- ifelse(coords[, 1] > 899000, 1, 2)
crs(metrics_map) <- "EPSG:2154"
```

```{r ex-8-2, exercise=TRUE, exercise.timelimit=180, exercise.setup="ex-8-2-setup"}
library(lidaRtRee)
library(terra)

cat("=== Prédiction stratifiée ===\n\n")

cat("Modèles par strate:\n")
cat("  Résineux: R²cv =", round(model_resineux$stats$r2_cv, 3), "\n")
cat("  Feuillus: R²cv =", round(model_feuillus$stats$r2_cv, 3), "\n\n")

# Créer les masques de strate
mask_resineux <- metrics_map[["strate"]] == 1
mask_feuillus <- metrics_map[["strate"]] == 2

# Prédire pour chaque strate
pred_resineux <- aba_predict(model_resineux, metrics_map)
pred_feuillus <- aba_predict(model_feuillus, metrics_map)

# Combiner les prédictions selon la strate
prediction_stratifiee <- pred_resineux
values(prediction_stratifiee)[values(mask_feuillus)] <- values(pred_feuillus)[values(mask_feuillus)]

cat("Statistiques par strate:\n")
cat("  Résineux - moyenne:", round(mean(values(pred_resineux)[values(mask_resineux)], na.rm = TRUE), 1), "m²/ha\n")
cat("  Feuillus - moyenne:", round(mean(values(pred_feuillus)[values(mask_feuillus)], na.rm = TRUE), 1), "m²/ha\n\n")

# Visualisation comparative
par(mfrow = c(1, 2))
terra::plot(metrics_map[["strate"]], main = "Carte des strates",
            col = c("darkgreen", "orange"), legend = FALSE)
legend("topright", legend = c("Résineux", "Feuillus"),
       fill = c("darkgreen", "orange"), bty = "n")

terra::plot(prediction_stratifiee, main = "G stratifiée (m²/ha)",
            col = hcl.colors(50, "YlGn"))
```

### Exercice 8.3 : Nettoyage et masquage des cartes

Utilisez `clean_raster()` pour appliquer des seuils et un masque forestier.

```{r ex-8-3-setup}
library(lidaRtRee)
library(terra)
library(sf)

# Créer un modèle et une carte de prédiction
if (requireNamespace("lidaRtRee", quietly = TRUE)) {
  data("quatre_montagnes", package = "lidaRtRee", envir = environment())
  plots <- quatre_montagnes

  set.seed(42)
  n <- nrow(plots)
  metrics <- data.frame(
    zmax = plots$G_m2_ha * 0.8 + rnorm(n, 5, 3),
    zmean = plots$G_m2_ha * 0.4 + rnorm(n, 3, 2),
    zq95 = plots$G_m2_ha * 0.7 + rnorm(n, 5, 4),
    pzabove2 = pmin(0.95, plots$G_m2_ha / 60 + rnorm(n, 0.1, 0.1))
  )
  rownames(metrics) <- plots$plot_id

  model_G <- aba_build_model(plots$G_m2_ha, metrics, transform = "boxcox", nmax = 4)
}

# Carte de métriques et prédiction
bbox_demo <- c(xmin = 896000, xmax = 902000, ymin = 6448000, ymax = 6452000)
metrics_map <- rast(nrows = 200, ncols = 300,
                    xmin = bbox_demo["xmin"], xmax = bbox_demo["xmax"],
                    ymin = bbox_demo["ymin"], ymax = bbox_demo["ymax"],
                    nlyrs = 4)
names(metrics_map) <- c("zmax", "zmean", "zq95", "pzabove2")
n_cells <- ncell(metrics_map)

set.seed(123)
values(metrics_map[["zmax"]]) <- runif(n_cells, 10, 45)
values(metrics_map[["zmean"]]) <- runif(n_cells, 5, 30)
values(metrics_map[["zq95"]]) <- runif(n_cells, 8, 42)
values(metrics_map[["pzabove2"]]) <- runif(n_cells, 0.2, 0.98)
crs(metrics_map) <- "EPSG:2154"

prediction_G <- aba_predict(model_G, metrics_map)

# Créer un masque forêt simulé (60% de la surface)
forest_mask <- rast(prediction_G)
set.seed(456)
forest_values <- runif(n_cells) > 0.4  # 60% forêt
values(forest_mask) <- ifelse(forest_values, 1, NA)
```

```{r ex-8-3, exercise=TRUE, exercise.timelimit=120, exercise.setup="ex-8-3-setup"}
library(lidaRtRee)
library(terra)

cat("=== Nettoyage et masquage des cartes ===\n\n")

# Statistiques avant nettoyage
pred_values <- values(prediction_G)
cat("Avant nettoyage:\n")
cat("  Min:", round(min(pred_values, na.rm = TRUE), 1), "m²/ha\n")
cat("  Max:", round(max(pred_values, na.rm = TRUE), 1), "m²/ha\n")
cat("  Valeurs aberrantes (<0):", sum(pred_values < 0, na.rm = TRUE), "\n")
cat("  Valeurs aberrantes (>80):", sum(pred_values > 80, na.rm = TRUE), "\n\n")

# Nettoyage avec clean_raster()
# Paramètres: seuils [min, max] et masque forestier
prediction_clean <- clean_raster(
  prediction_G,
  thresholds = c(0, 80),     # Surface terrière entre 0 et 80 m²/ha
  mask = forest_mask          # Appliquer le masque forêt
)

# Statistiques après nettoyage
clean_values <- values(prediction_clean)
cat("Après nettoyage:\n")
cat("  Min:", round(min(clean_values, na.rm = TRUE), 1), "m²/ha\n")
cat("  Max:", round(max(clean_values, na.rm = TRUE), 1), "m²/ha\n")
cat("  Pixels NA (hors forêt):", sum(is.na(clean_values)), "\n")
cat("  Pixels valides:", sum(!is.na(clean_values)), "\n\n")

# Visualisation comparative
par(mfrow = c(1, 3))

terra::plot(prediction_G, main = "Prédiction brute",
            col = hcl.colors(50, "YlGn"))

terra::plot(forest_mask, main = "Masque forêt",
            col = c("white", "darkgreen"), legend = FALSE)

terra::plot(prediction_clean, main = "Prédiction nettoyée",
            col = hcl.colors(50, "YlGn"))
```

### Exercice 8.4 : Export des produits nemeton

Exportez les cartes de prédiction pour les indicateurs nemeton.

```{r ex-8-4-setup}
library(lidaRtRee)
library(terra)

# Modèles pour plusieurs variables
if (requireNamespace("lidaRtRee", quietly = TRUE)) {
  data("quatre_montagnes", package = "lidaRtRee", envir = environment())
  plots <- quatre_montagnes

  set.seed(42)
  n <- nrow(plots)
  metrics <- data.frame(
    zmax = plots$G_m2_ha * 0.8 + rnorm(n, 5, 3),
    zmean = plots$G_m2_ha * 0.4 + rnorm(n, 3, 2),
    zq95 = plots$G_m2_ha * 0.7 + rnorm(n, 5, 4),
    pzabove2 = pmin(0.95, plots$G_m2_ha / 60 + rnorm(n, 0.1, 0.1))
  )
  rownames(metrics) <- plots$plot_id

  model_G <- aba_build_model(plots$G_m2_ha, metrics, transform = "boxcox", nmax = 4)
  model_N <- aba_build_model(plots$N_ha, metrics, transform = "boxcox", nmax = 4)
  model_D <- aba_build_model(plots$D_mean_cm, metrics, transform = "boxcox", nmax = 4)
}

# Carte de métriques
bbox_demo <- c(xmin = 896000, xmax = 902000, ymin = 6448000, ymax = 6452000)
metrics_map <- rast(nrows = 100, ncols = 150,
                    xmin = bbox_demo["xmin"], xmax = bbox_demo["xmax"],
                    ymin = bbox_demo["ymin"], ymax = bbox_demo["ymax"],
                    nlyrs = 4)
names(metrics_map) <- c("zmax", "zmean", "zq95", "pzabove2")
n_cells <- ncell(metrics_map)

set.seed(123)
values(metrics_map[["zmax"]]) <- runif(n_cells, 15, 40)
values(metrics_map[["zmean"]]) <- runif(n_cells, 10, 25)
values(metrics_map[["zq95"]]) <- runif(n_cells, 12, 38)
values(metrics_map[["pzabove2"]]) <- runif(n_cells, 0.4, 0.95)
crs(metrics_map) <- "EPSG:2154"

if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
data_dir <- normalizePath(data_dir, mustWork = FALSE)
```

```{r ex-8-4, exercise=TRUE, exercise.timelimit=180, exercise.setup="ex-8-4-setup"}
library(lidaRtRee)
library(terra)

cat("=== Export des produits ABA pour nemeton ===\n\n")

# Générer les prédictions pour chaque variable
prediction_G <- aba_predict(model_G, metrics_map)
prediction_N <- aba_predict(model_N, metrics_map)
prediction_D <- aba_predict(model_D, metrics_map)

# Créer un stack multi-couches
predictions_stack <- c(prediction_G, prediction_N, prediction_D)
names(predictions_stack) <- c("G_m2_ha", "N_ha", "D_mean_cm")

cat("Stack de prédictions créé:\n")
for (i in 1:nlyr(predictions_stack)) {
  layer <- predictions_stack[[i]]
  vals <- values(layer)
  cat(sprintf("  %s: %.1f - %.1f (moy: %.1f)\n",
              names(layer),
              min(vals, na.rm = TRUE),
              max(vals, na.rm = TRUE),
              mean(vals, na.rm = TRUE)))
}

cat("\n=== Correspondance indicateurs nemeton ===\n\n")
cat("G_m2_ha (Surface terrière) → P1 (Production bois)\n")
cat("N_ha (Densité tiges) → E1 (Structure peuplement)\n")
cat("D_mean_cm (Diamètre moyen) → P3 (Qualité bois)\n\n")

# Export (décommenter avec vos données)
# output_dir <- file.path(data_dir, "predictions_aba")
# dir.create(output_dir, showWarnings = FALSE, recursive = TRUE)
#
# writeRaster(predictions_stack,
#             file.path(output_dir, "predictions_aba.tif"),
#             overwrite = TRUE)
#
# cat("Fichier exporté:", file.path(output_dir, "predictions_aba.tif"), "\n")

# Visualisation multi-variable
par(mfrow = c(1, 3))
terra::plot(prediction_G, main = "G (m²/ha)", col = hcl.colors(50, "YlGn"))
terra::plot(prediction_N, main = "N (tiges/ha)", col = hcl.colors(50, "Blues"))
terra::plot(prediction_D, main = "D (cm)", col = hcl.colors(50, "Oranges"))
```

### Quiz Cartographie

```{r quiz-mapping, echo=FALSE}
quiz(
  question("Que fait la fonction aba_predict() ?",
    answer("Calibre un modèle"),
    answer("Applique un modèle calibré à une carte de métriques", correct = TRUE),
    answer("Valide les prédictions"),
    answer("Exporte les résultats"),
    allow_retry = TRUE
  ),
  question("Pourquoi utiliser la stratification ?",
    answer("Pour accélérer le calcul"),
    answer("Pour appliquer des modèles spécifiques par type de peuplement", correct = TRUE),
    answer("Pour réduire la taille des fichiers"),
    answer("Pour changer la résolution"),
    allow_retry = TRUE
  ),
  question("Que fait clean_raster() ?",
    answer("Supprime les fichiers temporaires"),
    answer("Applique des seuils et un masque aux cartes", correct = TRUE),
    answer("Compresse les rasters"),
    answer("Convertit les formats"),
    allow_retry = TRUE
  ),
  question("Quel indicateur nemeton utilise la surface terrière (G) ?",
    answer("B2 - Biodiversité"),
    answer("W1 - Hydrologie"),
    answer("P1 - Production bois", correct = TRUE),
    answer("F1 - Feu"),
    allow_retry = TRUE
  )
)
```

## Section 9 : Quiz Final

### Quiz de validation

```{r quiz-final, echo=FALSE}
quiz(
  caption = "Quiz Final - LiDAR Avancé",

  question("Quelle est la fonction principale d'un LAScatalog ?",
    answer("Compresser les fichiers LiDAR"),
    answer("Référencer plusieurs fichiers sans les charger en mémoire", correct = TRUE),
    answer("Convertir les fichiers en format .las"),
    answer("Visualiser les nuages de points en 3D"),
    allow_retry = TRUE
  ),

  question("Dans BABA, que signifie res = c(10, 20) ?",
    answer("10 bandes, 20 bits"),
    answer("Résolution 10m en sortie, fenêtre 20m pour le calcul", correct = TRUE),
    answer("10% de décimation, 20m de buffer"),
    answer("10 fichiers, 20 tuiles"),
    allow_retry = TRUE
  ),

  question("Quel algorithme est utilisé pour détecter les cimes d'arbres ?",
    answer("Random Forest"),
    answer("K-means"),
    answer("Local Maximum Filter (lmf)", correct = TRUE),
    answer("Principal Component Analysis"),
    allow_retry = TRUE
  ),

  question("Pourquoi la coregistration est-elle importante ?",
    answer("Pour compresser les données"),
    answer("Pour aligner les placettes terrain avec les données LiDAR", correct = TRUE),
    answer("Pour accélérer le traitement"),
    answer("Pour convertir les coordonnées"),
    allow_retry = TRUE
  ),

  question("Quelle métrique LiDAR est la plus utile pour estimer le volume de bois ?",
    answer("zentropy"),
    answer("pzabove2"),
    answer("zq95 (percentile 95 des hauteurs)", correct = TRUE),
    answer("strata_0_2"),
    allow_retry = TRUE
  ),

  question("Quel indicateur nemeton utilise les trouées forestières ?",
    answer("C1 - Carbone"),
    answer("B2 - Structure biodiversité", correct = TRUE),
    answer("P1 - Volume"),
    answer("W1 - TWI"),
    allow_retry = TRUE
  ),

  question("Quel est l'avantage principal de lasR par rapport à lidR ?",
    answer("Plus de fonctionnalités"),
    answer("Interface graphique"),
    answer("Traitement plus rapide et moins de mémoire", correct = TRUE),
    answer("Support de plus de formats"),
    allow_retry = TRUE
  ),

  question("Quelle résolution BABA est recommandée pour nemeton ?",
    answer("1m sortie, 5m fenêtre"),
    answer("10m sortie, 20m fenêtre", correct = TRUE),
    answer("50m sortie, 100m fenêtre"),
    answer("100m sortie, 200m fenêtre"),
    allow_retry = TRUE
  )
)
```

## Synthèse

### Récapitulatif des méthodes lidaRtRee

Ce tutorial a couvert les principales méthodes d'analyse LiDAR forestière de lidaRtRee :

```
            Workflow LiDAR Avancé - lidaRtRee

  ┌─────────────────────────────────────────────────────────┐
  │ Section 3 : Segmentation d'Arbres Individuels           │
  │   - tree_segmentation() : détection + segmentation      │
  │   - tree_extraction() : extraction des attributs        │
  │   → Produits : arbres.gpkg (P1, P3, E1)                 │
  └─────────────────────────────────────────────────────────┘
                          │
  ┌─────────────────────────────────────────────────────────┐
  │ Section 4 : Trouées et Lisières                         │
  │   - gap_detection() : identification des trouées        │
  │   - edge_detection() : lisières par morphologie         │
  │   → Produits : gaps.gpkg, edges.gpkg (B2, L1)           │
  └─────────────────────────────────────────────────────────┘
                          │
  ┌─────────────────────────────────────────────────────────┐
  │ Section 5 : Métriques de Structure                      │
  │   - aba_metrics() : métriques du nuage de points        │
  │   - std_tree_metrics() : métriques d'arbres             │
  │   → Produits : métriques par placette/pixel             │
  └─────────────────────────────────────────────────────────┘
                          │
  ┌─────────────────────────────────────────────────────────┐
  │ Section 6-7 : Approche ABA (Calibration)                │
  │   - clouds_metrics() : extraction sur placettes         │
  │   - aba_build_model() : calibration Box-Cox + stepwise  │
  │   → Produits : modèles calibrés (G, N, D, V)            │
  └─────────────────────────────────────────────────────────┘
                          │
  ┌─────────────────────────────────────────────────────────┐
  │ Section 8 : Cartographie                                │
  │   - aba_predict() : prédiction wall-to-wall             │
  │   - clean_raster() : seuils + masquage forêt            │
  │   → Produits : predictions_aba.tif (C1, P1, P3)         │
  └─────────────────────────────────────────────────────────┘
```

### Produits pour indicateurs nemeton

| Produit               | Fonction lidaRtRee     | Indicateurs       |
|-----------------------|------------------------|-------------------|
| arbres.gpkg           | tree_extraction()      | P1, P3, E1        |
| gaps.gpkg             | gap_detection()        | B2, L1            |
| edges.gpkg            | edge_detection()       | L1                |
| metriques_baba.tif    | lasR BABA              | C1, P1, A1, B2    |
| predictions_G.tif     | aba_predict()          | P1                |
| predictions_V.tif     | aba_predict()          | P1, C1            |
| predictions_N.tif     | aba_predict()          | E1                |

### Optimisation avec lasR

Pour les gros volumes de données, lasR offre des alternatives performantes :

- **Normalisation** : `transform_with(triangulate())`
- **BABA** : `rasterize(res = c(10, 30), ...)`
- **Segmentation** : `local_maximum_raster()` + `region_growing()`

### Ressources

**Documentation lidaRtRee :**

- [Segmentation d'arbres](https://lidar.pages-forge.inrae.fr/lidaRtRee/articles/tree.segmentation.html)
- [Trouées et lisières](https://lidar.pages-forge.inrae.fr/lidaRtRee/articles/gaps.and.edges.detection.html)
- [Métriques de structure](https://lidar.pages-forge.inrae.fr/lidaRtRee/articles/forest.structure.metrics.html)
- [ABA 1: Préparation](https://lidar.pages-forge.inrae.fr/lidaRtRee/articles/area-based.1.data.preparation.html)
- [ABA 2: Calibration](https://lidar.pages-forge.inrae.fr/lidaRtRee/articles/area-based.2.model.calibration.html)
- [ABA 3: Cartographie](https://lidar.pages-forge.inrae.fr/lidaRtRee/articles/area-based.3.mapping.and.inference.html)

**Autres ressources :**

- [lasR documentation](https://r-lidar.github.io/lasR/)
- [lidR book](https://r-lidar.github.io/lidRbook/)
- [BABA article](https://r-lidar.github.io/lasR/articles/baba.html)

### Prochaines étapes

1. **Tutorial 05** : Assembler tous les indicateurs et normaliser
2. **Tutorial 06** : Analyse multi-critères, radar, Pareto, export

**Félicitations !** Vous avez terminé le Tutorial 07 sur le traitement LiDAR avancé avec lidaRtRee.
