---
title: "Tutorial 07 : LiDAR Avancé — LAScatalog, lasR et BABA"
output:
  learnr::tutorial:
    progressive: true
    allow_skip: true
    language: fr
runtime: shiny_prerendered
description: >
  Traitement LiDAR avancé avec LAScatalog pour gros jeux de données,
  pipelines lasR haute performance, segmentation d'arbres avec lidaRtRee,
  détection des trouées/lisières, et approche BABA (Buffered Area-Based)
  pour cartographie haute résolution des indicateurs nemeton.
---

```{r setup, include=FALSE}
library(learnr)

# Options
knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  message = FALSE
)

# Timeout pour les exercices LiDAR avancés (15 min)
options(tutorial.exercise.timelimit = 900)

# Configuration des timeouts réseau (5 minutes)
NETWORK_TIMEOUT <- 300
options(
  timeout = NETWORK_TIMEOUT,
  HTTPUserAgent = "nemeton-tutorial/1.0"
)

# Configuration httr (connect + request timeout)
if (requireNamespace("httr", quietly = TRUE)) {
  httr::set_config(httr::config(
    connecttimeout = NETWORK_TIMEOUT,
    timeout = NETWORK_TIMEOUT
  ))
}

# Configuration GDAL/curl
Sys.setenv(
  GDAL_HTTP_TIMEOUT = as.character(NETWORK_TIMEOUT),
  GDAL_HTTP_CONNECTTIMEOUT = as.character(NETWORK_TIMEOUT),
  CURL_SSL_BACKEND = "openssl"
)

# Configuration parallélisation (6 cores sur 8 disponibles)
N_CORES <- 6L
if (requireNamespace("future", quietly = TRUE)) {
  future::plan(future::multisession, workers = N_CORES)
}
# Configuration lidR pour LAScatalog
options(lidR.progress = TRUE)
# Configuration lasR (si disponible)
if (requireNamespace("lasR", quietly = TRUE)) {
  options(lasR.threads = N_CORES)
}

# =============================================================================
# DONNÉES DU TUTORIEL
# =============================================================================

# Répertoire des données LiDAR (Tutorial 01)
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
data_dir <- normalizePath(data_dir, mustWork = FALSE)

# Charger les placettes lidaRtRee (96 placettes de 15m, projet Newfor)
# Les données sont dans le dossier vignettes/data du package lidaRtRee
lidartree_data_dir <- system.file("extdata", package = "lidaRtRee")
if (lidartree_data_dir == "") {

  # Fallback: chercher dans vignettes/data si extdata n'existe pas

  lidartree_data_dir <- system.file("vignettes", "data", package = "lidaRtRee")
}

# Fonction helper pour charger les placettes Newfor
load_newfor_plots <- function() {
  # Chercher les fichiers de centres de placettes
  plot_centers_file <- file.path(lidartree_data_dir, "aba.model", "field", "plot_centers.csv")


  if (file.exists(plot_centers_file)) {
    centers <- read.csv(plot_centers_file)
    # Créer des géométries circulaires de 15m de rayon
    if (requireNamespace("sf", quietly = TRUE)) {
      plots_sf <- sf::st_as_sf(centers, coords = c("X", "Y"), crs = 2154)
      plots_sf <- sf::st_buffer(plots_sf, dist = 15)
      return(plots_sf)
    }
  }
  return(NULL)
}
```

## Bienvenue

### Objectifs du tutoriel

Ce tutoriel **avancé** vous guide dans le traitement de **gros jeux de données LiDAR** en utilisant des outils professionnels. Il complète le Tutorial 02 avec des techniques plus sophistiquées.

À la fin de ce tutoriel, vous saurez :

1. **Utiliser LAScatalog** pour traiter des données LiDAR multi-tuiles
2. **Créer des pipelines lasR** optimisés pour la performance
3. **Segmenter des arbres individuels** avec lidaRtRee
4. **Détecter trouées et lisières** forestières
5. **Extraire des métriques de structure** avancées
6. **Appliquer l'approche BABA** pour cartographie haute résolution
7. **Coregistrer des placettes terrain** avec le MNH
8. **Exporter les métriques** pour les indicateurs nemeton

### Comparaison avec Tutorial 02

| Aspect | Tutorial 02 | Tutorial 07 (avancé) |
|--------|-------------|----------------------|
| Package principal | lidR | lidR + lasR + lidaRtRee |
| Traitement | Fichier par fichier | LAScatalog (multi-tuiles) |
| Performance | Standard | Haute performance |
| Résolution sortie | 20-30m | 10m (BABA) |
| Segmentation | Non | Arbres individuels |
| Trouées/lisières | Non | Oui |
| Calibration | Non | Oui (ABA/BABA) |
| RAM requise | 4 GB | 8 GB |
| Durée | 60 min | 90-120 min |

### Prérequis

Ce tutoriel combine les données du **Tutorial 01** et du package **lidaRtRee** :

- **Données LiDAR** : Les 18 dalles LiDAR HD IGN téléchargées dans le Tutorial 01 (42 km²)
- **Placettes terrain** : 28 placettes de 15m de rayon couvertes par le LiDAR (7 clusters)
- **Zone d'étude** : Partie centrale du massif des Quatre Montagnes (Vercors)

> **Note** : Le jeu de données lidaRtRee contient 96 placettes sur une zone plus large. Nous utilisons les 28 placettes couvertes par nos dalles LiDAR.

### Packages utilisés

**CORE :**

- `lidR` >= 4.1.1 : Traitement LiDAR standard
- `lasR` : Pipelines haute performance (r-universe)
- `lidaRtRee` >= 4.0.9 : Fonctions forestières (INRAE GitLab)

**SUPPORT :**

- `terra` : Manipulation rasters
- `sf` : Données vectorielles
- `future` : Parallélisation
- `exactextractr` : Extraction par polygone

### Installation des packages spéciaux

```r
# Installation (à exécuter UNE FOIS avant le tutoriel)

# lidR (CRAN)
install.packages('lidR')

# lasR (r-universe uniquement)
install.packages('lasR', repos = 'https://r-lidar.r-universe.dev')

# lidaRtRee (INRAE GitLab)
remotes::install_gitlab('lidar/lidaRtRee', host = 'forge.inrae.fr')
```

### Quiz d'introduction

```{r quiz-intro, echo=FALSE}
question("Quelle est la principale différence entre lidR et lasR ?",
  answer("lasR est une version payante de lidR"),
  answer("lidR charge les données en R, lasR traite en C++ sans exposer les données à R", correct = TRUE),
  answer("lasR ne peut pas lire les fichiers .laz"),
  answer("lidR est plus rapide que lasR"),
  allow_retry = TRUE,
  random_answer_order = TRUE
)
```

## Section 1 : LAScatalog

### Concept du LAScatalog

Un **LAScatalog** est une structure qui référence plusieurs fichiers LiDAR sans les charger en mémoire. Cela permet de :

- **Traiter de gros jeux de données** qui ne tiennent pas en RAM
- **Paralléliser** le traitement sur plusieurs cœurs
- **Gérer automatiquement les buffers** pour éviter les effets de bord

```
                         LAScatalog

   ┌─────┐ ┌─────┐ ┌─────┐ ┌─────┐     Fichiers LiDAR
   │tile1│ │tile2│ │tile3│ │tile4│     (sur disque)
   └──┬──┘ └──┬──┘ └──┬──┘ └──┬──┘
      │       │       │       │
      └───────┴───────┴───────┘
                  │
                  ▼
         ┌───────────────┐
         │  LAScatalog   │  Métadonnées uniquement
         │  (en mémoire) │  (emprises, CRS, stats)
         └───────────────┘
                  │
                  ▼
   ┌─────────────────────────────┐
   │ Traitement par tuiles       │  Charge une tuile à la fois
   │ avec buffer automatique     │  + buffer pour éviter artefacts
   └─────────────────────────────┘
```

### Exercice 1.1 : Création d'un LAScatalog

Créez un LAScatalog à partir des 18 dalles LiDAR HD téléchargées dans le Tutorial 01.

```{r ex-1-1, exercise=TRUE, exercise.timelimit=120}
library(lidR)
library(sf)

# Répertoire des données (Tutorial 01)
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
data_dir <- normalizePath(data_dir, mustWork = FALSE)

# Lister les 18 dalles LiDAR HD des Quatre Montagnes (recherche récursive)
fichiers_laz <- list.files(
  file.path(data_dir, "lidar_hd"),
  pattern = "\\.laz$",
  full.names = TRUE,
  recursive = TRUE
)

cat("Dalles LiDAR trouvées:", length(fichiers_laz), "/ 18 attendues\n")

# Créer le LAScatalog
ctg <- readLAScatalog(fichiers_laz)

# Afficher les informations
print(ctg)
plot(ctg)
```


### Exercice 1.2 : Configuration des options

Configurez les options du LAScatalog pour un traitement optimisé.

```{r ex-1-2-setup}
library(lidR)
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
data_dir <- normalizePath(data_dir, mustWork = FALSE)
fichiers_laz <- list.files(file.path(data_dir, "lidar_hd"),
                           pattern = "\\.laz$", full.names = TRUE, recursive = TRUE)
if (length(fichiers_laz) > 0) {
  ctg <- readLAScatalog(fichiers_laz)
} else {
  ctg <- NULL
}
```

```{r ex-1-2, exercise=TRUE, exercise.timelimit=60, exercise.setup="ex-1-2-setup"}
# === CONFIGURATION PARALLÉLISATION (6 cores sur 8) ===
library(future)
N_CORES <- 6L
plan(multisession, workers = N_CORES)
set_lidr_threads(N_CORES)

cat("=== Configuration parallèle ===\n")
cat("Cores utilisés:", N_CORES, "/ 8 disponibles\n\n")

# === OPTIONS DE TRAITEMENT PAR TUILES ===
opt_chunk_size(ctg) <- 500      # Taille des tuiles en mètres
opt_chunk_buffer(ctg) <- 30     # Buffer en mètres (évite effets de bord)

# Options de sortie
opt_output_files(ctg) <- ""     # "" = retour en mémoire (petit jeu de données)
                                 # ou template comme "{XLEFT}_{YBOTTOM}"

# Options de parallélisation LAScatalog
opt_progress(ctg) <- TRUE       # Afficher la progression

# Vérifier la configuration
cat("=== Configuration LAScatalog ===\n")
cat("Taille tuiles:", opt_chunk_size(ctg), "m\n")
cat("Buffer:", opt_chunk_buffer(ctg), "m\n")
cat("Threads lidR:", get_lidr_threads(), "\n")

# Afficher le découpage prévu
plot(ctg, chunk = TRUE)
```


### Exercice 1.3 : Visualisation avec placettes de calibration

Affichez le LAScatalog avec les placettes de calibration superposées pour visualiser la couverture.

```{r ex-1-3-setup}
library(lidR)
library(sf)
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
data_dir <- normalizePath(data_dir, mustWork = FALSE)
fichiers_laz <- list.files(file.path(data_dir, "lidar_hd"),
                           pattern = "\\.laz$", full.names = TRUE, recursive = TRUE)
if (length(fichiers_laz) > 0) {
  ctg <- readLAScatalog(fichiers_laz)
} else {
  ctg <- NULL
}

# Charger les placettes Quatre Montagnes de lidaRtRee
if (requireNamespace("lidaRtRee", quietly = TRUE) && !is.null(ctg)) {
  data("quatre_montagnes", package = "lidaRtRee", envir = environment())

  # Utiliser l'emprise réelle du LAScatalog (dynamique)
  ctg_extent <- ext(ctg)

  # Filtrer les placettes couvertes par le LiDAR
  covered <- quatre_montagnes$X >= ctg_extent$xmin &
             quatre_montagnes$X <= ctg_extent$xmax &
             quatre_montagnes$Y >= ctg_extent$ymin &
             quatre_montagnes$Y <= ctg_extent$ymax

  placettes_data <- quatre_montagnes[covered, ]
  placettes_calibration <- sf::st_as_sf(placettes_data, coords = c("X", "Y"), crs = 2154)
  placettes_calibration <- sf::st_buffer(placettes_calibration, dist = 15)  # Rayon 15m
} else {
  placettes_calibration <- NULL
}
```

```{r ex-1-3, exercise=TRUE, exercise.timelimit=60, exercise.setup="ex-1-3-setup"}
library(lidR)
library(sf)

# Vérifier que le catalogue et les placettes sont disponibles
if (is.null(ctg)) {
  cat("Catalogue non disponible. Exécutez d'abord le Tutorial 01.\n")
} else if (is.null(placettes_calibration)) {
  cat("Placettes non disponibles. Installez lidaRtRee:\n")
  cat("remotes::install_gitlab('lidar/lidaRtRee', host = 'forge.inrae.fr')\n")
} else {
  # Afficher le catalogue
  cat("=== LAScatalog ===\n")
  print(ctg)

  cat("\n=== Placettes de calibration ===\n")
  cat("Nombre de placettes:", nrow(placettes_calibration), "\n")
  cat("Rayon des placettes: 15 m (surface ≈ 707 m²)\n")

  # Visualisation : catalogue + placettes
  plot(ctg, main = "LAScatalog avec placettes de calibration")
  plot(st_geometry(placettes_calibration), add = TRUE,
       col = "red", border = "darkred", lwd = 2)

  # Ajouter une légende
  legend("topright",
         legend = c("Dalles LiDAR HD", "Placettes terrain (15m)"),
         fill = c("lightblue", "red"),
         border = c("blue", "darkred"),
         bty = "n")

  cat("\nLes placettes rouges seront utilisées pour:\n")
  cat("- Calibrer les modèles BABA (Section 6)\n")
  cat("- Valider les métriques LiDAR (Section 8)\n")
}
```


### Quiz LAScatalog

```{r quiz-catalog, echo=FALSE}
quiz(
  question("Pourquoi utiliser un buffer dans LAScatalog ?",
    answer("Pour augmenter la taille des fichiers"),
    answer("Pour éviter les artefacts aux bords des tuiles", correct = TRUE),
    answer("Pour accélérer le traitement"),
    answer("Pour réduire la mémoire utilisée"),
    allow_retry = TRUE
  ),
  question("Que signifie opt_chunk_size(ctg) <- 500 ?",
    answer("Limiter à 500 fichiers"),
    answer("Traiter par tuiles de 500 x 500 mètres", correct = TRUE),
    answer("Utiliser 500 MB de RAM"),
    answer("Garder 500 points par m²"),
    allow_retry = TRUE
  )
)
```

## Section 2 : Pipelines lasR

### Introduction à lasR

**lasR** est un package haute performance pour le traitement LiDAR. Contrairement à lidR qui charge les données en R, lasR traite directement en C++ sans exposer les données à l'utilisateur.

**Avantages** :
- Traitement 5-10x plus rapide
- Consommation mémoire réduite
- Pipelines chaînables

**Inconvénient** :
- Moins flexible (pas d'accès direct aux points)

```
                    lidR vs lasR

  lidR:                           lasR:
  ┌──────────┐                    ┌──────────┐
  │ Fichier  │                    │ Fichier  │
  │   .laz   │                    │   .laz   │
  └────┬─────┘                    └────┬─────┘
       │                               │
       ▼                               ▼
  ┌──────────┐                    ┌──────────┐
  │ Charger  │                    │ Pipeline │ (défini en R)
  │ en R     │                    │   C++    │
  └────┬─────┘                    └────┬─────┘
       │                               │
       ▼                               ▼
  ┌──────────┐                    ┌──────────┐
  │data.frame│ (en mémoire)       │ Résultat │ (direct)
  └────┬─────┘                    └──────────┘
       │
       ▼
  ┌──────────┐
  │ Traiter  │
  │ en R     │
  └────┬─────┘
       │
       ▼
  ┌──────────┐
  │ Résultat │
  └──────────┘
```

### Exercice 2.1 : Pipeline basique

Créez un pipeline lasR simple pour générer un MNT.

```{r ex-2-1-setup}
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
# Normaliser le chemin pour lasR (C++ ne gère pas le tilde)
data_dir <- normalizePath(data_dir, mustWork = FALSE)
fichiers_laz <- list.files(file.path(data_dir, "lidar_hd"),
                           pattern = "\\.laz$", full.names = TRUE, recursive = TRUE)
```

```{r ex-2-1, exercise=TRUE, exercise.timelimit=300, exercise.setup="ex-2-1-setup"}
# Vérifier que lasR est disponible
if (!requireNamespace("lasR", quietly = TRUE)) {
  cat("lasR n'est pas installé. Installez-le avec:\n")
  cat("install.packages('lasR', repos = 'https://r-lidar.r-universe.dev')\n")
} else {
  library(lasR)

  # Définir le pipeline
  # 1. Lire les fichiers
  # 2. Trianguler les points sol
  # 3. Rasteriser à 1m de résolution
  
  ofile  <- file.path(data_dir, "mnt_lasr.tif")

  pipeline <- reader_las(filter = "-drop_class 7") +
    triangulate(filter = keep_ground()) +
    rasterize(res = 1, operators = "max", ofile = ofile)

  # Afficher le pipeline
  print(pipeline)

  # Note: L'exécution nécessite des données LiDAR
  ans <- lasR::exec(pipeline, on = fichiers_laz[1])
  
  # On affiche le résultat
  print(ans)
  
  cat("\nPipeline créé avec succès !\n")
  
  terra::plot(ans, col = gray.colors(25,0,1), main = "MNT lasR")
}
```



### Exercice 2.2 : Pipeline complexe MNT + MNH

Créez un pipeline complet qui génère plusieurs produits en une seule passe.

```{r ex-2-2-setup}
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
# Normaliser le chemin pour lasR (C++ ne gère pas le tilde)
data_dir <- normalizePath(data_dir, mustWork = FALSE)
fichiers_laz <- list.files(file.path(data_dir, "lidar_hd"),
                           pattern = "\\.laz$", full.names = TRUE, recursive = TRUE)
```

```{r ex-2-2, exercise=TRUE, exercise.timelimit=1800, exercise.setup="ex-2-2-setup"}
# =============================================================================
# GESTION MÉMOIRE - Important pour les gros jeux de données
# =============================================================================
gc()  # Forcer le garbage collection avant traitement
cat("=== Gestion mémoire ===\n")
cat("Mémoire utilisée avant:", round(sum(gc()[, 2]), 1), "MB\n\n")

N_CORES <- 6L

cat("=== Stratégies de parallélisation lasR ===\n\n")
cat("1. sequential()        - Pas de parallélisation (debug)\n")
cat("2. concurrent_points() - Parallélise les étapes dans un fichier (défaut)\n")
cat("3. concurrent_files()  - Traite plusieurs fichiers en parallèle (RAPIDE)\n")
cat("4. nested()            - Combine les deux (experts)\n\n")
cat("Cores utilisés:", N_CORES, "/ 8 disponibles\n")
cat("Stratégie: concurrent_files() - la plus rapide avec SSD\n\n")

library(lidR)
# On crée le catalogue
if (length(fichiers_laz) > 0) {
  ctg <- readLAScatalog(fichiers_laz)
} else {
  ctg <- NULL
}

# On crée un répertoire résultat des calculs
result <- file.path(data_dir, "result_lasr")
if (!dir.exists(result)) {
  dir.create(result, recursive = TRUE)
}

# Vérifier que lasR est disponible
if (!requireNamespace("lasR", quietly = TRUE)) {
  cat("lasR n'est pas installé. Installez-le avec:\n")
  cat("install.packages('lasR', repos = 'https://r-lidar.r-universe.dev')\n")
} else {
  library(lasR)

  # 1. Créer l'étape de triangulation (référencée plus tard)
  tri <- triangulate(filter = keep_ground())

  # Pipeline lasR complet pour nemeton
  pipeline_complet <- reader_las() +

    # 2. MNT depuis points sol
    tri +
    rasterize(res = 1, operators = "max",
              ofile = file.path(result, "lasr_mnt_lidar_*.tif")) +

    # 3. Normalisation des hauteurs (référence l'étape tri)
    transform_with(tri) +

    # 4. MNH (hauteur max normalisée)
    rasterize(res = 1, operators = "max",
              ofile = file.path(result, "lasr_mnh_lidar_*.tif"))

  # Afficher le pipeline
  print(pipeline_complet)

  # Exécution avec stratégie concurrent_files (la plus rapide)
  # Note: Ne pas utiliser tous les cores pour éviter les problèmes de mémoire
  ans <- lasR::exec(pipeline_complet, on = ctg,
                    ncores = concurrent_files(N_CORES))

  # Affiche le resultat
  print(ans)

  cat("\nAvantage: Une seule lecture des fichiers pour tous les produits !")
  cat("\nStratégie concurrent_files:", N_CORES, "fichiers traités en parallèle\n")

  # =============================================================================
  # FUSION DES TUILES EN RASTER VIRTUEL (VRT)
  # =============================================================================
  cat("\n\n=== Création des rasters virtuels (VRT) ===\n")
  
  library(terra)
  # Lister les tuiles produites pour chaque produit
  mnt_tiles <- list.files(result, pattern = "lasr_mnt_lidar_.*\\.tif$", full.names = TRUE)
  mnh_tiles <- list.files(result, pattern = "lasr_mnh_lidar_.*\\.tif$", full.names = TRUE)
  
  cat("Tuiles MNT:", length(mnt_tiles), "\n")
  cat("Tuiles MNH:", length(mnh_tiles), "\n")

  # Créer les VRT avec terra::vrt()
  # Avantage: pas de duplication de données, lecture à la demande
  if (length(mnt_tiles) > 0) {
    mnt_vrt <- vrt(mnt_tiles, file.path(data_dir, "mnt_complet.vrt"), overwrite = TRUE)
    cat("VRT MNT créé:", file.path(data_dir, "mnt_complet.vrt"), "\n")
    cat("  Dimensions:", nrow(mnt_vrt), "x", ncol(mnt_vrt), "pixels\n")
    cat("  Résolution:", res(mnt_vrt)[1], "m\n")
  }

  if (length(mnh_tiles) > 0) {
    mnh_vrt <- vrt(mnh_tiles, file.path(data_dir, "mnh_complet.vrt"), overwrite = TRUE)
    cat("VRT MNH créé:", file.path(data_dir, "mnh_complet.vrt"), "\n")
  }

  cat("\n=== Avantages du VRT ===\n")
  cat("- Pas de duplication de données (fichier XML léger)\n")
  cat("- Lecture à la demande (seules les tuiles nécessaires sont chargées)\n")
  cat("- Compatible GDAL, QGIS, R (terra, stars)\n")
  cat("- Alternative: terra::merge() pour fusion physique (plus lent, plus lourd)\n")
  
  # Création des tif complet
  cat("\n=== Fusion physique du MNT (optionnel) ===\n")
  mnt_merge <- terra::merge(sprc(mnt_tiles))
  writeRaster(mnt_merge, file.path(data_dir, "mnt_complet.tif"), overwrite = TRUE)
  cat("MNT complet écrit:", file.path(data_dir, "mnt_complet.tif"), "\n")
  
  cat("\n=== Fusion physique du MNH (optionnel) ===\n")
  mnh_merge <- terra::merge(sprc(mnh_tiles))
  writeRaster(mnh_merge, file.path(data_dir, "mnh_complet.tif"), overwrite = TRUE)
  cat("MNH complet écrit:", file.path(data_dir, "mnh_complet.tif"), "\n")
  
  # Visualisation du MNT complet
  if (exists("mnt_vrt")) {
    plot(mnt_vrt, main = "MNT complet (VRT)", col = terrain.colors(50))
  }
}
```


### Quiz lasR

```{r quiz-lasr, echo=FALSE}
quiz(
  question("Quel est l'avantage principal de lasR par rapport à lidR ?",
    answer("Plus de fonctionnalités"),
    answer("Traitement plus rapide et moins de mémoire utilisée", correct = TRUE),
    answer("Interface graphique"),
    answer("Support de plus de formats"),
    allow_retry = TRUE
  ),
  question("Comment chaîne-t-on les opérations dans lasR ?",
    answer("Avec des pipes %>%"),
    answer("Avec l'opérateur +", correct = TRUE),
    answer("Avec des listes"),
    answer("Avec des fonctions imbriquées"),
    allow_retry = TRUE
  )
)
```

## Section 3 : Segmentation d'Arbres Individuels

*Basé sur l'article [Tree segmentation](https://lidar.pages-forge.inrae.fr/lidaRtRee/articles/tree.detection.html) de lidaRtRee*

### Principe

La **segmentation d'arbres individuels** (ITD - Individual Tree Detection) permet d'identifier et caractériser chaque arbre à partir du nuage de points LiDAR. Avec **lasR**, le traitement se fait via un pipeline optimisé qui enchaîne :

1. **Triangulation** : maillage TIN des premiers retours (`triangulate()`)
2. **Rastérisation** : génération du CHM haute résolution (`rasterize()`)
3. **Remplissage des puits** : correction des artefacts du CHM (`pit_fill()`)
4. **Détection des maxima locaux** : identification des cimes (`local_maximum_raster()`)
5. **Croissance de région** : délimitation des houppiers (`region_growing()`)

```
                    Pipeline ITD lasR

  Nuage LiDAR ──► triangulate() ──► rasterize() ──► pit_fill()
  (points)           (TIN)            (CHM)         (CHM lissé)
                                                         │
                                                         ▼
                   region_growing() ◄── local_maximum_raster()
                     (houppiers)            (cimes)
                          │                    │
                          ▼                    ▼
                    crowns_*.tif          seeds_*.gpkg
```

### Exercice 3.1 : Segmentation d'arbres avec lasR

Utilisez lasR pour détecter et segmenter les arbres individuels sur les données LiDAR.


```
==========================================================================
 PROBLÈME DES EFFETS DE BORD
==========================================================================
Sans buffer, les arbres à la frontière entre 2 tuiles sont mal segmentés :

     Tuile A          │         Tuile B
                      │
        ████          │          ████
      ████████   ◄────┼────►   ████████
        ████          │          ████
          │           │           │
       Arbre 1    COUPÉ !     Arbre 2
                  en deux

 Solution : traiter avec un BUFFER qui déborde sur les tuiles voisines

     Tuile A + buffer         Tuile B + buffer
     ┌─────────────────┐     ┌─────────────────┐
     │     ████        │     │        ████     │
     │   ████████      │     │      ████████   │
     │     ████        │     │        ████     │
     │       │    zone │     │ zone    │       │
     │    Arbre 1  buffer    buffer  Arbre 2   │
     └─────────────────┘     └─────────────────┘

 lasR ne garde que les résultats dans la zone SANS buffer (déduplication auto)
```

```{r ex-3-1-setup}
library(terra)
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
# Normaliser le chemin pour lasR (C++ ne gère pas le tilde)
data_dir <- normalizePath(data_dir, mustWork = FALSE)
fichiers_laz <- list.files(file.path(data_dir, "lidar_hd"),
                           pattern = "\\.laz$", full.names = TRUE, recursive = TRUE)
```

```{r ex-3-1, exercise=TRUE, exercise.timelimit=2400, exercise.setup="ex-3-1-setup"}
# =============================================================================
# GESTION MÉMOIRE - Important pour les gros jeux de données
# =============================================================================
gc()  # Forcer le garbage collection avant traitement
cat("=== Gestion mémoire ===\n")
cat("Mémoire utilisée avant:", round(sum(gc()[, 2]), 1), "MB\n\n")

# Limiter l'utilisation mémoire de terra (50% de la RAM disponible)
# terra::terraOptions(memfrac = 0.5)

# Nombre de cores - RÉDUIRE si problèmes de mémoire
# Chaque core charge des données en mémoire
N_CORES <- 4L  # Réduit de 6 à 4 pour économiser la mémoire

cat("=== Segmentation d'arbres avec lasR ===\n\n")

cat("Pipeline ITD (Individual Tree Detection):\n")
cat("1. reader_las()          - Lecture des fichiers LAS/LAZ\n")
cat("2. triangulate(ground)   - Maillage TIN du sol (DTM)\n")
cat("3. rasterize(DTM)        - DTM à 1m de résolution\n")
cat("4. transform_with(DTM)   - Normalisation des hauteurs (Z = hauteur)\n")
cat("5. triangulate(first)    - Maillage TIN des premiers retours\n")
cat("6. rasterize(CHM)        - CHM à 0.5m de résolution\n")
cat("7. pit_fill()            - Remplissage des trous\n")
cat("8. local_maximum_raster()- Détection des cimes\n")
cat("9. region_growing()      - Segmentation des houppiers\n\n")

cat("Cores utilisés:", N_CORES, "(réduit pour économiser la mémoire)\n")
cat("Stratégie: concurrent_files()\n\n")

library(lidR)
# On crée le catalogue
if (length(fichiers_laz) > 0) {
  ctg <- readLAScatalog(fichiers_laz)
} else {
  ctg <- NULL
}

# On crée un répertoire résultat des calculs
result_itd <- file.path(data_dir, "result_itd")
if (!dir.exists(result_itd)) {
  dir.create(result_itd, recursive = TRUE)
}

# Vérifier que lasR est disponible
if (!requireNamespace("lasR", quietly = TRUE)) {
  cat("lasR n'est pas installé. Installez-le avec:\n")
  cat("install.packages('lasR', repos = 'https://r-lidar.r-universe.dev')\n")
}

if (length(fichiers_laz) == 0) {
  cat("Données LiDAR non trouvées. Exécutez d'abord le Tutorial 01.\n")
} else {
  library(lasR)

  # ==========================================================================
  # PIPELINE ITD lasR COMPLET AVEC NORMALISATION
  # ==========================================================================
  # IMPORTANT: Les données LiDAR brutes ont Z = altitude (ex: 1200m)

  # Pour la détection d'arbres, on a besoin de Z = hauteur (ex: 25m)
  # Solution: créer un DTM puis normaliser avec transform_with()

  # 1. Triangulation du sol pour créer le DTM
  dtm_tri <- triangulate(filter = keep_ground())

  # 2. Rasteriser le DTM à 1m de résolution
  dtm <- lasR::rasterize(1, dtm_tri,
                         ofile = file.path(result_itd, "dtm_*.tif"))

  # 3. Normaliser les hauteurs : Z_nouveau = Z_original - DTM
  # On utilise la triangulation (pas le raster) pour une interpolation exacte
  # Après cette étape, Z représente la hauteur par rapport au sol
  normalize <- transform_with(dtm_tri)

  # 4. Triangulation des premiers retours (sur données normalisées)
  chm_tri <- triangulate(filter = keep_first())

  # 5. Créer le CHM à 0.5m de résolution
  chm <- lasR::rasterize(0.5, chm_tri,
                         ofile = file.path(result_itd, "chm_*.tif"))

  # 6. Remplissage des puits dans le CHM
  chm_filled <- pit_fill(chm,
                         ofile = file.path(result_itd, "c_filled_*.tif"))

  # 7. Détection des maxima locaux (cimes des arbres)
  # Fenêtre de 3m - ajuster selon la densité du peuplement
  # Hauteur minimum 5m (filtre les arbustes)
  seeds <- local_maximum_raster(chm_filled, ws = 3, min_height = 5,
                                ofile = file.path(result_itd, "seeds_*.gpkg"))

  # 8. Segmentation par croissance de région
  tree <- region_growing(chm_filled, seeds,
                         ofile = file.path(result_itd, "crowns_*.tif"))

  # Pipeline ITD complet avec normalisation
  pipeline_itd <- reader_las() +
    dtm_tri +      # Triangulation sol
    dtm +          # Raster DTM
    normalize +    # Normalisation Z = hauteur
    chm_tri +      # Triangulation premiers retours
    chm +          # Raster CHM
    chm_filled +   # CHM sans trous
    seeds +        # Cimes détectées
    tree           # Houppiers segmentés

  # Afficher le pipeline
  print(pipeline_itd)

  # ==========================================================================
  # GESTION DES EFFETS DE BORD (buffer)
  # ==========================================================================
  # Problème : les arbres à cheval sur 2 tuiles sont mal segmentés
  # Solution : traiter chaque tuile avec un buffer, puis ne garder que
  #            les résultats dans la zone centrale
  #
  # Buffer recommandé : diamètre max des houppiers (15-30m en forêt tempérée)
  BUFFER_SIZE <- 20  # mètres

  # Exécution avec stratégie concurrent_files et buffer
  cat("\n=== Exécution sur", length(fichiers_laz), "dalles LiDAR ===\n")
  cat("Stratégie: concurrent_files(", N_CORES, ")\n")
  cat("Buffer:", BUFFER_SIZE, "m (évite les effets de bord)\n\n")

  ans <- lasR::exec(pipeline_itd, on = ctg,
                    buffer = BUFFER_SIZE,
                    ncores = concurrent_files(N_CORES))

  # Affiche le resultat
  print(ans)

  cat("\nAvantage: Une seule lecture des fichiers pour tous les produits ITD !")
  cat("\nStratégie concurrent_files:", N_CORES, "fichiers traités en parallèle\n")

  cat("\n=== Fichiers générés dans result_itd/ ===\n")
  cat("- dtm_*.tif : tuiles DTM (altitude du sol)\n")
  cat("- chm_*.tif : tuiles CHM (hauteur de canopée)\n")
  cat("- c_filled_*.tif : tuiles CHM sans trous\n")
  cat("- crowns_*.tif : tuiles de segmentation\n")
  cat("- seeds_*.gpkg : cimes détectées par tuile\n")
}
```

### Exercice 3.2 : Fusion VRT et visualisation des résultats

Après l'exécution du pipeline ITD, fusionnez les tuiles en rasters virtuels (VRT)
et visualisez les résultats sur une zone de 100m × 100m.

```{r ex-3-2-setup}
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
data_dir <- normalizePath(data_dir, mustWork = FALSE)
```

```{r ex-3-2, exercise=TRUE, exercise.timelimit=300, exercise.setup="ex-3-2-setup"}
library(terra)
library(sf)

# ==========================================================================
# FUSION DES TUILES EN RASTER VIRTUEL (VRT)
# ==========================================================================
cat("=== Création des rasters virtuels (VRT) ===\n\n")

result_itd <- file.path(data_dir, "result_itd")

dtm_tiles <- list.files(result_itd, pattern = "^dtm_.*\\.tif$", full.names = TRUE)
chm_tiles <- list.files(result_itd, pattern = "^chm_.*\\.tif$", full.names = TRUE)
c_filled_tiles <- list.files(result_itd, pattern = "^c_filled_.*\\.tif$", full.names = TRUE)
crown_tiles <- list.files(result_itd, pattern = "^crowns_.*\\.tif$", full.names = TRUE)
seed_files <- list.files(result_itd, pattern = "^seeds_.*\\.gpkg$", full.names = TRUE)

cat("Tuiles trouvées:\n")
cat("- DTM:", length(dtm_tiles), "\n")
cat("- CHM:", length(chm_tiles), "\n")
cat("- CHM filled:", length(c_filled_tiles), "\n")
cat("- Crowns:", length(crown_tiles), "\n")
cat("- Seeds:", length(seed_files), "\n\n")

if (length(chm_tiles) == 0) {
  cat("Aucune tuile trouvée. Exécutez d'abord l'exercice 3.1.\n")
} else {
  # Créer les VRT avec terra::vrt()
  dtm_vrt <- vrt(dtm_tiles, file.path(data_dir, "dtm_complet.vrt"), overwrite = TRUE)
  cat("VRT DTM créé:", file.path(data_dir, "dtm_complet.vrt"), "\n")
  cat("  Dimensions:", nrow(dtm_vrt), "x", ncol(dtm_vrt), "pixels\n")
  cat("  Résolution:", res(dtm_vrt)[1], "m\n")

  chm_vrt <- vrt(chm_tiles, file.path(data_dir, "chm_complet.vrt"), overwrite = TRUE)
  cat("VRT CHM créé:", file.path(data_dir, "chm_complet.vrt"), "\n")
  cat("  Dimensions:", nrow(chm_vrt), "x", ncol(chm_vrt), "pixels\n")
  cat("  Résolution:", res(chm_vrt)[1], "m\n")

  c_filled_vrt <- vrt(c_filled_tiles, file.path(data_dir, "c_filled_complet.vrt"), overwrite = TRUE)
  cat("VRT CHM filled créé:", file.path(data_dir, "c_filled_complet.vrt"), "\n")

  crowns_vrt <- vrt(crown_tiles, file.path(data_dir, "crowns_complet.vrt"), overwrite = TRUE)
  cat("VRT Crowns créé:", file.path(data_dir, "crowns_complet.vrt"), "\n")

  # Fusionner les seeds (points) en un seul fichier
  seeds_list <- lapply(seed_files, sf::st_read, quiet = TRUE)
  seeds_all <- do.call(rbind, seeds_list)
  sf::st_write(seeds_all, file.path(data_dir, "seeds_complet.gpkg"),
               delete_dsn = TRUE, quiet = TRUE)
  cat("Seeds fusionnés:", nrow(seeds_all), "arbres détectés\n")

  cat("\n=== Avantages du VRT ===\n")
  cat("- Pas de duplication de données (fichier XML léger)\n")
  cat("- Lecture à la demande (seules les tuiles nécessaires sont chargées)\n")
  cat("- Compatible GDAL, QGIS, R (terra, stars)\n")

  # ==========================================================================
  # STATISTIQUES DU PEUPLEMENT
  # ==========================================================================
  cat("\n=== Statistiques du peuplement ===\n")
  cat("Nombre d'arbres:", nrow(seeds_all), "\n")
  cat("Hauteur moyenne:", round(mean(seeds_all$Z, na.rm = TRUE), 1), "m\n")
  cat("Hauteur max:", round(max(seeds_all$Z, na.rm = TRUE), 1), "m\n")
  cat("Hauteur min:", round(min(seeds_all$Z, na.rm = TRUE), 1), "m\n")

  # ==========================================================================
  # FUSION PHYSIQUE (optionnel - pour export)
  # ==========================================================================
  cat("\n=== Fusion physique des rasters ===\n")
  dtm_merge <- terra::merge(sprc(dtm_tiles))
  writeRaster(dtm_merge, file.path(data_dir, "dtm_complet.tif"), overwrite = TRUE)
  cat("DTM complet:", file.path(data_dir, "dtm_complet.tif"), "\n")

  chm_merge <- terra::merge(sprc(chm_tiles))
  writeRaster(chm_merge, file.path(data_dir, "chm_complet.tif"), overwrite = TRUE)
  cat("CHM complet:", file.path(data_dir, "chm_complet.tif"), "\n")

  crown_merge <- terra::merge(sprc(crown_tiles))
  writeRaster(crown_merge, file.path(data_dir, "crown_complet.tif"), overwrite = TRUE)
  cat("Crowns complet:", file.path(data_dir, "crown_complet.tif"), "\n")

  # ==========================================================================
  # VISUALISATION : ZOOM 100m x 100m CENTRÉ (2x2 graphiques)
  # ==========================================================================
  col_elev <- grDevices::colorRampPalette(c("darkgreen", "yellow", "brown", "white"))(25)
  col_height <- grDevices::colorRampPalette(c("blue", "cyan2", "yellow", "red"))(25)
  col_crowns <- grDevices::colorRampPalette(c("purple", "blue", "cyan2", "yellow", "red", "green"))(50)

  # Calculer le centre de l'emprise
  e <- terra::ext(chm_vrt)
  center_x <- (e$xmin + e$xmax) / 2
  center_y <- (e$ymin + e$ymax) / 2

  # Créer une emprise de 100m x 100m centrée
  zoom_ext <- terra::ext(
    center_x - 50, center_x + 50,
    center_y - 50, center_y + 50
  )

  # Cropper les rasters sur la zone de zoom
  dtm_zoom <- terra::crop(dtm_vrt, zoom_ext)
  chm_zoom <- terra::crop(chm_vrt, zoom_ext)
  chm_filled_zoom <- terra::crop(c_filled_vrt, zoom_ext)
  crowns_zoom <- terra::crop(crowns_vrt, zoom_ext)

  # Filtrer les cimes dans l'emprise de zoom (utiliser bbox du raster croppé)
  seeds_zoom <- sf::st_crop(seeds_all, sf::st_bbox(chm_zoom))

  cat("\n=== Visualisation : zoom 100m x 100m centré ===\n")
  cat("Centre:", round(center_x), ",", round(center_y), "\n")
  cat("Arbres dans la zone:", nrow(seeds_zoom), "\n\n")

  # Affichage 2x2 : DTM + CHM en haut, CHM filled + Crowns en bas
  par(mfrow = c(2, 2), mar = c(2, 2, 3, 4))

  # Ligne 1 : DTM et CHM
  plot(dtm_zoom, main = "DTM - Altitude sol (1m)", col = col_elev)
  plot(chm_zoom, main = "CHM - Hauteur canopée (0.5m)", col = col_height)

  # Ligne 2 : CHM filled et Houppiers
  plot(chm_filled_zoom, main = "CHM filled (0.5m)", col = col_height)
  plot(crowns_zoom %% 8, main = "Houppiers + cimes",
       col = col_crowns[sample.int(50, 1000, TRUE)], legend = FALSE)
  # Ajouter les cimes des arbres
  if (nrow(seeds_zoom) > 0) {
    plot(sf::st_geometry(seeds_zoom), add = TRUE, pch = 3, col = "white", cex = 0.8)
  }

  # Nettoyage mémoire
  invisible(gc())
  cat("=== Mémoire libérée ===\n")
}
```

### Exercice 3.3 : Extraction des métriques d'arbres (parallélisé par tuiles)

Cet exercice traite chaque tuile en parallèle pour calculer les métriques
d'arbres équivalentes à `tree_extraction()` de lidaRtRee.

**Avantage** : Traiter les tuiles individuellement est beaucoup plus rapide
que charger le VRT complet, car :
- Chaque tuile est plus petite → vectorisation rapide
- Parallélisation sur plusieurs tuiles simultanément
- Moins de mémoire utilisée

```{r ex-3-3-setup}
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
data_dir <- normalizePath(data_dir, mustWork = FALSE)
result_itd <- file.path(data_dir, "result_itd")
```

```{r ex-3-3, exercise=TRUE, exercise.timelimit=2400, exercise.setup="ex-3-3-setup"}
library(terra)
library(sf)

# ==========================================================================
# LISTER LES TUILES GÉNÉRÉES PAR L'EXERCICE 3.1
# ==========================================================================
cat("=== Recherche des tuiles ===\n\n")

chm_tiles <- list.files(result_itd, pattern = "^c_filled_.*\\.tif$", full.names = TRUE)
crown_tiles <- list.files(result_itd, pattern = "^crowns_.*\\.tif$", full.names = TRUE)
seed_files <- list.files(result_itd, pattern = "^seeds_.*\\.gpkg$", full.names = TRUE)

cat("Tuiles CHM filled:", length(chm_tiles), "\n")
cat("Tuiles Crowns:", length(crown_tiles), "\n")
cat("Fichiers Seeds:", length(seed_files), "\n\n")

if (length(crown_tiles) == 0) {
  cat("Aucune tuile trouvée. Exécutez d'abord l'exercice 3.1.\n")
} else {

  # ==========================================================================
  # FONCTION DE TRAITEMENT D'UNE TUILE
  # ==========================================================================
  # Cette fonction traite une tuile et retourne les métriques des arbres

  process_tile <- function(i, chm_tiles, crown_tiles, seed_files) {
    # Charger les données de la tuile
    chm <- terra::rast(chm_tiles[i])
    crowns <- terra::rast(crown_tiles[i])
    seeds <- sf::st_read(seed_files[i], quiet = TRUE)

    if (nrow(seeds) == 0) return(NULL)

    pixel_area <- terra::res(chm)[1] * terra::res(chm)[2]

    # 1. Vectoriser les houppiers de cette tuile
    crown_polys <- terra::as.polygons(crowns)
    crown_sf <- sf::st_as_sf(crown_polys)
    names(crown_sf)[1] <- "id"

    if (nrow(crown_sf) == 0) return(NULL)

    # 2. Calculer surface et volume
    if (requireNamespace("exactextractr", quietly = TRUE)) {
      zonal_stats <- exactextractr::exact_extract(chm, crown_sf,
                                                   fun = c("count", "sum"),
                                                   progress = FALSE)
      crown_sf$surface <- zonal_stats$count * pixel_area
      crown_sf$volume <- zonal_stats$sum * pixel_area
    } else {
      chm_vals <- terra::values(chm)[, 1]
      crown_vals <- terra::values(crowns)[, 1]
      valid <- !is.na(crown_vals) & crown_vals > 0 & !is.na(chm_vals)

      surf_table <- table(crown_vals[valid])
      surf_df <- data.frame(id = as.integer(names(surf_table)),
                            surface = as.numeric(surf_table) * pixel_area)
      vol_agg <- aggregate(chm_vals[valid], by = list(id = crown_vals[valid]), FUN = sum)
      vol_df <- data.frame(id = vol_agg$id, volume = vol_agg$x * pixel_area)

      crown_sf <- merge(crown_sf, surf_df, by = "id", all.x = TRUE)
      crown_sf <- merge(crown_sf, vol_df, by = "id", all.x = TRUE)
    }

    # 3. Associer les seeds aux segments
    # Note: les seeds sont des POINT Z, la hauteur est dans la géométrie
    coords <- sf::st_coordinates(seeds)
    seeds_vect <- terra::vect(seeds)
    ids_extracted <- terra::extract(crowns, seeds_vect)

    metrics <- data.frame(
      id = ids_extracted[, 2],
      x = coords[, "X"],
      y = coords[, "Y"],
      height = coords[, "Z"]
    )

    # 4. Fusionner avec surface et volume
    crown_data <- sf::st_drop_geometry(crown_sf[, c("id", "surface", "volume")])
    metrics <- merge(metrics, crown_data, by = "id", all.x = TRUE)

    # 5. Ajouter géométrie WKT
    bbox_max <- max(abs(sf::st_bbox(crown_sf)))
    n_digits <- ceiling(log10(bbox_max)) + 2
    crown_sf$crown_geom <- sf::st_as_text(sf::st_geometry(crown_sf), digits = n_digits)

    metrics <- merge(metrics,
                     sf::st_drop_geometry(crown_sf[, c("id", "crown_geom")]),
                     by = "id", all.x = TRUE)

    # Convertir en sf
    sf::st_as_sf(metrics, coords = c("x", "y"), crs = terra::crs(chm))
  }

  # ==========================================================================
  # TRAITEMENT PARALLÈLE DES TUILES
  # ==========================================================================
  cat("=== Traitement des tuiles ===\n")
  t0 <- Sys.time()

  n_tiles <- length(crown_tiles)

  if (requireNamespace("future.apply", quietly = TRUE) && n_tiles > 1) {
    # Traitement parallèle
    N_WORKERS <- min(4, n_tiles)
    future::plan(future::multisession, workers = N_WORKERS)

    cat("Méthode: future.apply (", N_WORKERS, " workers)\n", sep = "")
    cat("Traitement de", n_tiles, "tuiles en parallèle...\n\n")

    results <- future.apply::future_lapply(
      seq_len(n_tiles),
      function(i) process_tile(i, chm_tiles, crown_tiles, seed_files),
      future.seed = TRUE
    )

    future::plan(future::sequential)

  } else {
    # Traitement séquentiel
    cat("Méthode: séquentielle\n")
    cat("Traitement de", n_tiles, "tuiles...\n\n")

    results <- lapply(
      seq_len(n_tiles),
      function(i) {
        cat("  Tuile", i, "/", n_tiles, "\r")
        process_tile(i, chm_tiles, crown_tiles, seed_files)
      }
    )
  }

  t1 <- Sys.time()

  # ==========================================================================
  # FUSION DES RÉSULTATS
  # ==========================================================================
  cat("\n=== Fusion des résultats ===\n")

  # Supprimer les résultats NULL
  results <- results[!sapply(results, is.null)]

  if (length(results) > 0) {
    trees_all <- do.call(rbind, results)

    cat("Temps total:", round(difftime(t1, t0, units = "secs"), 1), "secondes\n")
    cat("Tuiles traitées:", length(results), "/", n_tiles, "\n\n")

    # Sauvegarder
    output_file <- file.path(data_dir, "tree_metrics_complet.gpkg")
    sf::st_write(trees_all, output_file, delete_dsn = TRUE, quiet = TRUE)
    cat("Fichier:", output_file, "\n\n")

    # ==========================================================================
    # RÉSULTATS
    # ==========================================================================
    cat("=== Résultats : Métriques des arbres ===\n")
    cat("Nombre d'arbres:", nrow(trees_all), "\n")
    cat("Hauteur moyenne:", round(mean(trees_all$height, na.rm = TRUE), 1), "m\n")
    cat("Hauteur max:", round(max(trees_all$height, na.rm = TRUE), 1), "m\n")
    cat("Surface moyenne houppier:", round(mean(trees_all$surface, na.rm = TRUE), 1), "m²\n")
    cat("Volume moyen houppier:", round(mean(trees_all$volume, na.rm = TRUE), 1), "m³\n")

    cat("\n=== Premiers arbres ===\n")
    print(head(sf::st_drop_geometry(trees_all[, c("id", "height", "surface", "volume")])))

    cat("\n=== Avantages du traitement par tuiles ===\n")
    cat("- Parallélisation efficace (", N_WORKERS, " tuiles simultanées)\n", sep = "")
    cat("- Mémoire réduite (une tuile à la fois par worker)\n")
    cat("- Scalable : fonctionne avec des centaines de tuiles\n")
  } else {
    cat("Aucun arbre détecté.\n")
  }
}
```

### Quiz Segmentation

```{r quiz-segmentation, echo=FALSE}
quiz(
  question("Quel paramètre contrôle la hauteur minimale des arbres détectés ?",
    answer("sigma"),
    answer("nl_size"),
    answer("hmin", correct = TRUE),
    answer("crown_prop"),
    allow_retry = TRUE
  ),
  question("À quoi sert le filtre médian (nl_filter) ?",
    answer("Accélérer le traitement"),
    answer("Réduire le bruit du MNH avant détection", correct = TRUE),
    answer("Augmenter la résolution"),
    answer("Convertir les coordonnées"),
    allow_retry = TRUE
  ),
  question("Que contient la sortie de tree_extraction() ?",
    answer("Un raster de hauteurs"),
    answer("Un nuage de points"),
    answer("Un objet sf avec les attributs de chaque arbre", correct = TRUE),
    answer("Une liste de fichiers"),
    allow_retry = TRUE
  )
)
```

## Section 4 : Trouées et Lisières

*Basé sur l'article [Gaps and edges detection](https://lidar.pages-forge.inrae.fr/lidaRtRee/articles/gaps.edges.detection.html) de lidaRtRee*

### Principe

Les **trouées** (gaps) et **lisières** (edges) sont des éléments clés de la structure forestière horizontale :

- **Trouées** : Zones ouvertes dans la canopée où la végétation est basse
- **Lisières** : Interfaces entre zones forestières et non-forestières

La fonction `gap_detection()` de lidaRtRee utilise deux critères :

1. **Critère de hauteur** : hauteur de végétation < seuil (ex: 1 m)
2. **Critère de distance** : distance à la végétation environnante > ratio × hauteur végétation

```
            Critères de détection des trouées

  Coupe transversale:
                    ▲ hauteur végétation
      ████          │          ████
      ████          │          ████
      ████    ◄─────┼─────►    ████
      ████    distance à la    ████
      ████    végétation       ████
  ────────────────────────────────────
             TROUÉE

  Si distance > ratio × hauteur → TROUÉE
  Sinon → Juste une zone basse (pas une vraie trouée)
```

### Exercice 4.1 : Détection des trouées sur le catalogue (parallélisé)

Détectez les trouées sur l'ensemble du catalogue LiDAR en utilisant le CHM généré
à la section 3, avec traitement parallélisé par tuile.

```{r ex-4-1-setup}
library(lidaRtRee)
library(terra)
library(sf)
library(future)
library(future.apply)

# Répertoire des données
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
data_dir <- normalizePath(data_dir, mustWork = FALSE)

# Lister les tuiles CHM filled (générées en section 3)
chm_tiles <- list.files(file.path(data_dir, "result_itd"),
                        pattern = "^c_filled_.*\\.tif$",
                        full.names = TRUE)
```

```{r ex-4-1, exercise=TRUE, exercise.timelimit=10000, exercise.setup="ex-4-1-setup"}
library(lidaRtRee)
library(terra)
library(sf)
library(future)
library(future.apply)

cat("=== Détection des trouées sur le catalogue ===\n\n")
cat("Tuiles CHM à traiter:", length(chm_tiles), "\n\n")

# Configuration parallélisation
plan(multisession, workers = 4)

# Paramètres de détection
GAP_MAX_HEIGHT <- 1      # Hauteur max pour être une trouée (m)
GAP_RATIO <- 2           # Distance > ratio × hauteur voisine
MIN_GAP_SURFACE <- 50    # Surface minimum (m²)

# Répertoire pour les masques de trouées (pour réutilisation en 4.2)
gap_mask_dir <- file.path(data_dir, "result_gaps")
dir.create(gap_mask_dir, showWarnings = FALSE, recursive = TRUE)

# Fonction de traitement par tuile
process_gaps_tile <- function(chm_path, tile_id, output_dir) {
  tile_name <- tools::file_path_sans_ext(basename(chm_path))
  mask_file <- file.path(output_dir, paste0("gap_mask_", tile_name, ".tif"))
  gpkg_file <- file.path(output_dir, paste0("gaps_", tile_name, ".gpkg"))

  # Si le masque existe déjà, recharger les données existantes
  if (file.exists(mask_file)) {
    gap_sf <- NULL
    if (file.exists(gpkg_file)) {
      gap_sf <- tryCatch(
        sf::st_read(gpkg_file, quiet = TRUE),
        error = function(e) NULL
      )
    }
    return(list(sf = gap_sf, mask_file = mask_file, skipped = TRUE))
  }

  # Charger le CHM
  chm <- terra::rast(chm_path)

  # Nettoyer les valeurs
  chm[is.na(chm)] <- 0
  chm[chm < 0] <- 0

  # Détection des trouées
  gaps <- gap_detection(
    chm,
    ratio = GAP_RATIO,
    gap_max_height = GAP_MAX_HEIGHT,
    min_gap_surface = MIN_GAP_SURFACE,
    gap_reconstruct = TRUE
  )

  # Sauvegarder le masque binaire des trouées (pour 4.2)
  gap_binary <- gaps$gap_id > 0
  terra::writeRaster(gap_binary, mask_file, overwrite = TRUE)

  # Vectoriser les trouées (gap_id > 0)
  gap_mask <- gaps$gap_id
  gap_mask[gap_mask == 0] <- NA

  if (all(is.na(values(gap_mask)))) {
    return(list(sf = NULL, mask_file = mask_file, skipped = FALSE))
  }

  # Convertir en polygones
  gap_polys <- terra::as.polygons(gap_mask, dissolve = TRUE)
  gap_sf <- sf::st_as_sf(gap_polys)
  names(gap_sf)[1] <- "gap_id"

  # Ajouter les attributs
  gap_sf$tile_id <- tile_id
  gap_sf$area_m2 <- as.numeric(sf::st_area(gap_sf))

  # Décaler les IDs pour éviter les doublons entre tuiles
  gap_sf$gap_id <- gap_sf$gap_id + (tile_id - 1) * 10000

  # Sauvegarder les polygones pour reprise ultérieure
  sf::st_write(gap_sf, gpkg_file, delete_dsn = TRUE, quiet = TRUE)

  list(sf = gap_sf, mask_file = mask_file, skipped = FALSE)
}

# Traitement parallèle
cat("Traitement parallèle en cours...\n")
start_time <- Sys.time()

results <- future_lapply(seq_along(chm_tiles), function(i) {
  process_gaps_tile(chm_tiles[i], i, gap_mask_dir)
}, future.seed = TRUE)

elapsed <- as.numeric(difftime(Sys.time(), start_time, units = "secs"))

# Extraire les SF et les fichiers de masque
sf_list <- lapply(results, `[[`, "sf")
sf_list <- sf_list[!sapply(sf_list, is.null)]
mask_files <- sapply(results, `[[`, "mask_file")
skipped <- sapply(results, `[[`, "skipped")

# Filtrer les fichiers de masque existants
mask_files_exist <- mask_files[file.exists(mask_files)]

# Créer le VRT des masques (pour réutilisation en 4.2)
# Utiliser normalizePath pour résoudre les chemins (évite problèmes avec ~)
gap_mask_vrt <- normalizePath(file.path(data_dir, "gap_mask_complet.vrt"), mustWork = FALSE)
if (length(mask_files_exist) > 0) {
  mask_files_normalized <- normalizePath(mask_files_exist)
  terra::vrt(mask_files_normalized, gap_mask_vrt, overwrite = TRUE)
  cat("VRT créé:", gap_mask_vrt, "\n")
} else {
  cat("Aucun fichier de masque trouvé, VRT non créé\n")
}

cat("\n=== Résultats ===\n")
cat("Temps de traitement:", round(elapsed, 1), "s\n")
cat("Tuiles totales:", length(chm_tiles), "\n")
cat("Tuiles sautées (déjà traitées):", sum(skipped), "\n")
cat("Tuiles nouvellement traitées:", sum(!skipped), "\n")
cat("Fichiers de masque existants:", length(mask_files_exist), "\n")
cat("Tuiles avec trouées:", length(sf_list), "\n")

# Sauvegarder les polygones par tuile pour l'exercice 4.2
gaps_by_tile <- file.path(data_dir, "result_gaps", "gaps_by_tile.rds")
saveRDS(sf_list, gaps_by_tile)
cat("Polygones par tuile sauvegardés:", gaps_by_tile, "\n")

plan(sequential)
```

### Exercice 4.2 : Fusion des polygones de trouées

Fusionnez les polygones de trouées détectés par tuile en un seul fichier
et analysez la distribution des surfaces.

```{r ex-4-2-setup}
library(sf)

# Répertoire des données
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
data_dir <- normalizePath(data_dir, mustWork = FALSE)

# Charger les polygones par tuile (générés en 4.1)
gaps_by_tile <- file.path(data_dir, "result_gaps", "gaps_by_tile.rds")
sf_list <- readRDS(gaps_by_tile)
```

```{r ex-4-2, exercise=TRUE, exercise.timelimit=120, exercise.setup="ex-4-2-setup"}
library(sf)

cat("=== Fusion des polygones de trouées ===\n\n")
cat("Tuiles à fusionner:", length(sf_list), "\n\n")

# Fusionner les polygones de trouées
if (length(sf_list) > 0) {
  gaps_all <- do.call(rbind, sf_list)

  cat("--- STATISTIQUES ---\n")
  cat("Trouées détectées:", nrow(gaps_all), "\n")
  cat("Surface totale:", round(sum(gaps_all$area_m2) / 10000, 2), "ha\n")
  cat("Surface moyenne:", round(mean(gaps_all$area_m2), 1), "m²\n")
  cat("Surface médiane:", round(median(gaps_all$area_m2), 1), "m²\n")
  cat("Surface max:", round(max(gaps_all$area_m2), 1), "m²\n")

  # Sauvegarder en gpkg
  output_file <- file.path(data_dir, "gaps_complet.gpkg")
  sf::st_write(gaps_all, output_file, delete_dsn = TRUE, quiet = TRUE)
  cat("\nSauvegardé:", output_file, "\n")

  # Distribution par classe de surface
  classes <- c(0, 50, 100, 500, 2000, Inf)
  gaps_all$classe <- cut(gaps_all$area_m2, breaks = classes,
                          labels = c("<50", "50-100", "100-500", "500-2000", ">2000"))
  cat("\n--- DISTRIBUTION PAR CLASSE DE SURFACE ---\n")
  print(table(gaps_all$classe))

  # Visualisation
  par(mfrow = c(1, 1))
  plot(sf::st_geometry(gaps_all), col = "forestgreen",
       main = paste("Trouées détectées (n =", nrow(gaps_all), ")"), border = NA)
} else {
  cat("Aucune trouée détectée.\n")
}
```

### Exercice 4.3 : Détection des lisières sur le catalogue (parallélisé)

Détectez les lisières forestières sur l'ensemble du catalogue en réutilisant
les masques de trouées générés en 4.1, avec traitement parallélisé par tuile.

```{r ex-4-3-setup}
library(lidaRtRee)
library(terra)
library(sf)
library(future)
library(future.apply)

# Répertoire des données
if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
data_dir <- normalizePath(data_dir, mustWork = FALSE)

# Lister les tuiles de masques de trouées (générées en 4.1)
gap_mask_tiles <- list.files(file.path(data_dir, "result_gaps"),
                              pattern = "^gap_mask_.*\\.tif$",
                              full.names = TRUE)
```

```{r ex-4-3, exercise=TRUE, exercise.timelimit=3000, exercise.setup="ex-4-3-setup"}
library(lidaRtRee)
library(terra)
library(sf)
library(future)
library(future.apply)

cat("=== Détection des lisières sur le catalogue ===\n\n")
cat("Réutilisation des masques de trouées de l'exercice 4.1\n")
cat("Tuiles de masques à traiter:", length(gap_mask_tiles), "\n\n")

# Configuration parallélisation
plan(multisession, workers = 4)

# Fonction de traitement par tuile
process_edges_tile <- function(mask_path, tile_id) {
  # Charger le masque de trouées (généré en 4.1)
  gap_mask <- terra::rast(mask_path)

  # Détection des lisières (internes = côté forêt)
  edges <- edge_detection(gap_mask, inside = TRUE)

  # Statistiques pour cette tuile
  total_pixels <- sum(!is.na(values(gap_mask)))
  edge_pixels <- sum(values(edges), na.rm = TRUE)

  if (edge_pixels == 0) {
    return(NULL)
  }

  # Vectoriser les lisières
  edges[edges == 0] <- NA
  edge_polys <- terra::as.polygons(edges)

  if (nrow(edge_polys) == 0) {
    return(NULL)
  }

  edge_sf <- sf::st_as_sf(edge_polys)
  names(edge_sf)[1] <- "edge_id"

  # Ajouter les attributs
  edge_sf$tile_id <- tile_id
  edge_sf$length_m <- as.numeric(sf::st_length(sf::st_cast(edge_sf, "MULTILINESTRING")))
  edge_sf$edge_id <- edge_sf$edge_id + (tile_id - 1) * 10000

  # Statistiques de la tuile
  attr(edge_sf, "tile_stats") <- list(
    total_pixels = total_pixels,
    edge_pixels = edge_pixels,
    edge_pct = edge_pixels / total_pixels * 100
  )

  edge_sf
}

# Traitement parallèle
cat("Traitement parallèle en cours...\n")
start_time <- Sys.time()

results <- future_lapply(seq_along(gap_mask_tiles), function(i) {
  process_edges_tile(gap_mask_tiles[i], i)
}, future.seed = TRUE)

# Filtrer les résultats NULL
results <- results[!sapply(results, is.null)]

# Fusionner tous les résultats
if (length(results) > 0) {
  # Collecter les stats avant fusion
  all_stats <- lapply(results, function(r) attr(r, "tile_stats"))
  total_pixels_all <- sum(sapply(all_stats, `[[`, "total_pixels"))
  edge_pixels_all <- sum(sapply(all_stats, `[[`, "edge_pixels"))

  edges_all <- do.call(rbind, results)

  elapsed <- as.numeric(difftime(Sys.time(), start_time, units = "secs"))

  cat("\n=== Résultats ===\n")
  cat("Temps de traitement:", round(elapsed, 1), "s\n")
  cat("Tuiles traitées:", length(gap_mask_tiles), "\n")
  cat("Polygones de lisières:", nrow(edges_all), "\n")
  cat("Pourcentage de lisières:", round(edge_pixels_all / total_pixels_all * 100, 2), "%\n")

  # Sauvegarder en gpkg
  output_file <- file.path(data_dir, "edges_complet.gpkg")
  sf::st_write(edges_all, output_file, delete_dsn = TRUE, quiet = TRUE)
  cat("\nFichier sauvegardé:", output_file, "\n")

  # Visualisation
  par(mfrow = c(1, 1))
  plot(sf::st_geometry(edges_all), col = "red",
       main = paste("Lisières détectées (", round(edge_pixels_all / total_pixels_all * 100, 2), "%)"),
       border = NA)
} else {
  cat("Aucune lisière détectée.\n")
}

plan(sequential)
```

### Exercice 4.4 : Statistiques des trouées

Analysez la distribution des tailles de trouées.

```{r ex-4-4-setup}
library(lidaRtRee)
library(terra)
data(chm_chablais3)
chm <- terra::rast(chm_chablais3)
chm[is.na(chm)] <- 0
chm[chm < 0] <- 0
gaps <- gap_detection(chm, ratio = NULL, gap_max_height = 1, min_gap_surface = 0)
```

```{r ex-4-4, exercise=TRUE, exercise.timelimit=60, exercise.setup="ex-4-4-setup"}
library(terra)

# Extraire les surfaces de trouées
gap_ids <- unique(values(gaps$gap_id))
gap_ids <- gap_ids[!is.na(gap_ids) & gap_ids > 0]

# Calculer la surface de chaque trouée
res_pixel <- res(gaps$gap_surface)[1]
gaps_df <- data.frame(
  id = gap_ids,
  surface_m2 = sapply(gap_ids, function(id) {
    sum(values(gaps$gap_id) == id, na.rm = TRUE) * res_pixel^2
  })
)

cat("=== Distribution des tailles de trouées ===\n\n")
cat("Nombre total de trouées:", nrow(gaps_df), "\n")
cat("Surface min:", round(min(gaps_df$surface_m2), 1), "m²\n")
cat("Surface max:", round(max(gaps_df$surface_m2), 1), "m²\n")
cat("Surface médiane:", round(median(gaps_df$surface_m2), 1), "m²\n")
cat("Surface moyenne:", round(mean(gaps_df$surface_m2), 1), "m²\n")

# Classes de surface (pour indicateurs nemeton)
classes <- c(0, 25, 100, 500, 2000, Inf)
gaps_df$classe <- cut(gaps_df$surface_m2, breaks = classes,
                       labels = c("<25", "25-100", "100-500", "500-2000", ">2000"))

cat("\nDistribution par classe:\n")
print(table(gaps_df$classe))

# Histogramme
hist(log10(gaps_df$surface_m2), breaks = 20,
     main = "Distribution des surfaces de trouées",
     xlab = "log10(Surface en m²)", col = "forestgreen")
```

### Quiz Trouées et Lisières

```{r quiz-gaps, echo=FALSE}
quiz(
  question("Que signifie le paramètre ratio=2 dans gap_detection() ?",
    answer("Surface minimum de 2 m²"),
    answer("Distance à la végétation > 2× hauteur de cette végétation", correct = TRUE),
    answer("Hauteur maximum de 2 m"),
    answer("2 trouées minimum"),
    allow_retry = TRUE
  ),
  question("Quelle méthode détecte les lisières à l'intérieur de la forêt ?",
    answer("Dilatation morphologique"),
    answer("Érosion morphologique", correct = TRUE),
    answer("Filtrage médian"),
    answer("Segmentation watershed"),
    allow_retry = TRUE
  ),
  question("Quel indicateur nemeton utilise les trouées forestières ?",
    answer("C1 - Carbone"),
    answer("B2 - Structure biodiversité", correct = TRUE),
    answer("P1 - Volume"),
    answer("W1 - TWI"),
    allow_retry = TRUE
  )
)
```

## Section 5 : Métriques de Structure Forestière

*Basé sur l'article [Forest structure metrics extraction](https://lidar.pages-forge.inrae.fr/lidaRtRee/articles/forest.structure.metrics.html) de lidaRtRee*

### Principe

L'extraction de **métriques de structure forestière** à partir des données LiDAR permet de caractériser la complexité verticale et horizontale des peuplements. lidaRtRee propose plusieurs familles de métriques :

1. **Métriques 2D (CHM)** : statistiques sur le MNH lissé à différentes échelles
2. **Métriques de trouées** : proportion de surface par classe de taille
3. **Métriques d'arbres** : densité, hauteur moyenne, indice de Gini
4. **Métriques 1D (nuage de points)** : percentiles, densité par strate

```
            Familles de métriques lidaRtRee

  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐
  │   Métriques 2D  │  │ Métriques arbres│  │  Métriques 1D   │
  │     (CHM)       │  │  (segmentation) │  │ (nuage points)  │
  ├─────────────────┤  ├─────────────────┤  ├─────────────────┤
  │ - CHM lissé σ   │  │ - Densité /ha   │  │ - Percentiles   │
  │ - % couverture  │  │ - H moyenne     │  │ - Densité/strate│
  │ - Écart-type    │  │ - Gini          │  │ - Intensité     │
  └─────────────────┘  └─────────────────┘  └─────────────────┘
```

### Exercice 5.1a : Normalisation des fichiers LAZ avec lasR (parallélisé)

Normalisez les fichiers LAZ bruts en utilisant le package `lasR` qui offre
un traitement parallélisé natif et performant.

```{r ex-5-1a-setup}
library(lasR)
library(sf)

if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
# Résoudre le chemin complet (évite les problèmes avec ~)
data_dir <- normalizePath(data_dir, mustWork = FALSE)

# Répertoire des fichiers LAZ bruts (téléchargés)
laz_raw_dir <- file.path(data_dir, "lidar_hd")
laz_raw_files <- list.files(laz_raw_dir, pattern = "\\.la[sz]$", full.names = TRUE, recursive = TRUE)

# Répertoire de sortie pour les fichiers normalisés
laz_norm_dir <- file.path(data_dir, "result_laz_normalized")
dir.create(laz_norm_dir, showWarnings = FALSE, recursive = TRUE)
```

```{r ex-5-1a, exercise=TRUE, exercise.timelimit=2400, exercise.setup="ex-5-1a-setup"}
library(lasR)

cat("=== Normalisation des fichiers LAZ avec lasR ===\n\n")

# ==========================================================================
# 1. VÉRIFICATION DES FICHIERS D'ENTRÉE
# ==========================================================================
cat("--- 1. Fichiers LAZ bruts ---\n")

if (length(laz_raw_files) == 0) {
  stop("Aucun fichier LAZ brut trouvé. Exécutez d'abord le téléchargement (section 2).")
}

cat("Fichiers trouvés:", length(laz_raw_files), "\n")
for (f in laz_raw_files) {
  cat("  -", basename(f), "\n")
}
cat("\n")

# ==========================================================================
# 2. CONSTRUCTION DU PIPELINE LASR
# ==========================================================================
cat("--- 2. Construction du pipeline lasR ---\n\n")

# Nombre de cœurs disponibles
n_cores <- parallel::detectCores() - 1
n_cores <- max(1, min(n_cores, 4))  # Entre 1 et 4 cœurs
cat("Cœurs utilisés:", n_cores, "\n\n")

cat("Pipeline de normalisation:\n")
cat("  1. reader_las()      - Lecture des fichiers LAZ\n")
cat("  2. triangulate()     - Triangulation TIN des points sol\n")
cat("  3. transform_with()  - Soustraction du DTM (normalisation)\n")
cat("  4. write_las()       - Écriture des fichiers normalisés\n\n")

# ==========================================================================
# 3. EXÉCUTION DU PIPELINE (PARALLÉLISÉ)
# ==========================================================================
cat("--- 3. Normalisation (parallélisée) ---\n")

# Identifier les fichiers déjà normalisés
files_to_process <- character(0)
files_skipped <- character(0)

for (f in laz_raw_files) {
  # Nom du fichier normalisé attendu
  base_name <- tools::file_path_sans_ext(basename(f))
  norm_file <- file.path(laz_norm_dir, paste0(base_name, "_norm.laz"))

  if (file.exists(norm_file)) {
    files_skipped <- c(files_skipped, f)
  } else {
    files_to_process <- c(files_to_process, f)
  }
}

cat("Fichiers à traiter:", length(files_to_process), "\n")
cat("Fichiers ignorés (déjà normalisés):", length(files_skipped), "\n\n")

if (length(files_skipped) > 0) {
  cat("Fichiers ignorés:\n")
  for (f in files_skipped) {
    cat("  - [SKIP]", basename(f), "\n")
  }
  cat("\n")
}

if (length(files_to_process) > 0) {
  cat("Traitement en cours...\n")
  start_time <- Sys.time()

  # Construction du pipeline lasR
  tri <- triangulate(filter = keep_ground())
  pipeline <- reader_las() +
    tri +
    transform_with(tri, operator = "-") +
    write_las(ofile = paste0(laz_norm_dir, "/*_norm.laz"))

  # Exécution parallélisée sur les fichiers restants

  ans <- exec(pipeline, on = files_to_process, ncores = n_cores, progress = TRUE)

  elapsed <- as.numeric(difftime(Sys.time(), start_time, units = "secs"))
  cat("\nTemps de traitement:", round(elapsed, 1), "s\n")
  cat("Vitesse:", round(length(files_to_process) / elapsed * 60, 1), "fichiers/min\n\n")
} else {
  cat("Tous les fichiers sont déjà normalisés.\n\n")
}

# ==========================================================================
# 4. VÉRIFICATION DES RÉSULTATS
# ==========================================================================
cat("--- 4. Résultats ---\n\n")

norm_files <- list.files(laz_norm_dir, pattern = "\\.laz$", full.names = TRUE)
cat("Fichiers normalisés créés:", length(norm_files), "\n")

total_size_norm <- sum(file.size(norm_files)) / (1024 * 1024)
cat("Taille totale (normalisés):", round(total_size_norm, 1), "Mo\n\n")

for (f in norm_files) {
  cat("  -", basename(f), "-", round(file.size(f) / (1024 * 1024), 1), "Mo\n")
}

# ==========================================================================
# 5. COMPRESSION LAZ ET STATISTIQUES
# ==========================================================================
cat("\n--- 5. Compression LAZ ---\n\n")

# Comparer avec les fichiers bruts
total_size_raw <- sum(file.size(laz_raw_files)) / (1024 * 1024)

cat("Taille fichiers bruts:", round(total_size_raw, 1), "Mo\n")
cat("Taille fichiers normalisés:", round(total_size_norm, 1), "Mo\n")

if (total_size_raw > 0) {
  ratio <- total_size_norm / total_size_raw * 100
  cat("Ratio:", round(ratio, 1), "%\n\n")
}

cat("Format de sortie: LAZ (compression LASzip)\n")
cat("Avantages du LAZ:\n")
cat("  - Compression sans perte (lossless)\n")
cat("  - Réduction typique: 7-20% de la taille LAS\n")
cat("  - Compatible avec tous les outils LiDAR\n")
cat("  - Décompression à la volée lors de la lecture\n")

cat("\nRépertoire de sortie:", laz_norm_dir, "\n")
```

### Exercice 5.1b : Extraction des métriques ABA sur les placettes (parallélisé)

Extrayez les métriques `aba_metrics()` de lidaRtRee sur les placettes terrain
sauvegardées dans le tutoriel T01, en utilisant les fichiers normalisés.

*Basé sur le tutoriel [Area-based 1: Data preparation](https://lidar.pages-forge.inrae.fr/lidaRtRee/articles/area-based.1.data.preparation.html)*

```{r ex-5-1b-setup}
library(lidaRtRee)
library(lidR)
library(sf)
library(future)
library(future.apply)

if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
# Résoudre le chemin complet (évite les problèmes avec ~)
data_dir <- normalizePath(data_dir, mustWork = FALSE)

# Fichiers normalisés par lasR (exercice 5.1a)
laz_norm_dir <- file.path(data_dir, "result_laz_normalized")
laz_files <- list.files(laz_norm_dir, pattern = "\\.laz$", full.names = TRUE)

# Fichier des placettes terrain (créé dans T01)
placettes_gpkg <- file.path(data_dir, "placettes_lidar.gpkg")
```

```{r ex-5-1b, exercise=TRUE, exercise.timelimit=2400, exercise.setup="ex-5-1b-setup"}
library(lidaRtRee)
library(lidR)
library(sf)
library(future)
library(future.apply)

cat("=== Extraction des métriques ABA sur les placettes terrain ===\n\n")

# ==========================================================================
# 1. CHARGEMENT DU CATALOGUE LIDAR
# ==========================================================================
cat("--- 1. Chargement du catalogue LiDAR ---\n")

if (length(laz_files) == 0) {
  stop("Aucun fichier LAZ normalisé trouvé. Exécutez d'abord l'exercice 5.1a.")
}

cat("Source:", laz_norm_dir, "\n")
ctg <- readLAScatalog(laz_files)
opt_progress(ctg) <- FALSE

cat("Fichiers LAZ:", length(laz_files), "\n")
cat("Emprise:", round(st_bbox(ctg)[c("xmin", "ymin", "xmax", "ymax")]), "\n")
cat("Surface totale:", round(st_area(st_as_sfc(st_bbox(ctg))) / 10000, 2), "ha\n\n")

# ==========================================================================
# 2. CHARGEMENT DES PLACETTES TERRAIN
# ==========================================================================
cat("--- 2. Chargement des placettes terrain ---\n")

if (!file.exists(placettes_gpkg)) {
  stop("Fichier placettes_lidar.gpkg non trouvé. Exécutez d'abord l'exercice 6.1 du tutoriel T01.")
}

# Charger les placettes
plots_sf <- st_read(placettes_gpkg, layer = "placettes_metrics", quiet = TRUE)

# Créer un identifiant unique si non présent
if (!"plot_id" %in% names(plots_sf)) {
  plots_sf$plot_id <- seq_len(nrow(plots_sf))
}
cat("Placettes chargées:", nrow(plots_sf), "\n")

# Filtrer les placettes dans l'emprise du catalogue
ctg_bbox <- st_as_sfc(st_bbox(ctg))
plots_in_extent <- plots_sf[st_intersects(plots_sf, ctg_bbox, sparse = FALSE), ]
cat("Placettes dans l'emprise du catalogue:", nrow(plots_in_extent), "\n")

if (nrow(plots_in_extent) == 0) {
  stop("Aucune placette dans l'emprise du catalogue LiDAR.")
}

# Paramètres des placettes
PLOT_RADIUS <- 15  # Rayon standard (m)

cat("Rayon placettes:", PLOT_RADIUS, "m\n")
cat("Surface placette:", round(pi * PLOT_RADIUS^2, 0), "m² (",
    round(pi * PLOT_RADIUS^2 / 10000, 4), "ha)\n\n")

# ==========================================================================
# 3. EXTRACTION DES MÉTRIQUES EN PARALLÈLE
# ==========================================================================
cat("--- 3. Extraction des métriques (parallélisé) ---\n")

# Configuration parallélisation
plan(multisession, workers = 4)

# Fichier de cache pour reprise
cache_file <- file.path(data_dir, "aba_metrics_placettes.rds")

if (file.exists(cache_file)) {
  cat("Chargement depuis le cache...\n")
  metrics_df <- readRDS(cache_file)
  cat("Métriques chargées:", nrow(metrics_df), "placettes\n\n")
} else {
  cat("Traitement en cours...\n")
  start_time <- Sys.time()

  # Fonction d'extraction par placette
  extract_plot_metrics <- function(plot_id, x, y, radius, ctg) {
    tryCatch({
      # Extraire le nuage de points circulaire
      las <- clip_circle(ctg, x, y, radius)

      if (is.null(las) || npoints(las) < 10) {
        return(NULL)
      }

      # Calculer les métriques ABA avec lidaRtRee
      metrics <- aba_metrics(
        z = las$Z,
        i = las$Intensity,
        rn = las$ReturnNumber,
        c = las$Classification,
        hmin = 2
      )

      # Ajouter les métadonnées
      metrics$plot_id <- plot_id
      metrics$X <- x
      metrics$Y <- y
      metrics$n_points <- npoints(las)

      as.data.frame(metrics)
    }, error = function(e) NULL)
  }

  # Extraction parallèle
  coords <- st_coordinates(plots_in_extent)
  results <- future_lapply(seq_len(nrow(plots_in_extent)), function(i) {
    extract_plot_metrics(
      plot_id = plots_in_extent$plot_id[i],
      x = coords[i, 1],
      y = coords[i, 2],
      radius = PLOT_RADIUS,
      ctg = ctg
    )
  }, future.seed = TRUE)

  # Combiner les résultats
  results <- results[!sapply(results, is.null)]
  metrics_df <- do.call(rbind, results)

  elapsed <- as.numeric(difftime(Sys.time(), start_time, units = "secs"))
  cat("Temps de traitement:", round(elapsed, 1), "s\n")
  cat("Placettes traitées:", nrow(metrics_df), "/", nrow(plots_in_extent), "\n\n")

  # Sauvegarder en cache
  saveRDS(metrics_df, cache_file)
  cat("Cache sauvegardé:", cache_file, "\n\n")
}

plan(sequential)

# ==========================================================================
# 4. STATISTIQUES ET VISUALISATION
# ==========================================================================
cat("--- 4. Statistiques des métriques extraites ---\n\n")

cat("Métriques de hauteur:\n")
cat("  zmax  - moy:", round(mean(metrics_df$zmax, na.rm = TRUE), 2), "m,",
    "sd:", round(sd(metrics_df$zmax, na.rm = TRUE), 2), "m\n")
cat("  zmean - moy:", round(mean(metrics_df$zmean, na.rm = TRUE), 2), "m,",
    "sd:", round(sd(metrics_df$zmean, na.rm = TRUE), 2), "m\n")
cat("  zq95  - moy:", round(mean(metrics_df$zq95, na.rm = TRUE), 2), "m,",
    "sd:", round(sd(metrics_df$zq95, na.rm = TRUE), 2), "m\n\n")

cat("Percentiles (moyennes):\n")
cat("  zq25:", round(mean(metrics_df$zq25, na.rm = TRUE), 2), "m\n")
cat("  zq50:", round(mean(metrics_df$zq50, na.rm = TRUE), 2), "m\n")
cat("  zq75:", round(mean(metrics_df$zq75, na.rm = TRUE), 2), "m\n")
cat("  zq95:", round(mean(metrics_df$zq95, na.rm = TRUE), 2), "m\n\n")

cat("Couverture canopée (moyennes):\n")
cat("  > 2m:", round(mean(metrics_df$pzabove2, na.rm = TRUE) * 100, 1), "%\n")
cat("  > zmean:", round(mean(metrics_df$pzabovezmean, na.rm = TRUE) * 100, 1), "%\n\n")

cat("Nombre de métriques par placette:", ncol(metrics_df) - 4, "\n")

# ==========================================================================
# 5. COMPARAISON AVEC LES MÉTRIQUES TERRAIN
# ==========================================================================
cat("\n--- 5. Comparaison avec les métriques existantes ---\n\n")

# Joindre les métriques extraites aux placettes terrain
plots_with_metrics <- merge(
  st_drop_geometry(plots_in_extent),
  metrics_df,
  by = "plot_id",
  suffixes = c("_terrain", "_extrait")
)

if ("zq95" %in% names(plots_in_extent) && "zq95" %in% names(metrics_df)) {
  cat("Corrélation zq95 (terrain vs extrait):",
      round(cor(plots_with_metrics$zq95_terrain, plots_with_metrics$zq95_extrait,
                use = "complete.obs"), 3), "\n")
}

# Visualisation
par(mfrow = c(2, 2))

hist(metrics_df$zq95, breaks = 15, col = "forestgreen",
     main = "Distribution zq95 (extrait)", xlab = "Hauteur (m)")

hist(metrics_df$pzabove2 * 100, breaks = 15, col = "darkgreen",
     main = "Couverture > 2m", xlab = "Couverture (%)")

plot(metrics_df$zq95, metrics_df$pzabove2 * 100, pch = 16, cex = 1.2,
     col = rgb(0, 0.5, 0, 0.7),
     main = "zq95 vs Couverture", xlab = "zq95 (m)", ylab = "Couverture > 2m (%)")

# Carte des placettes
plot(metrics_df$X, metrics_df$Y, pch = 19, cex = 2,
     col = hcl.colors(100, "Greens")[cut(metrics_df$zq95, 100)],
     main = "Carte zq95 par placette", xlab = "X", ylab = "Y", asp = 1)
```

### Exercice 5.2 : Cartographie des métriques d'arbres avec raster_metrics()

Utilisez `raster_metrics()` avec `std_tree_metrics()` pour créer une carte
de métriques d'arbres agrégées par pixel (résolution 25m), comme dans le
workflow ABA de lidaRtRee.

*Basé sur le tutoriel [Area-based 3: Mapping and inference](https://lidar.pages-forge.inrae.fr/lidaRtRee/articles/area-based.3.mapping.and.inference.html)*

```{r ex-5-2-setup}
library(lidaRtRee)
library(terra)
library(sf)

if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
data_dir <- normalizePath(data_dir, mustWork = FALSE)

# Charger les arbres extraits en section 3.3 (avec height, area_m2)
trees_gpkg <- file.path(data_dir, "tree_metrics_complet.gpkg")

if (file.exists(trees_gpkg)) {
  trees <- sf::st_read(trees_gpkg, quiet = TRUE)
  # Adapter les noms pour std_tree_metrics (h, s, v)
  trees$h <- trees$height
  trees$s <- trees$area_m2
  trees$v <- trees$s * trees$h * 0.5  # volume conique approximatif
} else {
  # Fallback sur données exemple
  data(chm_chablais3)
  chm <- terra::rast(chm_chablais3)
  segments <- tree_segmentation(chm, nl_filter = "Median", nl_size = 3,
                                 hmin = 5, crown_prop = 0.5, crown_hmin = 5)
  trees <- tree_extraction(segments, crown = TRUE)
}
```

```{r ex-5-2, exercise=TRUE, exercise.timelimit=300, exercise.setup="ex-5-2-setup"}
library(lidaRtRee)
library(terra)
library(sf)

cat("=== Cartographie des métriques d'arbres (workflow ABA) ===\n\n")

# Résolution de la grille de sortie (25m = taille typique placette ABA)
resolution <- 25
area_ha <- resolution^2 / 10000  # Surface d'un pixel en ha

cat("Paramètres:\n")
cat("  Résolution:", resolution, "m\n")
cat("  Surface pixel:", round(area_ha, 4), "ha\n")
cat("  Arbres détectés:", nrow(trees), "\n\n")

# ==========================================================================
# AGRÉGATION DES MÉTRIQUES PAR PIXEL AVEC raster_metrics()
# ==========================================================================
cat("--- Calcul des métriques par pixel (raster_metrics) ---\n")

# Fonction d'agrégation utilisant std_tree_metrics
metrics_map <- raster_metrics(

  trees,
  res = resolution,
  fun = function(x) {
    if (nrow(x) == 0) return(NULL)
    std_tree_metrics(x, area_ha = area_ha)
  },
  output = "raster"
)

cat("Carte de métriques créée:\n")
cat("  Dimensions:", nrow(metrics_map), "x", ncol(metrics_map), "pixels\n")
cat("  Métriques:", nlyr(metrics_map), "\n")
cat("  Noms:", paste(names(metrics_map)[1:5], collapse = ", "), "...\n\n")

# ==========================================================================
# STATISTIQUES DES MÉTRIQUES CARTOGRAPHIÉES
# ==========================================================================
cat("--- Statistiques des métriques cartographiées ---\n\n")

cat("Densité d'arbres (Tree_density):\n")
cat("  Moyenne:", round(mean(values(metrics_map$Tree_density), na.rm = TRUE), 0), "/ha\n")
cat("  Écart-type:", round(sd(values(metrics_map$Tree_density), na.rm = TRUE), 0), "/ha\n\n")

cat("Hauteur moyenne (Tree_meanH):\n")
cat("  Moyenne:", round(mean(values(metrics_map$Tree_meanH), na.rm = TRUE), 2), "m\n")
cat("  Écart-type:", round(sd(values(metrics_map$Tree_meanH), na.rm = TRUE), 2), "m\n\n")

cat("Indice de Gini (Tree_giniH):\n")
cat("  Moyenne:", round(mean(values(metrics_map$Tree_giniH), na.rm = TRUE), 3), "\n")
cat("  Interprétation: 0 = homogène, 1 = très hétérogène\n\n")

# ==========================================================================
# VISUALISATION
# ==========================================================================
cat("--- Visualisation ---\n")

par(mfrow = c(2, 2))

# Densité d'arbres
plot(metrics_map$Tree_density, main = "Densité d'arbres (/ha)",
     col = hcl.colors(50, "YlGn", rev = TRUE))

# Hauteur moyenne
plot(metrics_map$Tree_meanH, main = "Hauteur moyenne (m)",
     col = hcl.colors(50, "Greens", rev = TRUE))

# Gini (hétérogénéité)
plot(metrics_map$Tree_giniH, main = "Indice de Gini",
     col = hcl.colors(50, "RdYlGn", rev = TRUE))

# Arbres > 20m
plot(metrics_map$TreeSup20_density, main = "Arbres > 20m (/ha)",
     col = hcl.colors(50, "Blues", rev = TRUE))

cat("\nCette carte de métriques peut être utilisée pour:\n")
cat("- Prédire des paramètres forestiers (G, V, biomasse) avec aba_predict()\n")
cat("- Stratifier la forêt par types de peuplements\n")
cat("- Identifier les zones à fort potentiel ou dégradées\n")
```

### Exercice 5.3 : Métriques multi-échelles du CHM

Calculez les métriques du CHM à différentes échelles de lissage.

```{r ex-5-3-setup}
library(lidaRtRee)
library(terra)

if (requireNamespace("rappdirs", quietly = TRUE)) {
  data_dir <- file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data")
} else {
  data_dir <- file.path(path.expand("~"), "nemeton_tutorial_data")
}
data_dir <- normalizePath(data_dir, mustWork = FALSE)

# Utiliser le VRT créé en section 3.2
chm_vrt <- file.path(data_dir, "c_filled_complet.vrt")
if (file.exists(chm_vrt)) {
  chm_full <- terra::rast(chm_vrt)
  # Cropper sur une zone de 500m x 500m au centre
  e <- terra::ext(chm_full)
  center_x <- (e$xmin + e$xmax) / 2
  center_y <- (e$ymin + e$ymax) / 2
  crop_ext <- terra::ext(center_x - 250, center_x + 250,
                         center_y - 250, center_y + 250)
  chm <- terra::crop(chm_full, crop_ext)
} else {
  # Fallback sur données exemple
  data(chm_chablais3)
  chm <- terra::rast(chm_chablais3)
}
chm[is.na(chm)] <- 0
chm[chm < 0] <- 0
```

```{r ex-5-3, exercise=TRUE, exercise.timelimit=300, exercise.setup="ex-5-3-setup"}
library(terra)

cat("=== Métriques multi-échelles du CHM ===\n\n")

# Activer le multithreading terra
n_threads <- max(1, parallel::detectCores() - 1)
terraOptions(threads = n_threads)
cat("Threads terra:", n_threads, "\n")
cat("Dimensions CHM:", nrow(chm), "x", ncol(chm), "pixels\n\n")

# Valeurs sigma pour le lissage gaussien
sigmas <- c(0, 0.5, 1, 2, 4, 8)

# Calculer les écarts-types du CHM lissé à chaque échelle
chm_stats <- list()
for (sigma in sigmas) {
  if (sigma == 0) {
    chm_smooth <- chm
  } else {
    # Lissage gaussien (approximation avec focal)
    w_size <- ceiling(sigma * 3) * 2 + 1
    weights <- matrix(1, w_size, w_size)
    chm_smooth <- focal(chm, w = weights, fun = "mean", na.rm = TRUE)
  }

  chm_stats[[paste0("sigma_", sigma)]] <- list(
    mean = mean(values(chm_smooth), na.rm = TRUE),
    sd = sd(values(chm_smooth), na.rm = TRUE),
    max = max(values(chm_smooth), na.rm = TRUE)
  )
}

cat("Statistiques par échelle de lissage:\n\n")
cat(sprintf("%-10s %8s %8s %8s\n", "Sigma", "Moyenne", "Écart-T", "Max"))
for (name in names(chm_stats)) {
  s <- chm_stats[[name]]
  sigma_val <- gsub("sigma_", "", name)
  cat(sprintf("%-10s %8.2f %8.2f %8.2f\n", sigma_val, s$mean, s$sd, s$max))
}

# Métriques de couverture par classe de hauteur
cat("\n\nCouverture par classe de hauteur:\n")
seuils <- c(0.5, 1, 5, 10, 20)
for (s in seuils) {
  pct <- sum(values(chm) > s, na.rm = TRUE) / sum(!is.na(values(chm))) * 100
  cat(sprintf("  > %2.0f m : %5.1f %%\n", s, pct))
}
```

### Tableau récapitulatif des métriques

| Métrique | Fonction lidaRtRee | Description | Indicateur nemeton |
|----------|-------------------|-------------|-------------------|
| zmax, zmean, zsd | `aba_metrics()` | Statistiques de hauteur | P1, C1, B2 |
| zq25, zq50, zq75, zq95 | `aba_metrics()` | Percentiles | P1 |
| pzabove2, pzabovezmean | `aba_metrics()` | Couverture canopée | A1, C1 |
| N_ha, N_sup10 | `std_tree_metrics()` | Densité d'arbres | P1, E1 |
| H_mean, H_dom | `std_tree_metrics()` | Hauteur moyenne/dominante | P1, P3 |
| Gini | `std_tree_metrics()` | Hétérogénéité (inégalité) | B2 |
| Simpson | calcul manuel | Diversité des classes de hauteur | B2 |
| gap_surface | `gap_detection()` | Surface en trouées | B2 |
| edge_pct | `edge_detection()` | % de lisières | L1 |

### Quiz Métriques

```{r quiz-metrics, echo=FALSE}
quiz(
  question("Que mesure l'indice de Gini sur les hauteurs d'arbres ?",
    answer("La hauteur moyenne"),
    answer("L'inégalité/hétérogénéité des hauteurs", correct = TRUE),
    answer("La densité d'arbres"),
    answer("La couverture du sol"),
    allow_retry = TRUE
  ),
  question("Quelle métrique est la plus utile pour estimer la biomasse ?",
    answer("Gini"),
    answer("pzabove2"),
    answer("zq95 (percentile 95)", correct = TRUE),
    answer("N_ha"),
    allow_retry = TRUE
  ),
  question("À quoi sert le lissage multi-échelles du CHM ?",
    answer("Accélérer le traitement"),
    answer("Capturer la structure à différentes résolutions spatiales", correct = TRUE),
    answer("Corriger les erreurs GPS"),
    answer("Convertir les unités"),
    allow_retry = TRUE
  )
)
```


## Section 6 : Approche ABA — Préparation des Données

*Basé sur l'article [Area-based approach 1: data preparation](https://lidar.pages-forge.inrae.fr/lidaRtRee/articles/area-based.1.data.preparation.html) de lidaRtRee*

Cette section reprend le workflow du tutoriel officiel lidaRtRee, appliqué aux **28 placettes de notre zone d'étude** (clusters Verc-02, 05, 06, C1, C2, S4, S7).

### 6.1 Import des données d'inventaire terrain

96 placettes de rayon 15 m ont été inventoriées dans la zone des Quatre Montagnes (Vercors, France). Les placettes sont regroupées en clusters de 4. Nous travaillons sur 28 d'entre elles (7 clusters).

### Exercice 6.1 : Paramètres d'inventaire et import des données

On définit les paramètres d'inventaire (rayon de placette, seuil de diamètre) puis on importe les fichiers CSV contenant les mesures d'arbres pour les 28 placettes de notre zone d'étude.

```{r ex-6-1-setup}
library(lidaRtRee)
library(lidR)
library(sf)

# Paramètres d'inventaire
p_radius <- 15      # rayon de la placette (m)
dbh_min <- 7.5      # seuil DBH (cm), arbres plus petits non inventoriés

# Chemin vers les données (package nemeton, puis lidaRtRee en fallback)
data_dir <- system.file("extdata", "aba.model", package = "nemeton")
if (data_dir == "") data_dir <- system.file("extdata", "aba.model", package = "lidaRtRee")
if (data_dir == "") stop("Données aba.model non trouvées dans nemeton ni lidaRtRee")
```

```{r ex-6-1, exercise=TRUE, exercise.timelimit=120, exercise.setup="ex-6-1-setup"}
# === 6.1.1 : Import des données d'inventaire arbres ===
cat("=== Paramètres d'inventaire ===\n")
cat("Rayon placette:", p_radius, "m\n")
cat("Seuil DBH:", dbh_min, "cm\n\n")

# Lister les fichiers d'arbres par pattern matching
files_t <- dir(
  path = file.path(data_dir, "field"),
  pattern = "Verc-[[:alnum:]]{2}-[[:digit:]]{1}_ArbresTerrain.csv",
  full.names = TRUE
)
cat("Fichiers d'arbres trouvés:", length(files_t), "\n")

# Filtrer aux 7 clusters de notre zone d'étude
pattern_zone <- "Verc-(02|05|06|C1|C2|S4|S7)-"
files_t <- files_t[grepl(pattern_zone, basename(files_t))]
cat("Fichiers pour nos 28 placettes:", length(files_t), "\n\n")

# Charger le contenu de tous les fichiers avec lapply
trees <- lapply(files_t, function(x) {
  # Lire le tableau
  dummy <- read.table(x, sep = ";", header = TRUE, stringsAsFactors = FALSE)
  # Ajouter une colonne plot_id depuis le nom du fichier
  cbind(dummy, data.frame(plot_id = rep(substr(basename(x), 6, 9), nrow(dummy))))
})

# Fusionner les éléments de la liste en un seul data.frame
trees <- do.call(rbind, trees)

# Ajouter l'info de la zone d'étude dans plot_id
trees$plot_id <- paste0("Verc-", trees$plot_id)

cat("=== Données arbres importées ===\n")
cat("Nombre d'arbres:", nrow(trees), "\n")
cat("Colonnes:", paste(names(trees), collapse = ", "), "\n")
```

### Exercice 6.2 : Standardisation des noms de colonnes

On renomme les colonnes en anglais pour faciliter leur utilisation, on supprime les arbres sans mesure de diamètre, et on convertit les codes d'apparence et d'espèce en facteurs.

```{r ex-6-2-setup}
library(lidaRtRee)
data_dir <- system.file("extdata", "aba.model", package = "nemeton")
if (data_dir == "") data_dir <- system.file("extdata", "aba.model", package = "lidaRtRee")
p_radius <- 15
dbh_min <- 7.5

# Import des arbres (28 placettes)
files_t <- dir(file.path(data_dir, "field"),
               pattern = "Verc-[[:alnum:]]{2}-[[:digit:]]{1}_ArbresTerrain.csv",
               full.names = TRUE)
pattern_zone <- "Verc-(02|05|06|C1|C2|S4|S7)-"
files_t <- files_t[grepl(pattern_zone, basename(files_t))]
trees <- lapply(files_t, function(x) {
  dummy <- read.table(x, sep = ";", header = TRUE, stringsAsFactors = FALSE)
  cbind(dummy, data.frame(plot_id = rep(substr(basename(x), 6, 9), nrow(dummy))))
})
trees <- do.call(rbind, trees)
trees$plot_id <- paste0("Verc-", trees$plot_id)
```

```{r ex-6-2, exercise=TRUE, exercise.timelimit=60, exercise.setup="ex-6-2-setup"}
# === 6.1.1 suite : Standardisation des colonnes ===

# Renommer les colonnes en anglais
names(trees) <- c(
  "tree_id", "pole_id", "species", "azimuth_gr", "slope_gr", "diameter_cm",
  "ground_distance_m", "height_m", "appearance", "tilted", "remark", "plot_id"
)

# Supprimer les arbres sans diamètre
trees <- trees[!is.na(trees$diameter_cm), ]

# Ajouter les niveaux de facteur pour appearance
trees$appearance <- factor(trees$appearance, levels = 0:4)
levels(trees$appearance) <- c("missing or lying",
                              "live",
                              "live with broken treetop",
                              "dead with branches",
                              "dead without branches (snag)")

# Convertir species en facteur
trees$species <- factor(trees$species)

cat("=== Données arbres standardisées ===\n")
cat("Nombre d'arbres après nettoyage:", nrow(trees), "\n")
cat("Espèces présentes:", paste(levels(trees$species), collapse = ", "), "\n\n")
head(trees[, c("plot_id", "tree_id", "species", "diameter_cm", "height_m")], n = 5)
```

### Exercice 6.3 : Import des coordonnées des placettes

Cette section importe les coordonnées des centres de placettes.

```{r ex-6-3-setup}
library(lidaRtRee)
library(sf)
data_dir <- system.file("extdata", "aba.model", package = "nemeton")
if (data_dir == "") data_dir <- system.file("extdata", "aba.model", package = "lidaRtRee")
p_radius <- 15
pattern_zone <- "Verc-(02|05|06|C1|C2|S4|S7)"
```

```{r ex-6-3, exercise=TRUE, exercise.timelimit=120, exercise.setup="ex-6-3-setup"}
# === 6.1.2 : Import des coordonnées des placettes ===

# Lister les fichiers de localisation par pattern matching
files_p <- dir(
  path = file.path(data_dir, "field"),
  pattern = "Verc-[[:alnum:]]{2}_PiquetsTerrain.csv",
  full.names = TRUE
)

# Filtrer aux clusters de notre zone
files_p <- files_p[grepl(pattern_zone, basename(files_p))]
cat("Fichiers de localisation:", length(files_p), "\n\n")

# Initialiser le data.frame
plots <- NULL

# Charger tous les fichiers avec une boucle
for (i in files_p) {
  # Lire le fichier
  dummy <- read.table(i, sep = ";", header = TRUE, stringsAsFactors = FALSE)
  # Ajouter au data.frame avec l'info plot_id
  plots <- rbind(plots,
                 cbind(dummy,
                       data.frame(plot_id = rep(substr(basename(i), 6, 7),
                                                nrow(dummy)))))
}

# Garder uniquement les données nécessaires (supprimer doublons de mesure)
plots <- plots[is.element(plots$Id, c("p1", "p2", "p3", "p4")), ]

# Ajouter plot_id au cluster_id
plots$cluster_id <- paste0("Verc-", substr(plots$plot_id, 1, 2))
plots$plot_id <- paste(plots$cluster_id, substr(plots$Id, 2, 2), sep = "-")

# Garder uniquement les coordonnées et Id
plots <- plots[, c("X", "Y", "plot_id", "cluster_id")]

cat("=== Placettes importées ===\n")
cat("Nombre de placettes:", nrow(plots), "\n\n")

# Convertir en objet spatial sf
plots_sf <- sf::st_as_sf(plots, coords = c("X", "Y"))
sf::st_crs(plots_sf) <- 2154

# Ajouter les coordonnées dans le data.frame de l'objet sf
plots_sf <- cbind(plots_sf, data.frame(sf::st_coordinates(plots_sf)))

cat("Aperçu des placettes:\n")
print(head(plots_sf[, c("plot_id", "cluster_id", "X", "Y")], n = 6))
```

### Exercice 6.4 : Calcul des coordonnées des arbres

Les coordonnées des arbres sont calculées à partir des coordonnées du centre de la placette et des mesures d'azimut, de pente et de distance au sol.

```{r ex-6-4-setup}
library(lidaRtRee)
library(sf)
data_dir <- system.file("extdata", "aba.model", package = "nemeton")
if (data_dir == "") data_dir <- system.file("extdata", "aba.model", package = "lidaRtRee")
p_radius <- 15
dbh_min <- 7.5
pattern_zone <- "Verc-(02|05|06|C1|C2|S4|S7)"

# Import arbres
files_t <- dir(file.path(data_dir, "field"),
               pattern = "Verc-[[:alnum:]]{2}-[[:digit:]]{1}_ArbresTerrain.csv",
               full.names = TRUE)
files_t <- files_t[grepl(paste0(pattern_zone, "-"), basename(files_t))]
trees <- lapply(files_t, function(x) {
  dummy <- read.table(x, sep = ";", header = TRUE, stringsAsFactors = FALSE)
  cbind(dummy, data.frame(plot_id = rep(substr(basename(x), 6, 9), nrow(dummy))))
})
trees <- do.call(rbind, trees)
trees$plot_id <- paste0("Verc-", trees$plot_id)
names(trees) <- c("tree_id", "pole_id", "species", "azimuth_gr", "slope_gr",
                  "diameter_cm", "ground_distance_m", "height_m", "appearance",
                  "tilted", "remark", "plot_id")
trees <- trees[!is.na(trees$diameter_cm), ]
trees$appearance <- factor(trees$appearance, levels = 0:4)
levels(trees$appearance) <- c("missing or lying", "live", "live with broken treetop",
                              "dead with branches", "dead without branches (snag)")
trees$species <- factor(trees$species)

# Import placettes
files_p <- dir(file.path(data_dir, "field"),
               pattern = "Verc-[[:alnum:]]{2}_PiquetsTerrain.csv",
               full.names = TRUE)
files_p <- files_p[grepl(pattern_zone, basename(files_p))]
plots <- NULL
for (i in files_p) {
  dummy <- read.table(i, sep = ";", header = TRUE, stringsAsFactors = FALSE)
  plots <- rbind(plots, cbind(dummy, data.frame(plot_id = rep(substr(basename(i), 6, 7), nrow(dummy)))))
}
plots <- plots[is.element(plots$Id, c("p1", "p2", "p3", "p4")), ]
plots$cluster_id <- paste0("Verc-", substr(plots$plot_id, 1, 2))
plots$plot_id <- paste(plots$cluster_id, substr(plots$Id, 2, 2), sep = "-")
plots <- plots[, c("X", "Y", "plot_id", "cluster_id")]
plots_sf <- sf::st_as_sf(plots, coords = c("X", "Y"))
sf::st_crs(plots_sf) <- 2154
plots_sf <- cbind(plots_sf, data.frame(sf::st_coordinates(plots_sf)))

# Import métadonnées (convergence, déclinaison)
meta_file <- file.path(data_dir, "field", "plot.metadata.csv")
if (file.exists(meta_file)) {
  meta <- read.table(meta_file, sep = ";", header = TRUE)
  meta <- meta[, c("Id", "Convergence_gr", "Declinaison_gr")]
  names(meta) <- c("cluster_id", "convergence_gr", "declination_gr")
  plots_sf <- merge(plots_sf, meta)
} else {
  plots_sf$convergence_gr <- 0
  plots_sf$declination_gr <- 0
}
```

```{r ex-6-4, exercise=TRUE, exercise.timelimit=120, exercise.setup="ex-6-4-setup"}
# === 6.1.3 : Calcul des coordonnées projetées des arbres ===

# Fusionner trees et plots pour importer le centre de la placette
trees <- merge(trees, plots_sf[, c("X", "Y", "convergence_gr",
                                    "declination_gr", "plot_id")],
               by = "plot_id")

cat("Arbres après fusion avec coordonnées placettes:", nrow(trees), "\n\n")

# Calculer les coordonnées projetées avec polar2Projected
dummy <- lidaRtRee::polar2Projected(
  trees$X, trees$Y, 0,
  trees$azimuth_gr / 200 * pi,
  trees$ground_distance_m,
  trees$slope_gr / 200 * pi,
  trees$declination_gr / 200 * pi,
  trees$convergence_gr / 200 * pi,
  trees$diameter_cm / 100
)

# Ajouter les coordonnées au data.frame trees
trees[, c("X", "Y", "horiz_dist_m")] <- dummy[, c("x", "y", "d")]

cat("=== Coordonnées arbres calculées ===\n")
head(trees[, c("plot_id", "tree_id", "X", "Y", "horiz_dist_m", "height_m")], n = 5)
```

### Exercice 6.5 : Extraction des nuages de points

On extrait les nuages de points LiDAR aux emplacements des 28 placettes depuis les fichiers LAZ (normalisés et originaux). Cette extraction est effectuée une seule fois et les fichiers sont sauvegardés pour réutilisation.

Les fichiers LAZ doivent être normalisés, avec l'attribut Z contenant la hauteur au-dessus du sol.

```{r ex-6-5-setup}
library(lidaRtRee)
library(lidR)
library(sf)

p_radius <- 15
pattern_zone <- "Verc-(02|05|06|C1|C2|S4|S7)"

# Charger les données quatre_montagnes pour avoir les coordonnées
data("quatre_montagnes", package = "lidaRtRee", envir = environment())
plots <- quatre_montagnes[grepl(paste0("^", pattern_zone, "-"), quatre_montagnes$plot_id), ]
plots_sf <- sf::st_as_sf(plots, coords = c("X", "Y"), crs = 2154)
plots_sf <- cbind(plots_sf, X = plots$X, Y = plots$Y)

# Répertoire des données
data_dir <- normalizePath(file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data"), mustWork = FALSE)

# Répertoires source
laz_dir_normalized <- file.path(data_dir, "result_laz_normalized")
laz_dir_original <- file.path(data_dir, "lidar_hd", "NUALHD_1-0__LAZ_LAMB93_PM_2025-03-25")

# Répertoires destination (fichiers pré-extraits)
plots_extracted_norm <- file.path(data_dir, "plots_extracted_norm")
plots_extracted_orig <- file.path(data_dir, "plots_extracted_orig")
dir.create(plots_extracted_norm, recursive = TRUE, showWarnings = FALSE)
dir.create(plots_extracted_orig, recursive = TRUE, showWarnings = FALSE)

# Créer les LAScatalog pour l'extraction
ctg_normalized <- lidR::readLAScatalog(laz_dir_normalized)
lidR::projection(ctg_normalized) <- 2154
lidR::opt_progress(ctg_normalized) <- FALSE

ctg_original <- lidR::readLAScatalog(laz_dir_original)
lidR::opt_progress(ctg_original) <- FALSE
```

```{r ex-6-5, exercise=TRUE, exercise.timelimit=900, exercise.setup="ex-6-5-setup"}
# === 6.2.1 : Extraction et sauvegarde des nuages de points ===
# Cette étape extrait les placettes une seule fois et les sauvegarde
# pour réutilisation dans les exercices suivants

cat("=== Extraction des placettes depuis les tuiles LiDAR HD ===\n\n")
cat("Placettes à traiter:", nrow(plots), "\n\n")

# --- 1. LAZ NORMALISÉS (Z = hauteur) ---
cat("--- 1. LAZ Normalisés (pour métriques de hauteur) ---\n")
cat("Source:", laz_dir_normalized, "\n")
cat("Destination:", plots_extracted_norm, "\n\n")

existing_norm <- list.files(plots_extracted_norm, pattern = "\\.laz$", full.names = TRUE)
existing_norm_ids <- gsub("\\.laz$", "", basename(existing_norm))
plots_to_extract_norm <- plots[!plots$plot_id %in% existing_norm_ids, ]

if (nrow(plots_to_extract_norm) == 0) {
  cat(">>> Tous les fichiers normalisés existent déjà !\n\n")
} else {
  cat("À extraire:", nrow(plots_to_extract_norm), "\n")
  for (i in seq_len(nrow(plots_to_extract_norm))) {
    plot_id <- plots_to_extract_norm$plot_id[i]
    output_file <- file.path(plots_extracted_norm, paste0(plot_id, ".laz"))
    tryCatch({
      las <- lidR::clip_circle(ctg_normalized,
                                plots_to_extract_norm$X[i],
                                plots_to_extract_norm$Y[i],
                                p_radius)
      if (!lidR::is.empty(las)) {
        las$Z[las$Z < 0] <- 0
        lidR::writeLAS(las, output_file)
        cat("  [", i, "/", nrow(plots_to_extract_norm), "]", plot_id, "OK\n")
      }
    }, error = function(e) {
      cat("  [", i, "/", nrow(plots_to_extract_norm), "]", plot_id, "ERREUR\n")
    })
  }
}

# --- 2. LAZ ORIGINAUX (Z = altitude) ---
cat("\n--- 2. LAZ Originaux (pour métriques terrain) ---\n")
cat("Source:", laz_dir_original, "\n")
cat("Destination:", plots_extracted_orig, "\n\n")

existing_orig <- list.files(plots_extracted_orig, pattern = "\\.laz$", full.names = TRUE)
existing_orig_ids <- gsub("\\.laz$", "", basename(existing_orig))
plots_to_extract_orig <- plots[!plots$plot_id %in% existing_orig_ids, ]

if (nrow(plots_to_extract_orig) == 0) {
  cat(">>> Tous les fichiers originaux existent déjà !\n\n")
} else {
  cat("À extraire:", nrow(plots_to_extract_orig), "\n")
  for (i in seq_len(nrow(plots_to_extract_orig))) {
    plot_id <- plots_to_extract_orig$plot_id[i]
    output_file <- file.path(plots_extracted_orig, paste0(plot_id, ".laz"))
    tryCatch({
      las <- lidR::clip_circle(ctg_original,
                                plots_to_extract_orig$X[i],
                                plots_to_extract_orig$Y[i],
                                p_radius)
      if (!lidR::is.empty(las)) {
        lidR::writeLAS(las, output_file)
        cat("  [", i, "/", nrow(plots_to_extract_orig), "]", plot_id, "OK\n")
      }
    }, error = function(e) {
      cat("  [", i, "/", nrow(plots_to_extract_orig), "]", plot_id, "ERREUR\n")
    })
  }
}

# --- 3. Charger et afficher le résumé ---
cat("\n=== Résumé ===\n")
laz_norm_files <- list.files(plots_extracted_norm, pattern = "\\.laz$", full.names = TRUE)
laz_orig_files <- list.files(plots_extracted_orig, pattern = "\\.laz$", full.names = TRUE)
cat("LAZ normalisés:", length(laz_norm_files), "fichiers\n")
cat("LAZ originaux:", length(laz_orig_files), "fichiers\n\n")

# Charger un exemple
if (length(laz_norm_files) > 0) {
  llas_height <- purrr::map(laz_norm_files[1], lidR::readLAS)
  names(llas_height) <- gsub("\\.laz$", "", basename(laz_norm_files[1]))
  cat("Exemple -", names(llas_height)[1], ":\n")
  print(llas_height[[1]])
}

cat("\n>>> Ces fichiers seront réutilisés automatiquement dans les exercices suivants.\n")
```

### Exercice 6.6 : Statistiques de terrain

La fonction `terrain_points_metrics()` calcule l'aspect, l'altitude et la pente en ajustant un plan.

```{r ex-6-6-setup}
library(lidaRtRee)
library(lidR)

p_radius <- 15
pattern_zone <- "Verc-(02|05|06|C1|C2|S4|S7)"

# Charger quatre_montagnes pour les coordonnées
data("quatre_montagnes", package = "lidaRtRee", envir = environment())
plots <- quatre_montagnes[grepl(paste0("^", pattern_zone, "-"), quatre_montagnes$plot_id), ]

# Répertoire des données
data_dir <- normalizePath(file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data"), mustWork = FALSE)

# Charger les LAZ ORIGINAUX pré-extraits (exercice 6.5)
plots_extracted_orig <- file.path(data_dir, "plots_extracted_orig")
laz_orig_files <- list.files(plots_extracted_orig, pattern = "\\.laz$", full.names = TRUE)
llas_original <- purrr::map(laz_orig_files, lidR::readLAS)
names(llas_original) <- gsub("\\.laz$", "", basename(laz_orig_files))
```

```{r ex-6-6, exercise=TRUE, exercise.timelimit=180, exercise.setup="ex-6-6-setup"}
# === 6.2.2 : Calcul des statistiques de terrain ===
# NOTE: On utilise les LAZ non-normalisés pour avoir l'altitude vraie

cat("=== Calcul des métriques de terrain ===\n")
cat("Nuages originaux (non-normalisés):", length(llas_original), "\n")
cat("Placettes:", nrow(plots), "\n\n")

# Calculer les métriques terrain pour chaque placette
metrics_list <- list()

for (i in seq_along(llas_original)) {
  plot_name <- names(llas_original)[i]
  las <- llas_original[[i]]

  # Trouver les coordonnées du centre
  plot_row <- which(plots$plot_id == plot_name)

  if (length(plot_row) == 0) {
    cat("Placette", plot_name, "non trouvée dans plots\n")
    next
  }

  center_xy <- as.numeric(plots[plot_row, c("X", "Y")])

  # Calculer les métriques terrain (altitude, pente, aspect)
  tryCatch({
    result <- lidaRtRee::terrain_points_metrics(las, center_xy, p_radius)
    metrics_list[[plot_name]] <- result
  }, error = function(e) {
    cat("Erreur pour", plot_name, ":", e$message, "\n")
  })
}

cat("Métriques calculées pour", length(metrics_list), "placettes\n\n")

# Fusionner les résultats en data.frame
if (length(metrics_list) > 0) {
  metrics_terrain <- as.data.frame(do.call(rbind, metrics_list))

  cat("=== Métriques de terrain ===\n")
  cat("Dimensions:", nrow(metrics_terrain), "x", ncol(metrics_terrain), "\n")
  cat("Colonnes:", paste(names(metrics_terrain), collapse = ", "), "\n\n")
  print(round(head(metrics_terrain), 2))

  # Sauvegarder pour réutilisation dans les exercices suivants
  cache_dir <- file.path(data_dir, "metrics_cache")
  dir.create(cache_dir, recursive = TRUE, showWarnings = FALSE)
  saveRDS(metrics_terrain, file.path(cache_dir, "metrics_terrain.rds"))
  cat("\n>>> Métriques terrain sauvegardées pour réutilisation.\n")
} else {
  cat("ERREUR: Aucune métrique calculée\n")
  cat("Vérifiez que les nuages contiennent des points sol (Classification == 2)\n")
}
```

### Exercice 6.7 : Cohérence avec le protocole

On vérifie que les données d'inventaire sont cohérentes avec le protocole (placettes de 15 m de rayon, seuil DBH de 7.5 cm) et on affiche les statistiques des variables de peuplement pour nos 28 placettes.

```{r ex-6-7-setup}
library(lidaRtRee)
library(lidR)
data_dir <- system.file("extdata", "aba.model", package = "nemeton")
if (data_dir == "") data_dir <- system.file("extdata", "aba.model", package = "lidaRtRee")
p_radius <- 15
dbh_min <- 7.5
pattern_zone <- "Verc-(02|05|06|C1|C2|S4|S7)"

# Charger quatre_montagnes
data("quatre_montagnes", package = "lidaRtRee", envir = environment())
plots <- quatre_montagnes[grepl(paste0("^", pattern_zone, "-"), quatre_montagnes$plot_id), ]

# Import des arbres bruts pour avoir azimut et pente
files_t <- dir(file.path(data_dir, "field"),
               pattern = "Verc-[[:alnum:]]{2}-[[:digit:]]{1}_ArbresTerrain.csv",
               full.names = TRUE)
files_t <- files_t[grepl(paste0(pattern_zone, "-"), basename(files_t))]
trees <- lapply(files_t, function(x) {
  dummy <- read.table(x, sep = ";", header = TRUE, stringsAsFactors = FALSE)
  cbind(dummy, data.frame(plot_id = rep(substr(basename(x), 6, 9), nrow(dummy))))
})
trees <- do.call(rbind, trees)
trees$plot_id <- paste0("Verc-", trees$plot_id)
names(trees) <- c("tree_id", "pole_id", "species", "azimuth_gr", "slope_gr",
                  "diameter_cm", "ground_distance_m", "height_m", "appearance",
                  "tilted", "remark", "plot_id")
trees <- trees[!is.na(trees$diameter_cm), ]
```

```{r ex-6-7, exercise=TRUE, exercise.timelimit=60, exercise.setup="ex-6-7-setup"}
# === Vérification de la cohérence avec le protocole ===
cat("=== Vérification des données d'inventaire ===\n\n")

# Le jeu de données quatre_montagnes contient déjà les données nettoyées
# Afficher les statistiques des variables de peuplement
cat("Variables de peuplement pour nos 28 placettes:\n\n")
summary(plots[, c("G_m2_ha", "N_ha", "D_mean_cm")])

# Graphique azimut vs pente pour une placette
cat("\n=== Azimut vs Pente des arbres (placette Verc-02-1) ===\n")
trees_plot <- trees[trees$plot_id == "Verc-02-1", ]

plot(trees_plot$azimuth_gr, trees_plot$slope_gr,
     pch = 19, col = "darkgreen",
     xlab = "Azimut (grades)",
     ylab = "Pente (grades)",
     cex = trees_plot$ground_distance_m / trees_plot$diameter_cm,
     main = paste("Azimut vs Pente - Verc-02-1 (n =", nrow(trees_plot), "arbres)"))
abline(h = 0, col = "red", lty = 2)
grid()
```

### Exercice 6.8 : Relation hauteur-diamètre

On explore la relation allométrique entre le diamètre moyen des arbres et la hauteur dominante (estimée par la hauteur maximale LiDAR) au niveau du peuplement. Cette relation est fondamentale pour les modèles forestiers.

```{r ex-6-8-setup}
library(lidaRtRee)
library(ggplot2)
data_dir <- system.file("extdata", "aba.model", package = "nemeton")
if (data_dir == "") data_dir <- system.file("extdata", "aba.model", package = "lidaRtRee")
pattern_zone <- "Verc-(02|05|06|C1|C2|S4|S7)"

data("quatre_montagnes", package = "lidaRtRee", envir = environment())
plots <- quatre_montagnes[grepl(paste0("^", pattern_zone, "-"), quatre_montagnes$plot_id), ]
```

```{r ex-6-8, exercise=TRUE, exercise.timelimit=60, exercise.setup="ex-6-8-setup"}
# === 6.3.4 : Relation hauteur-diamètre (allométrie) ===
cat("=== Relation hauteur-diamètre au niveau peuplement ===\n\n")

# Au niveau peuplement : relation entre D moyen et hauteur dominante
# (zmax comme proxy de la hauteur dominante)

plot(plots$D_mean_cm, plots$zmax,
     pch = 19, col = "darkgreen",
     xlab = "Diamètre moyen (cm)",
     ylab = "Hauteur max LiDAR (m)",
     main = "Relation D moyen - Hauteur dominante (28 placettes)")

# Ajouter une régression
model <- lm(zmax ~ D_mean_cm, data = plots)
abline(model, col = "red", lwd = 2)

# Afficher le R²
r2 <- summary(model)$r.squared
legend("topleft", legend = paste("R² =", round(r2, 3)), bty = "n")
```

### Exercice 6.9 : Superposition CHM et arbres terrain

On visualise le modèle numérique de canopée (CHM) d'une placette avec les positions des arbres inventoriés sur le terrain. Cette superposition permet de valider la qualité du calage géographique entre données LiDAR et données terrain.

```{r ex-6-9-setup}
library(lidaRtRee)
library(lidR)
library(terra)

p_radius <- 15
pattern_zone <- "Verc-(02|05|06|C1|C2|S4|S7)"

data("quatre_montagnes", package = "lidaRtRee", envir = environment())
plots <- quatre_montagnes[grepl(paste0("^", pattern_zone, "-"), quatre_montagnes$plot_id), ]

# Répertoire des données
data_dir <- normalizePath(file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data"), mustWork = FALSE)

# Charger les LAZ NORMALISÉS pré-extraits (exercice 6.5)
plots_extracted_norm <- file.path(data_dir, "plots_extracted_norm")
laz_norm_files <- list.files(plots_extracted_norm, pattern = "\\.laz$", full.names = TRUE)
llas_height <- purrr::map(laz_norm_files, lidR::readLAS)
names(llas_height) <- gsub("\\.laz$", "", basename(laz_norm_files))

# Répertoire des données terrain (arbres et piquets)
field_dir <- system.file("extdata/aba.model/field", package = "nemeton")

# Fonction pour charger les arbres d'une placette avec coordonnées X,Y
load_trees_xy <- function(plot_id, field_dir) {
  # Extraire cluster_id (ex: "Verc-02" depuis "Verc-02-1")
  cluster_id <- sub("-[0-9]+$", "", plot_id)

  # Charger les piquets
  piquets_file <- file.path(field_dir, paste0(cluster_id, "_PiquetsTerrain.csv"))
  if (!file.exists(piquets_file)) return(NULL)
  piquets <- read.csv2(piquets_file)
  piquets$X <- as.numeric(piquets$X)
  piquets$Y <- as.numeric(piquets$Y)
  piquets <- piquets[!is.na(piquets$X), c("Id", "X", "Y")]

  # Charger les arbres
  arbres_file <- file.path(field_dir, paste0(plot_id, "_ArbresTerrain.csv"))
  if (!file.exists(arbres_file)) return(NULL)
  arbres <- read.csv2(arbres_file)

  # Convertir coordonnées polaires en X,Y
  arbres$X <- NA_real_
  arbres$Y <- NA_real_
  for (i in seq_len(nrow(arbres))) {
    pi_ref <- arbres$Pi[i]
    piquet <- piquets[piquets$Id == pi_ref, ]
    if (nrow(piquet) == 1) {
      azim_rad <- as.numeric(arbres$Azim_gr[i]) * pi / 200  # grades -> radians
      dist_m <- as.numeric(arbres$DistS_m[i])
      arbres$X[i] <- piquet$X + dist_m * sin(azim_rad)
      arbres$Y[i] <- piquet$Y + dist_m * cos(azim_rad)
    }
  }
  arbres <- arbres[!is.na(arbres$X), ]
  arbres$Dia_cm <- as.numeric(arbres$Dia_cm)
  arbres$Haut_m <- as.numeric(arbres$Haut_m)
  return(arbres)
}

# Placette test
plot_test <- names(llas_height)[1]

# Charger les arbres terrain de la placette test
arbres_terrain <- load_trees_xy(plot_test, field_dir)

# Créer l'objet sf du centre de placette
plot_coords <- plots[plots$plot_id == plot_test, c("X", "Y")]
plots_sf.t <- sf::st_as_sf(plot_coords, coords = c("X", "Y"), crs = 2154)

# Créer l'emprise circulaire de la placette (buffer de 15m)
plots_extent_t <- sf::st_buffer(plots_sf.t, p_radius)

# Préparer trees_t avec les noms de colonnes attendus par plot_tree_inventory
if (!is.null(arbres_terrain) && nrow(arbres_terrain) > 0) {
  trees_t <- arbres_terrain
  trees_t$height_m <- trees_t$Haut_m
  trees_t$species <- trees_t$Es
  trees_t$tree_id <- trees_t$Num
}
```

```{r ex-6-9, exercise=TRUE, exercise.timelimit=120, exercise.setup="ex-6-9-setup"}
# === 6.3.6 : Superposition CHM et positions arbres terrain ===
cat("=== Visualisation CHM placette", plot_test, "===\n\n")

# Calculer le CHM (Canopy Height Model)
chm <- lidR::rasterize_canopy(llas_height[[plot_test]],
                               res = 0.5,
                               algorithm = lidR::p2r(),
                               pkg = "terra")

# Afficher le CHM
terra::plot(chm,
            col = gray(seq(0, 1, 1/255)),
            main = paste("CHM + arbres terrain -", plot_test))

# Ajouter le cercle de la placette
plot_coords <- plots[plots$plot_id == plot_test, c("X", "Y")]
theta <- seq(0, 2*pi, length.out = 100)
circle_x <- plot_coords$X + p_radius * cos(theta)
circle_y <- plot_coords$Y + p_radius * sin(theta)
lines(circle_x, circle_y, col = "red", lwd = 2)

# Ajouter les arbres terrain avec leurs diamètres (DBH)
if (!is.null(arbres_terrain) && nrow(arbres_terrain) > 0) {
  # Dessiner un cercle pour chaque arbre (rayon = DBH/2 en mètres)
  for (i in seq_len(nrow(arbres_terrain))) {
    arbre <- arbres_terrain[i, ]
    rayon_m <- arbre$Dia_cm / 200  # diamètre cm -> rayon m
    # Cercle proportionnel au DBH (amplifié x5 pour visibilité)
    circle_arbre_x <- arbre$X + rayon_m * 5 * cos(theta)
    circle_arbre_y <- arbre$Y + rayon_m * 5 * sin(theta)
    lines(circle_arbre_x, circle_arbre_y, col = "cyan", lwd = 1.5)
  }
  # Ajouter les centres des arbres
  points(arbres_terrain$X, arbres_terrain$Y, pch = 16, col = "blue", cex = 0.4)

  cat("Arbres terrain:", nrow(arbres_terrain), "\n")
  cat("DBH moyen:", round(mean(arbres_terrain$Dia_cm, na.rm = TRUE), 1), "cm\n")
  cat("Hauteur moyenne:", round(mean(arbres_terrain$Haut_m, na.rm = TRUE), 1), "m\n")
}

# Ajouter le centre de placette
points(plot_coords$X, plot_coords$Y, pch = 3, col = "red", cex = 2)

# Légende
legend("topright", legend = c("Placette 15m", "Arbres terrain (DBH x5)"),
       col = c("red", "cyan"), lwd = c(2, 1.5), bg = "white", cex = 0.8)

cat("\nCHM résolution:", terra::res(chm)[1], "m\n")
cat("Hauteur max CHM:", round(terra::global(chm, "max", na.rm = TRUE)$max, 1), "m\n")

# === Visualisation avec plot_tree_inventory ===
cat("\n=== Inventaire des arbres avec plot_tree_inventory ===\n")

# Afficher l'emprise de la placette
plot(sf::st_geometry(plots_extent_t), border = "red", axes = TRUE,
     main = paste("Inventaire arbres -", plot_test))

# Afficher le centre de la placette
plot(sf::st_geometry(plots_sf.t), col = "red", pch = 3, cex = 2, add = TRUE)

# Ajouter les arbres inventoriés avec leurs hauteurs et essences
lidaRtRee::plot_tree_inventory(
  trees_t[, c("X", "Y")],
  trees_t$height_m,
  species = as.character(trees_t$species),
  add = TRUE
)

# Tracer les lignes entre arbres (ordre d'inventaire)
trees_ordered <- trees_t[order(trees_t$tree_id), ]
lines(trees_ordered[, c("X", "Y")], col = "gray", lty = 2)

# Marquer le premier arbre (triangle vide)
first_tree <- trees_ordered[1, ]
points(first_tree$X, first_tree$Y, pch = 2, col = "darkred", cex = 2, lwd = 2)

# Marquer le dernier arbre (double cercle concentrique)
last_tree <- trees_ordered[nrow(trees_ordered), ]
points(last_tree$X, last_tree$Y, pch = 1, col = "darkred", cex = 2.5, lwd = 2)
points(last_tree$X, last_tree$Y, pch = 1, col = "darkred", cex = 1.5, lwd = 2)

# Légende
legend("bottomleft",
       legend = c("Centre placette", "Arbre départ", "Arbre arrivée", "Parcours inventaire"),
       pch = c(3, 2, 1, NA),
       lty = c(NA, NA, NA, 2),
       col = c("red", "darkred", "darkred", "gray"),
       pt.cex = c(1.5, 1.5, 1.5, NA),
       lwd = 2, bg = "white", cex = 0.8)

cat("Arbres visualisés:", nrow(trees_t), "\n")
cat("Essences:", paste(unique(trees_t$species), collapse = ", "), "\n")
```

### Exercice 6.10 : Paramètres de peuplement

Trois paramètres de peuplement sont calculés en agrégeant les informations au niveau de l'arbre : surface terrière, diamètre moyen, densité de tiges.

```{r ex-6-10-setup}
library(lidaRtRee)
pattern_zone <- "Verc-(02|05|06|C1|C2|S4|S7)"

data("quatre_montagnes", package = "lidaRtRee", envir = environment())
plots <- quatre_montagnes[grepl(paste0("^", pattern_zone, "-"), quatre_montagnes$plot_id), ]
```

```{r ex-6-10, exercise=TRUE, exercise.timelimit=60, exercise.setup="ex-6-10-setup"}
# === 6.4.1 : Paramètres de peuplement ===
cat("=== Statistiques de peuplement (28 placettes) ===\n\n")

# Le jeu quatre_montagnes contient déjà G, N, D calculés
# Afficher les statistiques
cat("Surface terrière (G_m2_ha):\n")
summary(plots$G_m2_ha)

cat("\nDensité de tiges (N_ha):\n")
summary(plots$N_ha)

cat("\nDiamètre moyen (D_mean_cm):\n")
summary(plots$D_mean_cm)

# Histogrammes
par(mfrow = c(1, 3))
hist(plots$G_m2_ha, main = "Surface terrière",
     xlab = "(m²/ha)", ylab = "Nombre de placettes", col = "lightgreen")
hist(plots$N_ha, main = "Densité de tiges",
     xlab = "(N/ha)", ylab = "Nombre de placettes", col = "lightblue")
hist(plots$D_mean_cm, main = "Diamètre moyen",
     xlab = "(cm)", ylab = "Nombre de placettes", col = "lightyellow")
```

### Exercice 6.11 : Bilan des données

On fait le bilan des données préparées dans cette section : placettes avec leurs paramètres forestiers, nuages de points normalisés, et métriques de terrain. Ces données sont prêtes pour la calibration des modèles ABA (Section 7).

```{r ex-6-11-setup}
library(lidaRtRee)
library(lidR)

p_radius <- 15
pattern_zone <- "Verc-(02|05|06|C1|C2|S4|S7)"

data("quatre_montagnes", package = "lidaRtRee", envir = environment())
plots <- quatre_montagnes[grepl(paste0("^", pattern_zone, "-"), quatre_montagnes$plot_id), ]

# Répertoire des données
data_dir <- normalizePath(file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data"), mustWork = FALSE)

# Charger LAZ NORMALISÉS pré-extraits (exercice 6.5)
plots_extracted_norm <- file.path(data_dir, "plots_extracted_norm")
laz_norm_files <- list.files(plots_extracted_norm, pattern = "\\.laz$", full.names = TRUE)
llas_height <- purrr::map(laz_norm_files, lidR::readLAS)
names(llas_height) <- gsub("\\.laz$", "", basename(laz_norm_files))

# Répertoire des données
data_dir <- normalizePath(file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data"), mustWork = FALSE)

# Charger LAZ ORIGINAUX pré-extraits (exercice 6.5)
plots_extracted_orig <- file.path(data_dir, "plots_extracted_orig")
laz_orig_files <- list.files(plots_extracted_orig, pattern = "\\.laz$", full.names = TRUE)
llas_original <- purrr::map(laz_orig_files, lidR::readLAS)
names(llas_original) <- gsub("\\.laz$", "", basename(laz_orig_files))

# Synchroniser
common_ids <- intersect(plots$plot_id, names(llas_height))
plots <- plots[plots$plot_id %in% common_ids, ]
llas_height <- llas_height[plots$plot_id]

# Calculer métriques terrain depuis LAZ originaux pré-extraits
metrics_terrain <- list()
for (i in seq_along(llas_original)) {
  plot_name <- names(llas_original)[i]
  plot_row <- which(plots$plot_id == plot_name)
  if (length(plot_row) > 0) {
    tryCatch({
      center_xy <- as.numeric(plots[plot_row, c("X", "Y")])
      metrics_terrain[[plot_name]] <- lidaRtRee::terrain_points_metrics(llas_original[[i]], center_xy, p_radius)
    }, error = function(e) NULL)
  }
}
metrics_terrain <- as.data.frame(do.call(rbind, metrics_terrain))
```

```{r ex-6-11, exercise=TRUE, exercise.timelimit=60, exercise.setup="ex-6-11-setup"}
# === 6.5 : Résumé des données préparées ===
cat("=== RÉSUMÉ - Données prêtes pour la calibration ABA ===\n\n")

cat("DONNÉES TERRAIN (plots):\n")
cat("  - Nombre de placettes:", nrow(plots), "\n")
cat("  - Variables forestières: G_m2_ha, N_ha, D_mean_cm\n")
cat("  - Coordonnées: X, Y (Lambert-93)\n\n")

cat("NUAGES DE POINTS (llas_height):\n")
cat("  - Nombre de nuages:", length(llas_height), "\n")
cat("  - Type: LAS normalisés (Z = hauteur au-dessus du sol)\n")
total_points <- sum(sapply(llas_height, function(x) nrow(x@data)))
cat("  - Total points:", format(total_points, big.mark = " "), "\n\n")

cat("MÉTRIQUES TERRAIN (metrics_terrain):\n")
cat("  - Dimensions:", nrow(metrics_terrain), "x", ncol(metrics_terrain), "\n")
cat("  - Variables:", paste(names(metrics_terrain), collapse = ", "), "\n\n")

cat(">>> Ces données sont prêtes pour l'étape suivante:\n")
cat("    Section 7 - Calibration des modèles ABA\n")
```

### Quiz Section 6

```{r quiz-section6, echo=FALSE}
quiz(
 question("Quel est le rayon standard des placettes d'inventaire dans le tutoriel lidaRtRee ?",
    answer("10 m"),
    answer("15 m", correct = TRUE),
    answer("20 m"),
    answer("25 m"),
    allow_retry = TRUE
  ),
  question("Que calcule la fonction polar2Projected() ?",
    answer("Les coordonnées polaires depuis des coordonnées cartésiennes"),
    answer("Les coordonnées cartésiennes des arbres depuis azimut, pente et distance", correct = TRUE),
    answer("La projection du nuage de points"),
    answer("Les métriques de terrain"),
    allow_retry = TRUE
  ),
  question("Que contient l'attribut Z dans les fichiers LAZ normalisés ?",
    answer("L'altitude absolue"),
    answer("La hauteur au-dessus du sol", correct = TRUE),
    answer("La coordonnée Z brute"),
    answer("L'intensité du retour"),
    allow_retry = TRUE
  ),
  question("Quels sont les trois paramètres de peuplement calculés ?",
    answer("Hauteur, volume, biomasse"),
    answer("Surface terrière (G), densité (N), diamètre moyen (D)", correct = TRUE),
    answer("Couvert, LAI, hauteur dominante"),
    answer("Age, fertilité, production"),
    allow_retry = TRUE
  ),
  question("À quoi sert la fonction terrain_points_metrics() ?",
    answer("À calculer les métriques LiDAR de hauteur"),
    answer("À calculer altitude, pente et aspect depuis les points sol", correct = TRUE),
    answer("À filtrer les points de terrain"),
    answer("À normaliser les hauteurs"),
    allow_retry = TRUE
  )
)
```


## Section 7 : Approche ABA - Calibration des Modèles de Prédiction

*Approche surfacique (ABA) - Calibration de modèles de régression pour l'estimation des paramètres forestiers*

Ce code présente un workflow pour calibrer des modèles de prédiction pour l'estimation des paramètres forestiers à partir de métriques dérivées de l'ALS, en utilisant l'approche surfacique (ABA). Le workflow est basé sur les fonctions des packages R `lidaRtRee` (testé avec la version 4.0.9) et `lidR` (testé avec la version 4.1.2).

### 7.1 Chargement des données préparées

Les données préparées dans la section précédente sont chargées : le data.frame `plots` contenant les paramètres de peuplement mesurés sur le terrain, la liste `llas_height` contenant les nuages de points normalisés extraits aux emplacements des placettes, et le data.frame `metrics_terrain` contenant les statistiques de terrain.

```{r ex-7-1-setup, message=FALSE, warning=FALSE}
# Paramètres
pattern_zone <- "Verc-(02|05|06|C1|C2|S4|S7)"
p_radius <- 15

# Chargement des données quatre_montagnes
data("quatre_montagnes", package = "lidaRtRee", envir = environment())

# Filtrage sur les 28 placettes de la zone d'étude
plots <- quatre_montagnes[grepl(paste0("^", pattern_zone, "-"), quatre_montagnes$plot_id), ]

# Répertoire des données
data_dir <- normalizePath(file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data"), mustWork = FALSE)

# Charger LAZ NORMALISÉS pré-extraits (exercice 6.5)
plots_extracted_norm <- file.path(data_dir, "plots_extracted_norm")
laz_norm_files <- list.files(plots_extracted_norm, pattern = "\\.laz$", full.names = TRUE)
llas_height <- purrr::map(laz_norm_files, lidR::readLAS)
names(llas_height) <- gsub("\\.laz$", "", basename(laz_norm_files))

# Synchronisation plots / nuages
common_ids <- intersect(plots$plot_id, names(llas_height))
plots <- plots[plots$plot_id %in% common_ids, ]
llas_height <- llas_height[plots$plot_id]

# Répertoire des données
data_dir <- normalizePath(file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data"), mustWork = FALSE)

# Charger LAZ ORIGINAUX pré-extraits et calculer métriques terrain
plots_extracted_orig <- file.path(data_dir, "plots_extracted_orig")
laz_orig_files <- list.files(plots_extracted_orig, pattern = "\\.laz$", full.names = TRUE)
llas_original <- purrr::map(laz_orig_files, lidR::readLAS)
names(llas_original) <- gsub("\\.laz$", "", basename(laz_orig_files))

metrics_terrain <- list()
for (i in seq_along(llas_original)) {
  plot_name <- names(llas_original)[i]
  plot_row <- which(plots$plot_id == plot_name)
  if (length(plot_row) > 0) {
    tryCatch({
      center_xy <- as.numeric(plots[plot_row, c("X", "Y")])
      metrics_terrain[[plot_name]] <- lidaRtRee::terrain_points_metrics(llas_original[[i]], center_xy, p_radius)
    }, error = function(e) NULL)
  }
}
metrics_terrain <- as.data.frame(do.call(rbind, metrics_terrain))
```

```{r ex-7-1, exercise=TRUE, exercise.timelimit=60, exercise.setup="ex-7-1-setup"}
# === 7.1 : Chargement et vérification des données ===
cat("=== Données préparées pour la calibration ABA ===\n\n")

# Résumé des données terrain
cat("DONNÉES TERRAIN (plots):\n")
print(summary(plots[, c("G_m2_ha", "N_ha", "D_mean_cm")]))

# Visualisation des relations entre variables
cat("\nVISUALISATION DES VARIABLES FORESTIÈRES:\n")
plot(plots[, c("G_m2_ha", "N_ha", "D_mean_cm")],
     col = "forestgreen", pch = 19,
     main = "Relations entre paramètres forestiers")

# Vérification des nuages de points
cat("\nNUAGES DE POINTS (llas_height):\n")
cat("  Nombre de nuages:", length(llas_height), "\n")
cat("  Premier nuage:\n")
print(llas_height[[1]])

# Synchronisation
llas_height <- llas_height[plots$plot_id]
metrics_terrain <- metrics_terrain[plots$plot_id, ]

cat("\nDonnées synchronisées:", nrow(plots), "placettes\n")
```

### 7.2 Filtrage des nuages de points

Avant le calcul des métriques, les points indésirables sont retirés. Les points avec un code de classification 7 (bruit) et les hauteurs au-dessus d'un seuil (points erronés) ou en dessous de 0 (erreurs de normalisation) sont exclus.

```{r ex-7-2-setup, message=FALSE, warning=FALSE}
# Paramètres
pattern_zone <- "Verc-(02|05|06|C1|C2|S4|S7)"
p_radius <- 15

data("quatre_montagnes", package = "lidaRtRee", envir = environment())
plots <- quatre_montagnes[grepl(paste0("^", pattern_zone, "-"), quatre_montagnes$plot_id), ]

# Répertoire des données
data_dir <- normalizePath(file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data"), mustWork = FALSE)

# Charger LAZ NORMALISÉS pré-extraits (exercice 6.5)
plots_extracted_norm <- file.path(data_dir, "plots_extracted_norm")
laz_norm_files <- list.files(plots_extracted_norm, pattern = "\\.laz$", full.names = TRUE)
llas_height <- purrr::map(laz_norm_files, lidR::readLAS)
names(llas_height) <- gsub("\\.laz$", "", basename(laz_norm_files))

common_ids <- intersect(plots$plot_id, names(llas_height))
plots <- plots[plots$plot_id %in% common_ids, ]
llas_height <- llas_height[plots$plot_id]
```

```{r ex-7-2, exercise=TRUE, exercise.timelimit=60, exercise.setup="ex-7-2-setup"}
# === 7.2 : Filtrage des points ===

# Définition des paramètres de filtrage
class_points <- c(0, 1, 2, 3, 4, 5, 12)  # Classes à conserver
h_points <- 60  # Hauteur maximale (m)

cat("=== Filtrage des nuages de points ===\n\n")
cat("Classes conservées:", paste(class_points, collapse = ", "), "\n")
cat("Hauteur maximale:", h_points, "m\n\n")

# Filtrage par classification et hauteur
llas_height <- lapply(llas_height,
                      function(x)
                        lidR::filter_poi(x,
                                         is.element(Classification,
                                                    class_points) &
                                           Z <= h_points))

# Correction des hauteurs négatives
llas_height <- lapply(llas_height, function(x) {
  x$Z[x$Z < 0] <- 0
  x
})

# Vérification
cat("Après filtrage:\n")
for (i in 1:min(3, length(llas_height))) {
  cat("  ", names(llas_height)[i], ":",
      nrow(llas_height[[i]]@data), "points,",
      "Zmax =", round(max(llas_height[[i]]$Z), 1), "m\n")
}
```

### 7.3 Calcul des métriques du nuage de points

La fonction `clouds_metrics()` est utilisée pour calculer des métriques sur les nuages de points à l'aide de la fonction `aba_metrics()`.

```{r ex-7-3-setup, message=FALSE, warning=FALSE}
pattern_zone <- "Verc-(02|05|06|C1|C2|S4|S7)"
p_radius <- 15

data("quatre_montagnes", package = "lidaRtRee", envir = environment())
plots <- quatre_montagnes[grepl(paste0("^", pattern_zone, "-"), quatre_montagnes$plot_id), ]

# Répertoire des données
data_dir <- normalizePath(file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data"), mustWork = FALSE)

# Charger LAZ NORMALISÉS pré-extraits (exercice 6.5)
plots_extracted_norm <- file.path(data_dir, "plots_extracted_norm")
laz_norm_files <- list.files(plots_extracted_norm, pattern = "\\.laz$", full.names = TRUE)
llas_height <- purrr::map(laz_norm_files, lidR::readLAS)
names(llas_height) <- gsub("\\.laz$", "", basename(laz_norm_files))

common_ids <- intersect(plots$plot_id, names(llas_height))
plots <- plots[plots$plot_id %in% common_ids, ]
llas_height <- llas_height[plots$plot_id]

class_points <- c(0, 1, 2, 3, 4, 5, 12)
h_points <- 60

llas_height <- lapply(llas_height,
                      function(x)
                        lidR::filter_poi(x,
                                         is.element(Classification, class_points) &
                                           Z <= h_points))
llas_height <- lapply(llas_height, function(x) {
  x$Z[x$Z < 0] <- 0
  x
})
```

```{r ex-7-3, exercise=TRUE, exercise.timelimit=120, exercise.setup="ex-7-3-setup"}
# === 7.3 : Métriques du nuage de points ===

# Définition de la fonction de calcul des métriques
aba_point_metrics_fun <- ~ lidaRtRee::aba_metrics(Z, Intensity, ReturnNumber,
                                                  Classification, 2)

# Extraction des points dans l'emprise de la placette (sans buffer)
llas_height_plot_extent <- lapply(llas_height, function(x) {
  # Si attribut buffer existe, filtrer
  if ("buffer" %in% names(x@data)) {
    lidR::filter_poi(x, buffer == FALSE)
  } else {
    x
  }
})

# Calcul des métriques
cat("=== Calcul des métriques du nuage de points ===\n\n")
metrics_points <- lidaRtRee::clouds_metrics(llas_height_plot_extent,
                                            aba_point_metrics_fun)

cat("Dimensions:", nrow(metrics_points), "placettes x",
    ncol(metrics_points), "métriques\n\n")

cat("Premières métriques (8 premières colonnes):\n")
print(round(head(metrics_points[, 1:8], n = 5), 2))

cat("\nMétriques disponibles:\n")
cat(paste(names(metrics_points), collapse = ", "))

# Sauvegarder pour réutilisation dans les exercices suivants
cache_dir <- file.path(data_dir, "metrics_cache")
dir.create(cache_dir, recursive = TRUE, showWarnings = FALSE)
saveRDS(metrics_points, file.path(cache_dir, "metrics_points.rds"))
cat("\n\n>>> Métriques points sauvegardées pour réutilisation.\n")
```

### 7.4 Calcul des métriques basées sur les arbres

La détection des arbres individuels est effectuée sur les nuages de points. Un modèle numérique de canopée (MNC) avec une résolution de 0.5 m est d'abord calculé. Les arbres sont détectés en utilisant la fonction `tree_segmentation()`, leurs caractéristiques sont extraites et agrégées à l'échelle de la placette avec `std_tree_metrics()`.

```{r ex-7-4-setup, message=FALSE, warning=FALSE}
pattern_zone <- "Verc-(02|05|06|C1|C2|S4|S7)"
p_radius <- 15

data("quatre_montagnes", package = "lidaRtRee", envir = environment())
plots <- quatre_montagnes[grepl(paste0("^", pattern_zone, "-"), quatre_montagnes$plot_id), ]

# Répertoire des données
data_dir <- normalizePath(file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data"), mustWork = FALSE)

# Charger LAZ NORMALISÉS pré-extraits (exercice 6.5)
plots_extracted_norm <- file.path(data_dir, "plots_extracted_norm")
laz_norm_files <- list.files(plots_extracted_norm, pattern = "\\.laz$", full.names = TRUE)
llas_height <- purrr::map(laz_norm_files, lidR::readLAS)
names(llas_height) <- gsub("\\.laz$", "", basename(laz_norm_files))

common_ids <- intersect(plots$plot_id, names(llas_height))
plots <- plots[plots$plot_id %in% common_ids, ]
llas_height <- llas_height[plots$plot_id]

class_points <- c(0, 1, 2, 3, 4, 5, 12)
h_points <- 60

llas_height <- lapply(llas_height,
                      function(x)
                        lidR::filter_poi(x,
                                         is.element(Classification, class_points) &
                                           Z <= h_points))
llas_height <- lapply(llas_height, function(x) {
  x$Z[x$Z < 0] <- 0
  x
})
```

```{r ex-7-4, exercise=TRUE, exercise.timelimit=180, exercise.setup="ex-7-4-setup"}
# === 7.4 : Métriques basées sur les arbres ===

# Paramètres
aba_res_chm <- 0.5  # Résolution du MNC
plot_radius <- 15   # Rayon de la placette

cat("=== Calcul des métriques arbres ===\n\n")
cat("Résolution MNC:", aba_res_chm, "m\n")
cat("Rayon placette:", plot_radius, "m\n")
cat("Surface placette:", round(pi * plot_radius^2, 1), "m² =",
    round(pi * plot_radius^2 / 10000, 4), "ha\n\n")

# Calcul des métriques arbres avec clouds_tree_metrics
metrics_trees <- lidaRtRee::clouds_tree_metrics(
  llas_height,
  plots[, c("X", "Y")],
  plot_radius,
  res = aba_res_chm,
  func = function(x) {
    lidaRtRee::std_tree_metrics(x, area_ha = pi * plot_radius^2 / 10000)
  }
)

cat("Dimensions:", nrow(metrics_trees), "placettes x",
    ncol(metrics_trees), "métriques\n\n")

cat("Premières métriques arbres:\n")
print(round(head(metrics_trees[, 1:5], n = 5), 2))

cat("\nMétriques arbres disponibles:\n")
print(names(metrics_trees))

# Sauvegarder pour réutilisation dans les exercices suivants
cache_dir <- file.path(data_dir, "metrics_cache")
dir.create(cache_dir, recursive = TRUE, showWarnings = FALSE)
saveRDS(metrics_trees, file.path(cache_dir, "metrics_trees.rds"))
cat("\n>>> Métriques arbres sauvegardées pour réutilisation.\n")
```

### 7.5 Combinaison des métriques

Les métriques de points, d'arbres et de terrain sont combinées dans un seul data.frame.

```{r ex-7-5-setup, message=FALSE, warning=FALSE}
pattern_zone <- "Verc-(02|05|06|C1|C2|S4|S7)"
p_radius <- 15

data("quatre_montagnes", package = "lidaRtRee", envir = environment())
plots <- quatre_montagnes[grepl(paste0("^", pattern_zone, "-"), quatre_montagnes$plot_id), ]

# Répertoire des données et cache
data_dir <- normalizePath(file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data"), mustWork = FALSE)
cache_dir <- file.path(data_dir, "metrics_cache")

# Charger les métriques pré-calculées (exercices 6.6, 7.3, 7.4)
metrics_terrain <- readRDS(file.path(cache_dir, "metrics_terrain.rds"))
metrics_points <- readRDS(file.path(cache_dir, "metrics_points.rds"))
metrics_trees <- readRDS(file.path(cache_dir, "metrics_trees.rds"))

# Synchroniser plots avec les métriques disponibles
common_ids <- intersect(plots$plot_id, rownames(metrics_points))
common_ids <- intersect(common_ids, rownames(metrics_trees))
common_ids <- intersect(common_ids, rownames(metrics_terrain))
plots <- plots[plots$plot_id %in% common_ids, ]
rownames(plots) <- plots$plot_id
```

```{r ex-7-5, exercise=TRUE, exercise.timelimit=60, exercise.setup="ex-7-5-setup"}
# === 7.5 : Combinaison des métriques ===

cat("=== Fusion des métriques ===\n\n")

# Combinaison des trois types de métriques avec indexation explicite
idx <- plots$plot_id
metrics <- cbind(
  metrics_points[idx, , drop = FALSE],
  metrics_trees[idx, , drop = FALSE],
  metrics_terrain[idx, 1:3, drop = FALSE]
)
metrics <- as.data.frame(metrics)

# Supprimer colonnes dupliquées
metrics <- metrics[, !duplicated(colnames(metrics))]

cat("MÉTRIQUES COMBINÉES:\n")
cat("  Dimensions:", nrow(metrics), "placettes x", ncol(metrics), "prédicteurs\n\n")

cat("Types de métriques:\n")
cat("  - Points (aba_metrics):", ncol(metrics_points), "variables\n")
cat("  - Arbres (std_tree_metrics):", ncol(metrics_trees), "variables\n")
cat("  - Terrain:", 3, "variables (altitude, pente, aspect)\n\n")

cat("Aperçu des données combinées (9 colonnes aléatoires):\n")
metrics |>
  head(5) |>
  dplyr::select(all_of(sample(names(metrics), 9))) |>
  round(2) |>
  print()
```

### 7.6 Calibration d'un modèle mono-variable

La fonction `aba_build_model()` sélectionne le modèle de régression linéaire optimal maximisant le R² ajusté (maximum 4 prédicteurs). Une transformation Box-Cox ou log peut être appliquée pour normaliser la variable cible. Une validation croisée leave-one-out est réalisée.

```{r ex-7-6-setup, message=FALSE, warning=FALSE}
pattern_zone <- "Verc-(02|05|06|C1|C2|S4|S7)"
p_radius <- 15
data("quatre_montagnes", package = "lidaRtRee", envir = environment())
plots <- quatre_montagnes[grepl(paste0("^", pattern_zone, "-"), quatre_montagnes$plot_id), ]

# Répertoire des données et cache
data_dir <- normalizePath(file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data"), mustWork = FALSE)
cache_dir <- file.path(data_dir, "metrics_cache")

# Charger les métriques pré-calculées (exercices 6.6, 7.3, 7.4)
metrics_terrain <- readRDS(file.path(cache_dir, "metrics_terrain.rds"))
metrics_points <- readRDS(file.path(cache_dir, "metrics_points.rds"))
metrics_trees <- readRDS(file.path(cache_dir, "metrics_trees.rds"))

# Synchroniser plots avec les métriques disponibles
common_ids <- intersect(plots$plot_id, rownames(metrics_points))
common_ids <- intersect(common_ids, rownames(metrics_trees))
common_ids <- intersect(common_ids, rownames(metrics_terrain))
plots <- plots[plots$plot_id %in% common_ids, ]
rownames(plots) <- plots$plot_id

# Combiner les métriques avec indexation explicite
idx <- plots$plot_id
metrics <- cbind(
  metrics_points[idx, , drop = FALSE],
  metrics_trees[idx, , drop = FALSE],
  metrics_terrain[idx, 1:3, drop = FALSE]
)
metrics <- as.data.frame(metrics)

# Supprimer colonnes dupliquées
metrics <- metrics[, !duplicated(colnames(metrics))]

# Nettoyer les données : supprimer colonnes avec NA ou variance nulle
metrics <- metrics[, colSums(is.na(metrics)) == 0, drop = FALSE]
var_cols <- sapply(metrics, function(x) var(x, na.rm = TRUE) > 0)
metrics <- metrics[, var_cols, drop = FALSE]

# Garder uniquement les variables positives (pour boxcox/log)
pos_cols <- sapply(metrics, function(x) min(x, na.rm = TRUE) > 0)
metrics <- metrics[, pos_cols, drop = FALSE]

# Sélection des variables par Random Forest
library(randomForest)
set.seed(42)
rf_model <- randomForest(
  x = metrics,
  y = plots$G_m2_ha,
  ntree = 500,
  importance = TRUE
)

# Importance des variables (%IncMSE)
importance_df <- data.frame(
  variable = rownames(rf_model$importance),
  importance = rf_model$importance[, "%IncMSE"]
)
importance_df <- importance_df[order(-importance_df$importance), ]

# Sélectionner les 10 variables les plus importantes
top_vars <- head(importance_df$variable, 10)
metrics_rf <- metrics[, top_vars]
```

```{r ex-7-6, exercise=TRUE, exercise.timelimit=120, exercise.setup="ex-7-6-setup"}
# === 7.6 : Calibration modèle surface terrière (G) ===

variable <- "G_m2_ha"
subsample <- 1:nrow(plots)

cat("=== Sélection Random Forest ===\n")
cat("Variables originales:", ncol(metrics), "\n")
cat("Variables sélectionnées:", ncol(metrics_rf), "\n\n")

cat("Top 10 variables par importance (%IncMSE):\n")
print(head(importance_df, 10))

cat("\n=== Calibration du modèle pour", variable, "===\n\n")

# Construction du modèle avec les variables sélectionnées par RF
model_aba <- lidaRtRee::aba_build_model(
  plots[subsample, variable],
  metrics_rf[subsample, ],
  transform = "boxcox",
  nmax = 4,
  xy = plots[subsample, c("X", "Y")]
)

# Résultats
row.names(model_aba$stats) <- variable

cat("MODÈLE SÉLECTIONNÉ:\n")
print(model_aba$model)

cat("\nSTATISTIQUES:\n")
print(model_aba$stats)

# Analyse des résidus
cat("\nCORRÉLATION DES RÉSIDUS avec les variables:\n")
idx_sub <- plots$plot_id[subsample]
cor_residuals <- round(cor(cbind(
  model_aba$values$residual,
  plots[subsample, c("G_m2_ha", "N_ha", "D_mean_cm")],
  metrics_terrain[idx_sub, 1:3]
)), 2)[1, ]
print(cor_residuals)

# Test de corrélation résidus vs variable observée
cat("\nTest corrélation résidus ~", variable, ":\n")
cor_test <- cor.test(model_aba$values$residual, plots[subsample, variable])
print(cor_test)

# === Interprétation des résultats ===
cat("\n")
cat("═══════════════════════════════════════════════════════════════════\n")
cat("                    INTERPRÉTATION DES RÉSULTATS\n")
cat("═══════════════════════════════════════════════════════════════════\n\n")

cat("1. SÉLECTION DES VARIABLES (Random Forest)\n")
cat("   - L'importance %IncMSE mesure l'augmentation de l'erreur quand\n")
cat("     une variable est permutée aléatoirement.\n")
cat("   - Plus la valeur est élevée, plus la variable est prédictive.\n\n")

cat("2. STATISTIQUES DU MODÈLE\n")
cat("   - R² ajusté : proportion de variance expliquée (0-1).\n")
cat("     Valeur > 0.7 = bon modèle, > 0.8 = très bon modèle.\n")
cat("   - RMSE : erreur quadratique moyenne (même unité que G).\n")
cat("   - rRMSE : RMSE relatif (%). < 20% = acceptable, < 15% = bon.\n\n")

cat("3. CORRÉLATION DES RÉSIDUS\n")
cat("   - Résidus = écart entre valeurs observées et prédites.\n")
cat("   - Corrélation résidus ~ variable observée :\n")
if (abs(cor_test$estimate) < 0.3) {
  cat("     → Faible (< 0.3) : pas de biais systématique. ✓\n")
} else if (abs(cor_test$estimate) < 0.5) {
  cat("     → Modérée (0.3-0.5) : léger biais possible.\n")
} else {
  cat("     → Forte (> 0.5) : biais systématique à corriger.\n")
}
cat("   - p-value du test de Pearson :\n")
if (cor_test$p.value > 0.05) {
  cat("     → Non significatif (p > 0.05) : corrélation due au hasard. ✓\n")
} else {
  cat("     → Significatif (p < 0.05) : corrélation réelle, biais à investiguer.\n")
}

# Pistes d'amélioration si problèmes détectés
if (abs(cor_test$estimate) >= 0.3 || cor_test$p.value <= 0.05) {
  cat("\n")
  cat("4. PISTES D'AMÉLIORATION\n")
  cat("   Le modèle présente un biais. Voici des pistes à explorer :\n\n")
  cat("   a) DONNÉES D'ENTRÉE\n")
  cat("      - Vérifier la qualité des données terrain (erreurs de mesure)\n")
  cat("      - Contrôler le géoréférencement placettes/LiDAR\n")
  cat("      - Augmenter le nombre de placettes d'entraînement\n\n")
  cat("   b) SÉLECTION DE VARIABLES\n")
  cat("      - Tester d'autres métriques LiDAR (percentiles, densité)\n")
  cat("      - Ajouter des variables environnementales (pente, exposition)\n")
  cat("      - Réduire/augmenter le nombre de variables sélectionnées\n\n")
  cat("   c) MODÉLISATION\n")
  cat("      - Essayer transform='log' au lieu de 'boxcox'\n")
  cat("      - Réduire nmax (moins de prédicteurs)\n")
  cat("      - Stratifier par type de peuplement ou classe d'âge\n")
  cat("      - Tester des modèles non-linéaires (GAM, Random Forest)\n\n")
  cat("   d) VALIDATION\n")
  cat("      - Identifier les placettes avec forts résidus (outliers)\n")
  cat("      - Analyser si le biais dépend d'une variable (ex: pente)\n")
  cat("      - Utiliser une validation croisée k-fold au lieu de LOO\n")
}
cat("\n")

# Sauvegarder le modèle pour réutilisation
saveRDS(model_aba, file.path(cache_dir, "model_aba_G.rds"))
cat(">>> Modèle sauvegardé pour réutilisation.\n")
```

### 7.7 Diagnostics du modèle

La fonction `aba_plot()` permet de visualiser les valeurs prédites vs observées.

```{r ex-7-7-setup, message=FALSE, warning=FALSE}
# Répertoire des données et cache
data_dir <- normalizePath(file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data"), mustWork = FALSE)
cache_dir <- file.path(data_dir, "metrics_cache")

# Charger le modèle sauvegardé (exercice 7.6)
model_aba <- readRDS(file.path(cache_dir, "model_aba_G.rds"))

variable <- "G_m2_ha"
```

```{r ex-7-7, exercise=TRUE, exercise.timelimit=60, exercise.setup="ex-7-7-setup"}
# === 7.7 : Diagnostics du modèle ===

variable <- "G_m2_ha"

cat("=== Diagnostics graphiques ===\n\n")

par(mfrow = c(1, 2))

# Graphique prédit vs observé
lidaRtRee::aba_plot(model_aba,
                    main = paste("Modèle", variable),
                    col = "forestgreen")

# Graphique résidus vs prédit
plot(model_aba$values$predicted,
     model_aba$values$residual,
     ylab = "Erreur de prédiction",
     xlab = "Valeur prédite (LOOCV)",
     main = paste("Résidus", variable),
     col = "forestgreen",
     pch = 19)
abline(h = 0, lty = 2, col = "red")

par(mfrow = c(1, 1))

cat("INTERPRÉTATION:\n")
cat("- Gauche: valeurs prédites vs observées (idéal = ligne 1:1)\n")
cat("- Droite: résidus vs prédictions (idéal = dispersion uniforme autour de 0)\n")
cat("- Une tendance dans les résidus indique un biais systématique\n")
```

### 7.8 Calibration de modèles multiples

Les modèles sont calibrés séquentiellement pour différents paramètres forestiers.

```{r ex-7-8-setup, message=FALSE, warning=FALSE}
pattern_zone <- "Verc-(02|05|06|C1|C2|S4|S7)"
p_radius <- 15
data("quatre_montagnes", package = "lidaRtRee", envir = environment())
plots <- quatre_montagnes[grepl(paste0("^", pattern_zone, "-"), quatre_montagnes$plot_id), ]

# Répertoire des données et cache
data_dir <- normalizePath(file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data"), mustWork = FALSE)
cache_dir <- file.path(data_dir, "metrics_cache")

# Charger les métriques pré-calculées
metrics_terrain <- readRDS(file.path(cache_dir, "metrics_terrain.rds"))
metrics_points <- readRDS(file.path(cache_dir, "metrics_points.rds"))
metrics_trees <- readRDS(file.path(cache_dir, "metrics_trees.rds"))

# Synchroniser plots avec les métriques disponibles
common_ids <- intersect(plots$plot_id, rownames(metrics_points))
common_ids <- intersect(common_ids, rownames(metrics_trees))
common_ids <- intersect(common_ids, rownames(metrics_terrain))
plots <- plots[plots$plot_id %in% common_ids, ]
rownames(plots) <- plots$plot_id

# Combiner les métriques avec indexation explicite
idx <- plots$plot_id
metrics <- cbind(
  metrics_points[idx, , drop = FALSE],
  metrics_trees[idx, , drop = FALSE],
  metrics_terrain[idx, 1:3, drop = FALSE]
)
metrics <- as.data.frame(metrics)

# Supprimer colonnes dupliquées
metrics <- metrics[, !duplicated(colnames(metrics))]

# Nettoyer les données : supprimer colonnes avec NA ou variance nulle
metrics <- metrics[, colSums(is.na(metrics)) == 0, drop = FALSE]
var_cols <- sapply(metrics, function(x) var(x, na.rm = TRUE) > 0)
metrics <- metrics[, var_cols, drop = FALSE]

# Garder uniquement les variables positives (pour boxcox/log)
pos_cols <- sapply(metrics, function(x) min(x, na.rm = TRUE) > 0)
metrics <- metrics[, pos_cols, drop = FALSE]

library(randomForest)
```

```{r ex-7-8, exercise=TRUE, exercise.timelimit=300, exercise.setup="ex-7-8-setup"}
# === 7.8 : Modèles multiples (G, D, N) avec sélection Random Forest ===

cat("=== Calibration de modèles pour G, D et N ===\n\n")

variables <- c("G_m2_ha", "D_mean_cm", "N_ha")
models_aba <- list()
importance_list <- list()

for (var in variables) {
  cat("━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n")
  cat("Variable:", var, "\n\n")

  # Sélection des variables par Random Forest
  set.seed(42)
  rf_model <- randomForest(
    x = metrics,
    y = plots[[var]],
    ntree = 500,
    importance = TRUE
  )

  # Top 10 variables par importance
  importance_df <- data.frame(
    variable = rownames(rf_model$importance),
    importance = rf_model$importance[, "%IncMSE"]
  )
  importance_df <- importance_df[order(-importance_df$importance), ]
  importance_list[[var]] <- head(importance_df, 10)

  cat("Top 5 variables (Random Forest):\n")
  print(head(importance_df, 5))

  # Sélectionner les variables et filtrer les corrélations
  top_vars <- head(importance_df$variable, 15)
  metrics_rf <- metrics[, top_vars, drop = FALSE]

  # Supprimer les variables trop corrélées (> 0.9)
  cor_mat <- cor(metrics_rf)
  to_remove <- c()
  for (i in 1:(ncol(cor_mat) - 1)) {
    for (j in (i + 1):ncol(cor_mat)) {
      if (abs(cor_mat[i, j]) > 0.9 && !(colnames(cor_mat)[j] %in% to_remove)) {
        to_remove <- c(to_remove, colnames(cor_mat)[j])
      }
    }
  }
  if (length(to_remove) > 0) {
    metrics_rf <- metrics_rf[, !(colnames(metrics_rf) %in% to_remove), drop = FALSE]
  }
  cat("Variables après filtrage corrélation:", ncol(metrics_rf), "\n")

  # Calibration du modèle avec gestion d'erreur
  cat("\nCalibration avec boxcox...\n")
  suppressWarnings({
    models_aba[[var]] <- tryCatch({
      lidaRtRee::aba_build_model(
        plots[[var]],
        metrics_rf,
        transform = "boxcox",
        nmax = 4,
        xy = plots[, c("X", "Y")]
      )
    }, error = function(e) {
      cat("  Erreur boxcox, tentative avec log...\n")
      lidaRtRee::aba_build_model(
        plots[[var]],
        metrics_rf,
        transform = "log",
        nmax = 3,
        xy = plots[, c("X", "Y")]
      )
    })
  })
  cat("\n")
}

# Tableau récapitulatif des statistiques
model_stats <- do.call(rbind, lapply(models_aba, function(x) x[["stats"]]))

cat("━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n")
cat("           RÉSUMÉ DES MODÈLES\n")
cat("━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\n")

# Arrondir uniquement les colonnes numériques
num_cols <- sapply(model_stats, is.numeric)
model_stats[, num_cols] <- round(model_stats[, num_cols], 3)

# Renommer pour clarté et convertir cvrmse en %
stats_display <- model_stats[, c("n", "adjR2", "looR2", "rmse", "cvrmse")]
stats_display$cvrmse <- stats_display$cvrmse * 100
colnames(stats_display) <- c("n", "adjR2", "looR2", "RMSE", "RMSE%")
print(stats_display)

cat("\nINTERPRÉTATION:\n")
cat("- adjR2 > 0.7 : bon modèle | > 0.8 : très bon\n")
cat("- looR2 : R² en validation croisée leave-one-out\n")
cat("- RMSE% < 20% : acceptable | < 15% : bon\n")

# Visualisation
par(mfrow = c(1, 3))
for (var in names(models_aba)) {
  lidaRtRee::aba_plot(models_aba[[var]], main = var, col = "forestgreen")
}
par(mfrow = c(1, 1))

# Sauvegarder les modèles
saveRDS(models_aba, file.path(cache_dir, "models_aba_all.rds"))
cat("\n>>> Modèles sauvegardés pour réutilisation.\n")
```

### 7.9 Modèles stratifiés

La calibration de modèles séparés par strate (type de propriété forestière dans cet exemple) permet de tenir compte des variations dans les conditions d'acquisition, la structure forestière et les conditions topographiques. Un minimum de 50 placettes par strate est recommandé ; 100 est préférable.

**Note:** Avec seulement 28 placettes dans notre zone d'étude, la stratification n'est pas recommandée statistiquement. Cet exercice est présenté à titre pédagogique.

```{r ex-7-9-setup, message=FALSE, warning=FALSE}
pattern_zone <- "Verc-(02|05|06|C1|C2|S4|S7)"
data("quatre_montagnes", package = "lidaRtRee", envir = environment())
plots <- quatre_montagnes[grepl(paste0("^", pattern_zone, "-"), quatre_montagnes$plot_id), ]

# Répertoire des données et cache
data_dir <- normalizePath(file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data"), mustWork = FALSE)
cache_dir <- file.path(data_dir, "metrics_cache")

# Charger les métriques pré-calculées
metrics_terrain <- readRDS(file.path(cache_dir, "metrics_terrain.rds"))
metrics_points <- readRDS(file.path(cache_dir, "metrics_points.rds"))
metrics_trees <- readRDS(file.path(cache_dir, "metrics_trees.rds"))

# Charger le modèle global (exercice 7.6)
model_aba <- readRDS(file.path(cache_dir, "model_aba_G.rds"))

# Synchroniser plots avec les métriques disponibles
common_ids <- intersect(plots$plot_id, rownames(metrics_points))
common_ids <- intersect(common_ids, rownames(metrics_trees))
common_ids <- intersect(common_ids, rownames(metrics_terrain))
plots <- plots[plots$plot_id %in% common_ids, ]
rownames(plots) <- plots$plot_id

# Combiner les métriques avec indexation explicite
idx <- plots$plot_id
metrics <- cbind(
  metrics_points[idx, , drop = FALSE],
  metrics_trees[idx, , drop = FALSE],
  metrics_terrain[idx, 1:3, drop = FALSE]
)
metrics <- as.data.frame(metrics)
metrics <- metrics[, !duplicated(colnames(metrics))]

# Nettoyer les données
metrics <- metrics[, colSums(is.na(metrics)) == 0, drop = FALSE]
var_cols <- sapply(metrics, function(x) var(x, na.rm = TRUE) > 0)
metrics <- metrics[, var_cols, drop = FALSE]
pos_cols <- sapply(metrics, function(x) min(x, na.rm = TRUE) > 0)
metrics <- metrics[, pos_cols, drop = FALSE]

library(randomForest)
```

```{r ex-7-9, exercise=TRUE, exercise.timelimit=180, exercise.setup="ex-7-9-setup"}
# === 7.9 : Modèles stratifiés (exemple pédagogique) ===

variable <- "G_m2_ha"
strat <- "stratum"

cat("=== Modèles stratifiés par type de propriété ===\n\n")

# Vérification de la variable de stratification
if (!strat %in% names(plots)) {
  cat("Variable 'stratum' non disponible, création basée sur le cluster...\n")
  plots$stratum <- factor(ifelse(grepl("^Verc-(02|05|06)", plots$plot_id),
                                  "cluster_A", "cluster_B"))
}

cat("Distribution des placettes par strate:\n")
print(table(plots[, strat]))

# Sélection des variables par Random Forest (sur l'ensemble)
set.seed(42)
rf_model <- randomForest(x = metrics, y = plots[[variable]], ntree = 500, importance = TRUE)
importance_df <- data.frame(
  variable = rownames(rf_model$importance),
  importance = rf_model$importance[, "%IncMSE"]
)
importance_df <- importance_df[order(-importance_df$importance), ]

# Sélectionner et filtrer les corrélations
top_vars <- head(importance_df$variable, 15)
metrics_rf <- metrics[, top_vars, drop = FALSE]
cor_mat <- cor(metrics_rf)
to_remove <- c()
for (i in 1:(ncol(cor_mat) - 1)) {
  for (j in (i + 1):ncol(cor_mat)) {
    if (abs(cor_mat[i, j]) > 0.9 && !(colnames(cor_mat)[j] %in% to_remove)) {
      to_remove <- c(to_remove, colnames(cor_mat)[j])
    }
  }
}
if (length(to_remove) > 0) {
  metrics_rf <- metrics_rf[, !(colnames(metrics_rf) %in% to_remove), drop = FALSE]
}
cat("\nVariables sélectionnées:", ncol(metrics_rf), "\n")

# Calibration par strate
model_aba_stratified <- list()

for (i in levels(plots[, strat])) {
  subsample <- which(plots[, strat] == i)
  cat("\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n")
  cat("Strate", i, ":", length(subsample), "placettes\n")

  if (length(subsample) >= 10) {
    suppressWarnings({
      model_aba_stratified[[i]] <- tryCatch({
        lidaRtRee::aba_build_model(
          plots[subsample, variable],
          metrics_rf[subsample, , drop = FALSE],
          transform = "boxcox",
          nmax = 3,
          xy = plots[subsample, c("X", "Y")]
        )
      }, error = function(e) {
        cat("  Erreur boxcox, tentative avec log...\n")
        lidaRtRee::aba_build_model(
          plots[subsample, variable],
          metrics_rf[subsample, , drop = FALSE],
          transform = "log",
          nmax = 2,
          xy = plots[subsample, c("X", "Y")]
        )
      })
    })
    cat("  adjR2:", round(model_aba_stratified[[i]]$stats$adjR2, 3),
        "| looR2:", round(model_aba_stratified[[i]]$stats$looR2, 3), "\n")
  } else {
    cat("  Trop peu de placettes pour la calibration\n")
  }
}

# Comparaison avec le modèle global
cat("\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n")
cat("           COMPARAISON\n")
cat("━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\n")
cat("Modèle global (7.6):\n")
cat("  adjR2:", round(model_aba$stats$adjR2, 3),
    "| looR2:", round(model_aba$stats$looR2, 3), "\n")

for (i in names(model_aba_stratified)) {
  cat("\nModèle strate", i, ":\n")
  cat("  adjR2:", round(model_aba_stratified[[i]]$stats$adjR2, 3),
      "| looR2:", round(model_aba_stratified[[i]]$stats$looR2, 3), "\n")
}

cat("\n")
cat("NOTE: Avec 28 placettes, la stratification n'est pas statistiquement robuste.\n")
cat("En pratique, utilisez au moins 50 placettes par strate.\n")
```

### 7.10 Sauvegarde des modèles

Les modèles calibrés et les paramètres de configuration sont sauvegardés pour la cartographie.

```{r ex-7-10-setup, message=FALSE, warning=FALSE}
# Répertoire des données et cache
data_dir <- normalizePath(file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data"), mustWork = FALSE)
cache_dir <- file.path(data_dir, "metrics_cache")

# Charger les modèles pré-calculés (exercices 7.6 et 7.8)
model_aba <- readRDS(file.path(cache_dir, "model_aba_G.rds"))
models_aba_all <- readRDS(file.path(cache_dir, "models_aba_all.rds"))

# Paramètres de configuration
class_points <- c(0, 1, 2, 3, 4, 5, 12)
h_points <- 60
aba_res_chm <- 0.5
plot_radius <- 15

# Fonction de calcul des métriques
aba_point_metrics_fun <- ~ lidaRtRee::aba_metrics(Z, Intensity, ReturnNumber,
                                                  Classification, 2)

output_dir <- data_dir
```

```{r ex-7-10, exercise=TRUE, exercise.timelimit=60, exercise.setup="ex-7-10-setup"}
# === 7.10 : Sauvegarde des modèles ===

cat("=== Sauvegarde pour la cartographie (Section 8) ===\n\n")

# Résumé des modèles disponibles
cat("MODÈLES CALIBRÉS:\n")
cat("━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n")
cat("\n1. Modèle G_m2_ha (exercice 7.6):\n")
cat("   adjR2:", round(model_aba$stats$adjR2, 3),
    "| looR2:", round(model_aba$stats$looR2, 3),
    "| RMSE:", round(model_aba$stats$rmse, 2), "\n")

cat("\n2. Modèles multiples (exercice 7.8):\n")
for (var in names(models_aba_all)) {
  cat("   ", var, "- adjR2:", round(models_aba_all[[var]]$stats$adjR2, 3),
      "| looR2:", round(models_aba_all[[var]]$stats$looR2, 3), "\n")
}

# Paramètres de configuration
cat("\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n")
cat("PARAMÈTRES DE CONFIGURATION:\n")
cat("  - class_points:", paste(class_points, collapse = ", "), "\n")
cat("  - h_points:", h_points, "m\n")
cat("  - aba_res_chm:", aba_res_chm, "m\n")
cat("  - plot_radius:", plot_radius, "m\n")

# Sauvegarde
output_file <- file.path(output_dir, "models_aba.rda")

save(model_aba,
     models_aba_all,
     aba_point_metrics_fun,
     aba_res_chm,
     class_points,
     h_points,
     plot_radius,
     file = output_file)

cat("\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n")
cat("FICHIER SAUVEGARDÉ:\n")
cat(output_file, "\n\n")

cat("CONTENU:\n")
cat("  - model_aba: modèle G_m2_ha (mono-variable)\n")
cat("  - models_aba_all: modèles G, D, N (multi-variables)\n")
cat("  - aba_point_metrics_fun: fonction de calcul des métriques\n")
cat("  - Paramètres: aba_res_chm, class_points, h_points, plot_radius\n\n")

cat(">>> Ces données seront utilisées dans la Section 8\n")
cat("    pour la cartographie wall-to-wall avec aba_predict()\n")
```

### Quiz Section 7

```{r quiz-section7, echo=FALSE}
quiz(
  question("Quelle fonction calcule les métriques standard du nuage de points ?",
    answer("stdmetrics()"),
    answer("aba_metrics()", correct = TRUE),
    answer("point_metrics()"),
    answer("cloud_stats()"),
    allow_retry = TRUE
  ),
  question("Que fait la transformation Box-Cox dans aba_build_model() ?",
    answer("Compresse les données"),
    answer("Normalise la variable cible pour la régression", correct = TRUE),
    answer("Filtre les outliers"),
    answer("Réduit le nombre de prédicteurs"),
    allow_retry = TRUE
  ),
  question("Que signifie CV-R² dans les statistiques du modèle ?",
    answer("Coefficient de variation du R²"),
    answer("R² calculé en validation croisée leave-one-out", correct = TRUE),
    answer("R² corrigé pour le nombre de variables"),
    answer("R² calculé sur les données d'entraînement"),
    allow_retry = TRUE
  ),
  question("Combien de placettes minimum sont recommandées par strate ?",
    answer("10"),
    answer("25"),
    answer("50 minimum, 100 préférable", correct = TRUE),
    answer("200"),
    allow_retry = TRUE
  ),
  question("Quelle fonction combine les modèles calibrés par strate ?",
    answer("merge_models()"),
    answer("aba_combine_strata()", correct = TRUE),
    answer("stratify_models()"),
    answer("bind_aba()"),
    allow_retry = TRUE
  )
)
```


## Section 8 : Approche ABA - Cartographie Wall-to-Wall

*Approche surfacique (ABA) - Application des modèles pour la cartographie wall-to-wall sur l'ensemble de la zone d'étude*

Cette section utilise l'approche **LAScatalog** pour traiter l'ensemble des 18 tuiles LAZ normalisées (~3.8 GB) de façon efficace, tuile par tuile, avec gestion automatique des buffers pour éviter les effets de bord.

### 8.1 Configuration du LAScatalog

Les modèles calibrés sont chargés et le LAScatalog est configuré pour le traitement par tuiles avec les filtres appropriés.

```{r ex-8-1-setup, message=FALSE, warning=FALSE}
# Répertoire des données
data_dir <- normalizePath(file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data"), mustWork = FALSE)
cache_dir <- file.path(data_dir, "metrics_cache")
output_dir_rasters <- file.path(data_dir, "rasters_aba")

# Créer le répertoire de cache rasters si nécessaire
if (!dir.exists(output_dir_rasters)) dir.create(output_dir_rasters, recursive = TRUE)

# Charger les modèles et paramètres sauvegardés (exercice 7.10)
load(file.path(data_dir, "models_aba.rda"))

# Résolution de la carte de sortie
resolution <- 25

# Répertoire des tuiles normalisées (calculé dans les tutos précédents)
laz_dir_normalized <- file.path(data_dir, "result_laz_normalized")

# Répertoire des tuiles originales (pour métriques terrain)
laz_dir_original <- file.path(data_dir, "laz")
```

```{r ex-8-1, exercise=TRUE, exercise.timelimit=60, exercise.setup="ex-8-1-setup"}
# === 8.1 : Configuration du LAScatalog pour traitement wall-to-wall ===

cat("=== Configuration LAScatalog pour la zone d'étude complète ===\n\n")

# Afficher les modèles chargés (depuis exercice 7.10)
cat("MODÈLES CHARGÉS:\n")
cat("━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n")
cat("Modèle G_m2_ha:\n")
cat("  adjR2:", round(model_aba$stats$adjR2, 3),
    "| looR2:", round(model_aba$stats$looR2, 3), "\n")
cat("  Formule:", as.character(model_aba$stats$formula), "\n")

if (exists("models_aba_all")) {
  cat("\nModèles multiples disponibles:", paste(names(models_aba_all), collapse = ", "), "\n")
}

# Paramètres de configuration
cat("\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n")
cat("PARAMÈTRES DE CONFIGURATION:\n")
cat("  - class_points:", paste(class_points, collapse = ", "), "\n")
cat("  - h_points:", h_points, "m\n")
cat("  - aba_res_chm:", aba_res_chm, "m\n")
cat("  - plot_radius:", plot_radius, "m\n")
cat("  - Résolution sortie:", resolution, "m\n")

# Créer le LAScatalog des tuiles normalisées
cat("\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n")
cat("CRÉATION DU LAScatalog:\n")
cat("Répertoire:", laz_dir_normalized, "\n\n")

if (dir.exists(laz_dir_normalized)) {
  laz_files <- list.files(laz_dir_normalized, pattern = "\\.laz$", full.names = TRUE)
  cat("Fichiers LAZ trouvés:", length(laz_files), "\n")

  if (length(laz_files) > 0) {
    # Taille totale des données
    total_size_gb <- sum(file.size(laz_files)) / 1e9
    cat("Taille totale:", round(total_size_gb, 2), "GB\n\n")

    # Filtre pour le LAScatalog (hauteurs normalisées)
    filter_cata_height <- paste(c("-keep_class", class_points,
                                  "-drop_z_above", h_points), collapse = " ")
    cat("Filtre appliqué:", filter_cata_height, "\n\n")

    # Création du LAScatalog avec options
    cata_height <- lidR::readALSLAScatalog(laz_dir_normalized,
                                            progress = FALSE,
                                            select = "xyzirnc",
                                            filter = filter_cata_height,
                                            chunk_buffer = 30)
    sf::st_crs(cata_height) <- 2154

    # Statistiques du LAScatalog
    n_tiles <- nrow(cata_height)
    bbox <- as.numeric(sf::st_bbox(cata_height))
    names(bbox) <- c("xmin", "ymin", "xmax", "ymax")
    area_km2 <- (bbox["xmax"] - bbox["xmin"]) * (bbox["ymax"] - bbox["ymin"]) / 1e6

    cat("LAScatalog créé:\n")
    cat("  - Nombre de tuiles:", n_tiles, "\n")
    cat("  - Emprise (Lambert 93):\n")
    cat("    xmin:", round(bbox["xmin"]), "| xmax:", round(bbox["xmax"]), "\n")
    cat("    ymin:", round(bbox["ymin"]), "| ymax:", round(bbox["ymax"]), "\n")
    cat("  - Surface:", round(area_km2, 2), "km²\n")
    cat("  - Buffer: 30 m\n\n")

    # Visualisation de l'emprise
    lidR::plot(cata_height, main = "LAScatalog - tuiles normalisées")

    cat("\n>>> LAScatalog prêt pour le traitement wall-to-wall\n")
    cat("    Les exercices suivants calculeront les métriques sur\n")
    cat("    l'ensemble de la zone d'étude.\n")
  }
} else {
  cat("Répertoire non trouvé.\n")
  cat("NOTE: Exécutez d'abord les tutoriels précédents pour\n")
  cat("      télécharger et normaliser les données LiDAR.\n")
}
```

### 8.2 Calcul des métriques raster - Points

Les métriques du nuage de points sont calculées sur l'ensemble de la zone d'étude via le LAScatalog. Le traitement s'effectue **tuile par tuile** avec les options `opt_*` de lidR :

- `opt_chunk_buffer()` : buffer pour éviter les effets de bord
- `opt_output_files()` : template pour sauvegarder chaque tuile en TIF
- `opt_progress()` : afficher la progression

Les tuiles sont ensuite assemblées en **VRT** (Virtual Raster) pour une lecture paresseuse sans duplication de données.

```{r ex-8-2-setup, message=FALSE, warning=FALSE}
# Répertoire des données
data_dir <- normalizePath(file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data"), mustWork = FALSE)
output_dir_rasters <- file.path(data_dir, "rasters_aba")

# Créer les répertoires si nécessaire
if (!dir.exists(output_dir_rasters)) dir.create(output_dir_rasters, recursive = TRUE)

# Répertoire pour les tuiles de métriques points
tiles_dir_points <- file.path(output_dir_rasters, "tiles_metrics_points")
if (!dir.exists(tiles_dir_points)) dir.create(tiles_dir_points, recursive = TRUE)

# Charger les paramètres (exercice 7.10)
load(file.path(data_dir, "models_aba.rda"))

resolution <- 25
laz_dir_normalized <- file.path(data_dir, "result_laz_normalized")

# Fichier VRT pour les métriques points
vrt_points <- file.path(output_dir_rasters, "metrics_points.vrt")

# Configuration parallélisation
N_CORES <- 4L
```

```{r ex-8-2, exercise=TRUE, exercise.timelimit=2400, exercise.setup="ex-8-2-setup"}
# === 8.2 : Métriques raster du nuage de points (LAScatalog) ===

cat("=== Calcul des métriques points sur l'ensemble de la zone ===\n\n")
cat("Résolution:", resolution, "m\n")
cat("Surface pixel:", resolution^2, "m²\n\n")

# Compter les fichiers LAZ source et tuiles TIF existantes
n_laz <- length(list.files(laz_dir_normalized, pattern = "\\.laz$"))
existing_tiles <- list.files(tiles_dir_points, pattern = "\\.tif$", full.names = TRUE)
n_existing <- length(existing_tiles)

cat("Fichiers source:", n_laz, "LAZ\n")
cat("Tuiles existantes:", n_existing, "TIF\n\n")

# Vérifier si le traitement est complet
if (file.exists(vrt_points) && n_existing >= n_laz) {
  cat(">>> Traitement complet, chargement du VRT existant\n\n")
  metrics_points_raster <- terra::rast(vrt_points)
  # Restaurer les noms de couches depuis une tuile TIF
  tile_names <- names(terra::rast(existing_tiles[1]))
  names(metrics_points_raster) <- tile_names
} else {
  # Nettoyer les tuiles existantes pour éviter les conflits
  # (lidR ne supporte pas overwrite=TRUE nativement)
  if (n_existing > 0) {
    cat(">>> Nettoyage des", n_existing, "tuiles existantes (traitement incomplet)\n")
    file.remove(existing_tiles)
    if (file.exists(vrt_points)) file.remove(vrt_points)
    cat(">>> Recalcul complet de toutes les tuiles\n\n")
  } else {
    cat(">>> Nouveau calcul de toutes les tuiles\n\n")
  }

  # Configuration parallélisation
  library(future)
  plan(multisession, workers = N_CORES)
  lidR::set_lidr_threads(N_CORES)

  # Créer le LAScatalog
  filter_cata_height <- paste(c("-keep_class", class_points,
                                "-drop_z_above", h_points), collapse = " ")

  cata_height <- lidR::readALSLAScatalog(laz_dir_normalized,
                                          progress = FALSE,
                                          select = "xyzirnc",
                                          filter = filter_cata_height)
  sf::st_crs(cata_height) <- 2154

  # === OPTIONS LAScatalog ===
  lidR::opt_chunk_buffer(cata_height) <- 30
  lidR::opt_progress(cata_height) <- TRUE
  lidR::opt_output_files(cata_height) <- file.path(tiles_dir_points,
                                                    "metrics_{XLEFT}_{YBOTTOM}")

  cat("Configuration:\n")
  cat("  - future workers:", N_CORES, "\n")
  cat("  - lidR threads:", lidR::get_lidr_threads(), "\n")
  cat("  - Tuiles à traiter:", nrow(cata_height), "\n")
  cat("  - Buffer:", lidR::opt_chunk_buffer(cata_height), "m\n")
  cat("  - Sortie:", basename(tiles_dir_points), "/\n\n")

  # Calcul des métriques (lidR saute les fichiers existants)
  cat("Calcul pixel_metrics par tuile...\n")
  start_time <- Sys.time()

  lidR::pixel_metrics(cata_height, aba_point_metrics_fun, res = resolution)

  elapsed <- as.numeric(difftime(Sys.time(), start_time, units = "secs"))
  cat("\nTemps de calcul:", round(elapsed, 1), "s\n\n")

  # Réinitialiser future
  plan(sequential)

  # Lister toutes les tuiles (anciennes + nouvelles)
  metric_tiles <- list.files(tiles_dir_points, pattern = "\\.tif$", full.names = TRUE)
  cat("Tuiles totales:", length(metric_tiles), "\n")

  # Récupérer les noms de couches depuis une tuile (le VRT peut les perdre)
  tile_names <- names(terra::rast(metric_tiles[1]))

  # Créer/recréer le VRT (assemblage virtuel sans copie)
  metrics_points_raster <- terra::vrt(metric_tiles, vrt_points, overwrite = TRUE)

  # Restaurer les noms de couches
  names(metrics_points_raster) <- tile_names
  cat("VRT créé:", basename(vrt_points), "\n")
}

# Statistiques
cat("\nRésultat:\n")
cat("  - Dimensions:", terra::ncol(metrics_points_raster), "x",
    terra::nrow(metrics_points_raster), "pixels\n")
cat("  - Couches:", terra::nlyr(metrics_points_raster), "\n")

# Afficher les noms des couches disponibles
layer_names <- names(metrics_points_raster)
cat("  - Couches disponibles:", paste(layer_names, collapse = ", "), "\n")

# Surface couverte
n_valid <- sum(!is.na(terra::values(metrics_points_raster[[1]])))
surface_ha <- n_valid * (resolution^2) / 10000
cat("  - Pixels valides:", n_valid, "\n")
cat("  - Surface couverte:", round(surface_ha, 1), "ha\n")

# Visualisation (utiliser les 4 premières couches disponibles)
par(mfrow = c(2, 2), mar = c(2, 2, 3, 1))
n_layers <- min(4, terra::nlyr(metrics_points_raster))
for (i in seq_len(n_layers)) {
  terra::plot(metrics_points_raster[[i]], main = layer_names[i],
              col = grDevices::hcl.colors(50, "Greens", rev = TRUE))
}
par(mfrow = c(1, 1))

cat("\n>>> Métriques points calculées pour", round(surface_ha, 1), "ha\n")
```

### 8.3 Calcul des métriques raster - Arbres

Les métriques basées sur la détection d'arbres sont calculées sur l'ensemble de la zone via :

1. **Création du MNC** tuile par tuile avec `opt_output_files()`, puis assemblage en VRT
2. **Segmentation** sur le VRT complet avec `lidaRtRee::tree_segmentation()`
3. **Agrégation** des métriques arbres par pixel

```{r ex-8-3-setup, message=FALSE, warning=FALSE}
# Répertoire des données
data_dir <- normalizePath(file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data"), mustWork = FALSE)
output_dir_rasters <- file.path(data_dir, "rasters_aba")

# Créer les répertoires si nécessaire
if (!dir.exists(output_dir_rasters)) dir.create(output_dir_rasters, recursive = TRUE)

# Répertoire pour les tuiles CHM
tiles_dir_chm <- file.path(output_dir_rasters, "tiles_chm")
if (!dir.exists(tiles_dir_chm)) dir.create(tiles_dir_chm, recursive = TRUE)

# Charger les paramètres (exercice 7.10)
load(file.path(data_dir, "models_aba.rda"))

resolution <- 25
laz_dir_normalized <- file.path(data_dir, "result_laz_normalized")

# Fichiers cache
vrt_chm <- file.path(output_dir_rasters, "chm.vrt")
cache_trees <- file.path(output_dir_rasters, "metrics_trees_raster.tif")

# Configuration parallélisation
N_CORES <- 4L
```

```{r ex-8-3, exercise=TRUE, exercise.timelimit=900, exercise.setup="ex-8-3-setup"}
# === 8.3 : Métriques raster basées sur les arbres (LAScatalog) ===

cat("=== Segmentation et métriques arbres sur l'ensemble de la zone ===\n\n")

# Vérifier si le cache existe déjà
if (file.exists(cache_trees)) {
  cat(">>> Cache trouvé, chargement depuis:", basename(cache_trees), "\n\n")
  metrics_trees_raster <- terra::rast(cache_trees)
} else {
  cat("Calcul des métriques arbres (ceci peut prendre plusieurs minutes)...\n\n")

  # 1. Créer le MNC tuile par tuile via LAScatalog
  cat("1. Création du MNC tuile par tuile (résolution:", aba_res_chm, "m)...\n")

  # Compter les fichiers LAZ source et tuiles CHM existantes
  n_laz <- length(list.files(laz_dir_normalized, pattern = "\\.laz$"))
  existing_chm_tiles <- list.files(tiles_dir_chm, pattern = "\\.tif$", full.names = TRUE)
  n_existing_chm <- length(existing_chm_tiles)

  cat("   Fichiers source:", n_laz, "LAZ\n")
  cat("   Tuiles CHM existantes:", n_existing_chm, "TIF\n")

  if (file.exists(vrt_chm) && n_existing_chm >= n_laz) {
    cat("   >>> CHM complet, chargement du VRT existant\n")
    chm <- terra::rast(vrt_chm)
  } else {
    # Nettoyer les tuiles existantes pour éviter les conflits
    if (n_existing_chm > 0) {
      cat("   >>> Nettoyage des", n_existing_chm, "tuiles existantes\n")
      file.remove(existing_chm_tiles)
      if (file.exists(vrt_chm)) file.remove(vrt_chm)
    }
    cat("   >>> Calcul de toutes les tuiles CHM\n")

    # Configuration parallélisation
    library(future)
    plan(multisession, workers = N_CORES)
    lidR::set_lidr_threads(N_CORES)

    # Créer le LAScatalog
    filter_cata_height <- paste(c("-keep_class", class_points,
                                  "-drop_z_above", h_points), collapse = " ")

    cata_height <- lidR::readALSLAScatalog(laz_dir_normalized,
                                            progress = FALSE,
                                            select = "xyzirnc",
                                            filter = filter_cata_height)
    sf::st_crs(cata_height) <- 2154

    # === OPTIONS LAScatalog ===
    lidR::opt_chunk_buffer(cata_height) <- 30
    lidR::opt_progress(cata_height) <- TRUE
    lidR::opt_output_files(cata_height) <- file.path(tiles_dir_chm,
                                                      "chm_{XLEFT}_{YBOTTOM}")

    cat("   future workers:", N_CORES, "\n")
    cat("   lidR threads:", lidR::get_lidr_threads(), "\n")
    cat("   Tuiles à traiter:", nrow(cata_height), "\n")
    cat("   Buffer:", lidR::opt_chunk_buffer(cata_height), "m\n")

    # Créer le MNC par tuile (lidR saute les existantes)
    lidR::rasterize_canopy(cata_height, res = aba_res_chm,
                           algorithm = lidR::p2r())

    # Réinitialiser future
    plan(sequential)

    # Lister toutes les tuiles (anciennes + nouvelles)
    chm_tiles <- list.files(tiles_dir_chm, pattern = "\\.tif$", full.names = TRUE)
    cat("   Tuiles totales:", length(chm_tiles), "\n")

    # Créer/recréer le VRT
    chm <- terra::vrt(chm_tiles, vrt_chm, overwrite = TRUE)
    cat("   VRT créé:", basename(vrt_chm), "\n")
  }

  # Remplacer les valeurs négatives/NA par 0
  chm[is.na(chm) | chm < 0] <- 0

  cat("   Dimensions:", terra::ncol(chm), "x", terra::nrow(chm), "pixels\n\n")

  # 2. Segmentation des arbres
  cat("2. Segmentation des arbres (tree_segmentation)...\n")
  segms <- lidaRtRee::tree_segmentation(chm)
  trees <- lidaRtRee::tree_extraction(segms)

  cat("   Arbres détectés:", nrow(trees), "\n\n")

  # 3. Calcul des métriques arbres par pixel
  cat("3. Calcul métriques arbres par pixel (", resolution, "m)...\n")
  metrics_trees_raster <- lidaRtRee::raster_metrics(
    trees,
    res = resolution,
    fun = function(x) {
      lidaRtRee::std_tree_metrics(x, resolution^2 / 10000)
    },
    output = "raster"
  )
  metrics_trees_raster[!is.finite(metrics_trees_raster)] <- 0

  cat("   Couches:", paste(names(metrics_trees_raster), collapse = ", "), "\n\n")

  # 4. Métriques supplémentaires (couverture canopée)
  cat("4. Calcul couverture canopée...\n")
  r_treechm <- segms$filled_dem
  r_treechm[segms$segments_id == 0] <- NA

  metrics_canopy <- lidaRtRee::raster_metrics(
    r_treechm,
    res = resolution,
    fun = function(x) {
      c(
        sum(!is.na(x$filled_dem)) / (resolution / aba_res_chm)^2,
        mean(x$filled_dem, na.rm = TRUE)
      )
    },
    output = "raster"
  )
  names(metrics_canopy) <- c("TreeCanopy_cover_in_plot", "TreeCanopy_meanH_in_plot")

  # Harmoniser les emprises avant combinaison
  metrics_canopy <- terra::extend(metrics_canopy, metrics_trees_raster)
  metrics_canopy <- terra::crop(metrics_canopy, metrics_trees_raster)
  metrics_trees_raster <- c(metrics_trees_raster, metrics_canopy)

  # Sauvegarder en cache
  terra::writeRaster(metrics_trees_raster, cache_trees, overwrite = TRUE)
  cat("\n>>> Métriques arbres sauvegardées:", basename(cache_trees), "\n")
}

# Statistiques
cat("\nMétriques arbres calculées:\n")
print(names(metrics_trees_raster))

n_valid <- sum(!is.na(terra::values(metrics_trees_raster[[1]])))
surface_ha <- n_valid * (resolution^2) / 10000
cat("\n  - Pixels valides:", n_valid, "\n")
cat("  - Surface couverte:", round(surface_ha, 1), "ha\n")

# Visualisation
par(mfrow = c(1, 2), mar = c(2, 2, 3, 1))
terra::plot(metrics_trees_raster[["Tree_meanH"]], main = "Hauteur moyenne arbres",
            col = grDevices::hcl.colors(50, "Viridis"))
terra::plot(metrics_trees_raster[["Tree_density"]], main = "Densité arbres/ha",
            col = grDevices::hcl.colors(50, "Plasma"))
par(mfrow = c(1, 1))

cat("\n>>> Métriques arbres calculées pour", round(surface_ha, 1), "ha\n")
```

### 8.4 Calcul des métriques raster - Terrain

Les métriques de terrain (altitude, pente, aspect) sont calculées à partir des points classifiés sol sur l'ensemble de la zone, en utilisant les fichiers LAZ **originaux** (non normalisés). Le traitement s'effectue tuile par tuile avec les options `opt_*` de lidR.

```{r ex-8-4-setup, message=FALSE, warning=FALSE}
# Répertoire des données
data_dir <- normalizePath(file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data"), mustWork = FALSE)
output_dir_rasters <- file.path(data_dir, "rasters_aba")

# Créer les répertoires si nécessaire
if (!dir.exists(output_dir_rasters)) dir.create(output_dir_rasters, recursive = TRUE)

# Répertoire pour les tuiles de métriques terrain
tiles_dir_terrain <- file.path(output_dir_rasters, "tiles_metrics_terrain")
if (!dir.exists(tiles_dir_terrain)) dir.create(tiles_dir_terrain, recursive = TRUE)

# Charger les paramètres (exercice 7.10)
load(file.path(data_dir, "models_aba.rda"))

resolution <- 25

# Répertoire des tuiles ORIGINALES (pour métriques terrain)
laz_dir_original <- file.path(data_dir, "laz")

# Fichier VRT pour les métriques terrain
vrt_terrain <- file.path(output_dir_rasters, "metrics_terrain.vrt")

# Configuration parallélisation
N_CORES <- 4L
```

```{r ex-8-4, exercise=TRUE, exercise.timelimit=600, exercise.setup="ex-8-4-setup"}
# === 8.4 : Métriques terrain (LAScatalog) ===

cat("=== Calcul des métriques de terrain sur l'ensemble de la zone ===\n\n")

# Compter les fichiers LAZ source et tuiles TIF existantes
n_laz <- length(list.files(laz_dir_original, pattern = "\\.laz$"))
existing_tiles <- list.files(tiles_dir_terrain, pattern = "\\.tif$", full.names = TRUE)
n_existing <- length(existing_tiles)

cat("Fichiers source:", n_laz, "LAZ\n")
cat("Tuiles existantes:", n_existing, "TIF\n\n")

# Vérifier si le traitement est complet
if (file.exists(vrt_terrain) && n_existing >= n_laz) {
  cat(">>> Traitement complet, chargement du VRT existant\n\n")
  metrics_terrain_raster <- terra::rast(vrt_terrain)
  # Restaurer les noms de couches depuis une tuile TIF
  tile_names <- names(terra::rast(existing_tiles[1]))
  names(metrics_terrain_raster) <- tile_names
} else {
  # Nettoyer les tuiles existantes pour éviter les conflits
  if (n_existing > 0) {
    cat(">>> Nettoyage des", n_existing, "tuiles existantes (traitement incomplet)\n")
    file.remove(existing_tiles)
    if (file.exists(vrt_terrain)) file.remove(vrt_terrain)
    cat(">>> Recalcul complet de toutes les tuiles\n\n")
  } else {
    cat(">>> Nouveau calcul de toutes les tuiles\n\n")
  }

  # Configuration parallélisation
  library(future)
  plan(multisession, workers = N_CORES)
  lidR::set_lidr_threads(N_CORES)

  # Fonction pour terrain_points_metrics
  f_terrain <- function(x, y, z) {
    as.list(lidaRtRee::terrain_points_metrics(data.frame(x, y, z)))
  }

  # Créer le LAScatalog des tuiles ORIGINALES (non normalisées)
  # Filtrer uniquement les points sol (classes 2 et 9)
  filter_ground <- "-keep_class 2 9"

  cata_ground <- lidR::readALSLAScatalog(laz_dir_original,
                                          progress = FALSE,
                                          select = "xyzc",
                                          filter = filter_ground)
  sf::st_crs(cata_ground) <- 2154

  # === OPTIONS LAScatalog ===
  lidR::opt_chunk_buffer(cata_ground) <- 30
  lidR::opt_progress(cata_ground) <- TRUE
  lidR::opt_output_files(cata_ground) <- file.path(tiles_dir_terrain,
                                                    "terrain_{XLEFT}_{YBOTTOM}")

  cat("Configuration:\n")
  cat("  - future workers:", N_CORES, "\n")
  cat("  - lidR threads:", lidR::get_lidr_threads(), "\n")
  cat("  - Tuiles à traiter:", nrow(cata_ground), "\n")
  cat("  - Filtre:", filter_ground, "(points sol uniquement)\n")
  cat("  - Buffer:", lidR::opt_chunk_buffer(cata_ground), "m\n")
  cat("  - Sortie:", basename(tiles_dir_terrain), "/\n\n")

  # Calcul des métriques terrain (lidR saute les fichiers existants)
  cat("Calcul pixel_metrics terrain par tuile...\n")
  start_time <- Sys.time()

  lidR::pixel_metrics(cata_ground, ~ f_terrain(X, Y, Z), res = resolution)

  elapsed <- as.numeric(difftime(Sys.time(), start_time, units = "secs"))
  cat("\nTemps de calcul:", round(elapsed, 1), "s\n\n")

  # Réinitialiser future
  plan(sequential)

  # Lister toutes les tuiles (anciennes + nouvelles)
  terrain_tiles <- list.files(tiles_dir_terrain, pattern = "\\.tif$", full.names = TRUE)
  cat("Tuiles totales:", length(terrain_tiles), "\n")

  # Récupérer les noms de couches depuis une tuile (le VRT peut les perdre)
  tile_names <- names(terra::rast(terrain_tiles[1]))

  # Créer/recréer le VRT (assemblage virtuel sans copie)
  metrics_terrain_raster <- terra::vrt(terrain_tiles, vrt_terrain, overwrite = TRUE)

  # Restaurer les noms de couches
  names(metrics_terrain_raster) <- tile_names
  cat("VRT créé:", basename(vrt_terrain), "\n")

  # Retirer adjR2_plane si présent (statistique de qualité du plan ajusté)
  if ("adjR2_plane" %in% names(metrics_terrain_raster)) {
    metrics_terrain_raster <- terra::subset(
      metrics_terrain_raster,
      which(names(metrics_terrain_raster) != "adjR2_plane")
    )
  }
}

# Statistiques
cat("\nMétriques terrain calculées:\n")
print(names(metrics_terrain_raster))

n_valid <- sum(!is.na(terra::values(metrics_terrain_raster[[1]])))
surface_ha <- n_valid * (resolution^2) / 10000
cat("\n  - Pixels valides:", n_valid, "\n")
cat("  - Surface couverte:", round(surface_ha, 1), "ha\n")

# Statistiques d'altitude
alt <- terra::values(metrics_terrain_raster[["altitude_mean"]])
alt <- alt[!is.na(alt)]
cat("\nAltitude:\n")
cat("  - Min:", round(min(alt)), "m | Max:", round(max(alt)), "m\n")
cat("  - Dénivelé:", round(max(alt) - min(alt)), "m\n")

# Visualisation
par(mfrow = c(1, 3), mar = c(2, 2, 3, 1))
terra::plot(metrics_terrain_raster[["altitude_mean"]], main = "Altitude (m)",
            col = grDevices::terrain.colors(50))
terra::plot(metrics_terrain_raster[["slope_deg"]], main = "Pente (°)",
            col = grDevices::heat.colors(50, rev = TRUE))
terra::plot(metrics_terrain_raster[["aspect_deg"]], main = "Aspect (°)",
            col = grDevices::rainbow(50))
par(mfrow = c(1, 1))

cat("\n>>> Métriques terrain calculées pour", round(surface_ha, 1), "ha\n")
```

### 8.5 Prédiction avec aba_predict()

La fonction `aba_predict()` applique le modèle calibré aux métriques raster pour produire une carte de prédiction sur l'ensemble de la zone d'étude. Les métriques sont chargées depuis les fichiers cache créés dans les exercices précédents.

```{r ex-8-5-setup, message=FALSE, warning=FALSE}
# Répertoire des données
data_dir <- normalizePath(file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data"), mustWork = FALSE)
output_dir_rasters <- file.path(data_dir, "rasters_aba")

# Charger les modèles et paramètres (exercice 7.10)
load(file.path(data_dir, "models_aba.rda"))

resolution <- 25

# Fichiers cache des métriques (exercices 8.2-8.4)
vrt_points <- file.path(output_dir_rasters, "metrics_points.vrt")
cache_trees <- file.path(output_dir_rasters, "metrics_trees_raster.tif")
vrt_terrain <- file.path(output_dir_rasters, "metrics_terrain.vrt")

# Charger les métriques depuis le cache (VRT pour points et terrain)
metrics_points_raster <- terra::rast(vrt_points)
metrics_trees_raster <- terra::rast(cache_trees)
metrics_terrain_raster <- terra::rast(vrt_terrain)

# Harmoniser les emprises et combiner
metrics_terrain_raster <- terra::extend(metrics_terrain_raster, metrics_points_raster)
metrics_terrain_raster <- terra::crop(metrics_terrain_raster, metrics_points_raster)
metrics_trees_raster <- terra::extend(metrics_trees_raster, metrics_points_raster)
metrics_trees_raster <- terra::crop(metrics_trees_raster, metrics_points_raster)

metrics_map <- c(metrics_points_raster, metrics_trees_raster, metrics_terrain_raster)
```

```{r ex-8-5, exercise=TRUE, exercise.timelimit=120, exercise.setup="ex-8-5-setup"}
# === 8.5 : Prédiction wall-to-wall avec aba_predict() ===

cat("=== Application du modèle ABA sur l'ensemble de la zone ===\n\n")

cat("MÉTRIQUES CHARGÉES DEPUIS CACHE:\n")
cat("━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n")
cat("  - Points:", terra::nlyr(metrics_points_raster), "couches\n")
cat("  - Arbres:", terra::nlyr(metrics_trees_raster), "couches\n")
cat("  - Terrain:", terra::nlyr(metrics_terrain_raster), "couches\n")
cat("  - Total:", terra::nlyr(metrics_map), "couches\n\n")

cat("Dimensions:", terra::ncol(metrics_map), "x", terra::nrow(metrics_map), "pixels\n")

n_valid <- sum(!is.na(terra::values(metrics_map[[1]])))
surface_ha <- n_valid * (resolution^2) / 10000
cat("Surface:", round(surface_ha, 1), "ha\n\n")

# Modèle utilisé
cat("MODÈLE UTILISÉ:\n")
cat("━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n")
print(model_aba$model)
cat("\n")

# Vérifier que les prédicteurs du modèle sont présents
predictors <- all.vars(model_aba$model$terms)[-1]  # Exclure la variable réponse
cat("Prédicteurs requis:", paste(predictors, collapse = ", "), "\n")
cat("Présents:", sum(predictors %in% names(metrics_map)), "/", length(predictors), "\n\n")

# Prédiction
cat("Prédiction wall-to-wall en cours...\n")
prediction_map <- lidaRtRee::aba_predict(model_aba, metrics_map)

cat("\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n")
cat("RÉSULTAT:\n")
cat("  - Variable prédite: G_m2_ha (surface terrière)\n")
cat("  - Min:", round(terra::minmax(prediction_map)[1], 1), "m²/ha\n")
cat("  - Max:", round(terra::minmax(prediction_map)[2], 1), "m²/ha\n")
cat("  - Moyenne:", round(terra::global(prediction_map, "mean", na.rm = TRUE)[[1]], 1), "m²/ha\n\n")

# Visualisation
par(mfrow = c(1, 2), mar = c(2, 2, 3, 1))

# Carte de prédiction
terra::plot(prediction_map, main = "Surface terrière prédite (m²/ha)",
            col = grDevices::hcl.colors(50, "Greens", rev = TRUE))

# Histogramme
hist(terra::values(prediction_map), breaks = 30, main = "Distribution G",
     xlab = "G (m²/ha)", col = "forestgreen", border = "white")

par(mfrow = c(1, 1))

cat(">>> Prédiction réalisée sur", round(surface_ha, 1), "ha\n")
```

### 8.6 Nettoyage et masquage forêt

La fonction `clean_raster()` permet d'appliquer des seuils de validité et un masque forêt pour filtrer les valeurs aberrantes et les zones non forestières.

```{r ex-8-6-setup, message=FALSE, warning=FALSE}
# Répertoire des données
data_dir <- normalizePath(file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data"), mustWork = FALSE)
output_dir_rasters <- file.path(data_dir, "rasters_aba")

# Charger les modèles et paramètres (exercice 7.10)
load(file.path(data_dir, "models_aba.rda"))

resolution <- 25

# Fichiers cache des métriques (exercices 8.2-8.4)
vrt_points <- file.path(output_dir_rasters, "metrics_points.vrt")
cache_trees <- file.path(output_dir_rasters, "metrics_trees_raster.tif")
vrt_terrain <- file.path(output_dir_rasters, "metrics_terrain.vrt")

# Charger les métriques depuis le cache (VRT pour points et terrain)
metrics_points_raster <- terra::rast(vrt_points)
metrics_trees_raster <- terra::rast(cache_trees)
metrics_terrain_raster <- terra::rast(vrt_terrain)

# Harmoniser et combiner
metrics_terrain_raster <- terra::extend(metrics_terrain_raster, metrics_points_raster)
metrics_terrain_raster <- terra::crop(metrics_terrain_raster, metrics_points_raster)
metrics_trees_raster <- terra::extend(metrics_trees_raster, metrics_points_raster)
metrics_trees_raster <- terra::crop(metrics_trees_raster, metrics_points_raster)
metrics_map <- c(metrics_points_raster, metrics_trees_raster, metrics_terrain_raster)

# Prédiction
prediction_map <- lidaRtRee::aba_predict(model_aba, metrics_map)
```

```{r ex-8-6, exercise=TRUE, exercise.timelimit=60, exercise.setup="ex-8-6-setup"}
# === 8.6 : Nettoyage avec clean_raster() ===

cat("=== Nettoyage de la carte de prédiction ===\n\n")

# Seuils de validité basés sur les données d'entraînement
g_min <- 0
g_max <- 80  # m²/ha - valeur maximale réaliste

cat("Seuils de validité:\n")
cat("  - G minimum:", g_min, "m²/ha\n")
cat("  - G maximum:", g_max, "m²/ha\n\n")

# Créer un masque forêt simple basé sur la couverture > 2m
# (en pratique, utiliser un masque BD Forêt ou autre)
if ("pzabove2" %in% names(metrics_map)) {
  forest_mask <- metrics_map[["pzabove2"]] > 0.2  # >20% couverture
  cat("Masque forêt créé (couverture > 20%)\n")
  n_forest <- sum(terra::values(forest_mask), na.rm = TRUE)
  n_total <- terra::ncell(forest_mask)
  cat("  - Pixels forêt:", n_forest, "(", round(100 * n_forest / n_total, 1), "%)\n")
  cat("  - Pixels total:", n_total, "\n\n")
} else {
  forest_mask <- NULL
  cat("Pas de masque forêt appliqué\n\n")
}

# Appliquer clean_raster
prediction_clean <- lidaRtRee::clean_raster(prediction_map,
                                             c(g_min, g_max),
                                             forest_mask)

cat("Après nettoyage:\n")
n_valid <- sum(!is.na(terra::values(prediction_clean)))
surface_ha <- n_valid * (resolution^2) / 10000
cat("  - Pixels valides:", n_valid, "\n")
cat("  - Surface forestière:", round(surface_ha, 1), "ha\n")
cat("  - Min:", round(terra::minmax(prediction_clean)[1], 1), "m²/ha\n")
cat("  - Max:", round(terra::minmax(prediction_clean)[2], 1), "m²/ha\n\n")

# Visualisation comparaison
par(mfrow = c(1, 2), mar = c(2, 2, 3, 1))
terra::plot(prediction_map, main = "Avant nettoyage",
            col = grDevices::hcl.colors(50, "Greens", rev = TRUE))
terra::plot(prediction_clean, main = "Après nettoyage (masque forêt)",
            col = grDevices::hcl.colors(50, "Greens", rev = TRUE))
par(mfrow = c(1, 1))

cat(">>> Carte nettoyée et masquée sur", round(surface_ha, 1), "ha de forêt\n")
```

### 8.7 Export et résumé

Les cartes de prédiction sont exportées au format GeoTIFF et les statistiques de synthèse sont calculées pour l'ensemble de la zone d'étude.

```{r ex-8-7-setup, message=FALSE, warning=FALSE}
# Répertoire des données
data_dir <- normalizePath(file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data"), mustWork = FALSE)
output_dir <- data_dir
output_dir_rasters <- file.path(data_dir, "rasters_aba")

# Charger les modèles et paramètres (exercice 7.10)
load(file.path(data_dir, "models_aba.rda"))

resolution <- 25

# Fichiers cache des métriques (exercices 8.2-8.4)
vrt_points <- file.path(output_dir_rasters, "metrics_points.vrt")
cache_trees <- file.path(output_dir_rasters, "metrics_trees_raster.tif")
vrt_terrain <- file.path(output_dir_rasters, "metrics_terrain.vrt")

# Charger les métriques depuis le cache (VRT pour points et terrain)
metrics_points_raster <- terra::rast(vrt_points)
metrics_trees_raster <- terra::rast(cache_trees)
metrics_terrain_raster <- terra::rast(vrt_terrain)

# Harmoniser et combiner
metrics_terrain_raster <- terra::extend(metrics_terrain_raster, metrics_points_raster)
metrics_terrain_raster <- terra::crop(metrics_terrain_raster, metrics_points_raster)
metrics_trees_raster <- terra::extend(metrics_trees_raster, metrics_points_raster)
metrics_trees_raster <- terra::crop(metrics_trees_raster, metrics_points_raster)
metrics_map <- c(metrics_points_raster, metrics_trees_raster, metrics_terrain_raster)

# Prédiction et nettoyage
prediction_map <- lidaRtRee::aba_predict(model_aba, metrics_map)

if ("pzabove2" %in% names(metrics_map)) {
  forest_mask <- metrics_map[["pzabove2"]] > 0.2
} else {
  forest_mask <- NULL
}
prediction_clean <- lidaRtRee::clean_raster(prediction_map, c(0, 80), forest_mask)
```

```{r ex-8-7, exercise=TRUE, exercise.timelimit=60, exercise.setup="ex-8-7-setup"}
# === 8.7 : Export et synthèse ===

cat("=== Export des résultats ===\n\n")

# Export GeoTIFF
output_file <- file.path(output_dir, "prediction_G_m2_ha.tif")
terra::writeRaster(prediction_clean, filename = output_file, overwrite = TRUE)

cat("Fichier exporté:", output_file, "\n\n")

# Statistiques de synthèse
cat("=== STATISTIQUES DE SYNTHÈSE ===\n\n")

# Surface totale
n_pixels <- sum(!is.na(terra::values(prediction_clean)))
surface_ha <- n_pixels * (resolution^2) / 10000

cat("ZONE CARTOGRAPHIÉE:\n")
cat("  - Pixels valides:", n_pixels, "\n")
cat("  - Résolution:", resolution, "m\n")
cat("  - Surface totale:", round(surface_ha, 1), "ha\n\n")

# Statistiques G
g_values <- terra::values(prediction_clean)
g_values <- g_values[!is.na(g_values)]

cat("SURFACE TERRIÈRE (G):\n")
cat("  - Moyenne:", round(mean(g_values), 1), "m²/ha\n")
cat("  - Médiane:", round(median(g_values), 1), "m²/ha\n")
cat("  - Écart-type:", round(sd(g_values), 1), "m²/ha\n")
cat("  - Min:", round(min(g_values), 1), "m²/ha\n")
cat("  - Max:", round(max(g_values), 1), "m²/ha\n\n")

# Estimation du stock total
g_total <- sum(g_values) * (resolution^2) / 10000  # Somme pondérée par surface pixel

cat("STOCK ESTIMÉ:\n")
cat("  - Surface terrière totale:", round(g_total, 0), "m²\n")
cat("  - G moyenne pondérée:", round(g_total / surface_ha, 1), "m²/ha\n\n")

# Qualité du modèle
cat("QUALITÉ DU MODÈLE:\n")
cat("  - adjR²:", round(model_aba$stats$adjR2, 3), "\n")
cat("  - looR²:", round(model_aba$stats$looR2, 3), "\n")
cat("  - RMSE:", round(model_aba$stats$rmse, 2), "m²/ha\n")
cat("  - RMSE%:", round(model_aba$stats$cvrmse * 100, 1), "%\n\n")

cat(">>> Workflow ABA terminé !\n")
cat("    Les prédictions peuvent maintenant alimenter les indicateurs nemeton.\n")
```

### Quiz Section 8

```{r quiz-section8, echo=FALSE}
quiz(
  question("Quelle fonction applique le modèle calibré aux métriques raster ?",
    answer("predict()"),
    answer("aba_predict()", correct = TRUE),
    answer("model_predict()"),
    answer("apply_model()"),
    allow_retry = TRUE
  ),
  question("Que fait la fonction clean_raster() ?",
    answer("Compresse le fichier raster"),
    answer("Applique des seuils de validité et un masque", correct = TRUE),
    answer("Convertit le format du raster"),
    answer("Lisse les valeurs du raster"),
    allow_retry = TRUE
  ),
  question("Quelle résolution est utilisée pour la cartographie wall-to-wall ?",
    answer("0.5 m"),
    answer("5 m"),
    answer("25 m", correct = TRUE),
    answer("100 m"),
    allow_retry = TRUE
  ),
  question("Pourquoi combiner métriques points, arbres et terrain ?",
    answer("Pour réduire la taille des fichiers"),
    answer("Pour améliorer la prédiction en capturant différents aspects de la structure", correct = TRUE),
    answer("Pour accélérer le calcul"),
    answer("Ce n'est pas nécessaire"),
    allow_retry = TRUE
  ),
  question("Quel format d'export est recommandé pour les cartes de prédiction ?",
    answer("PNG"),
    answer("CSV"),
    answer("GeoTIFF", correct = TRUE),
    answer("PDF"),
    allow_retry = TRUE
  )
)
```


## Section 9 : Approche BABA - Alternative sans Placettes

*Approche alternative quand les données terrain sont limitées ou inexistantes*

### Principe du BABA (Buffered Area-Based Approach)

Le **BABA** est une approche complémentaire à l'ABA classique, particulièrement utile quand :

- Les placettes terrain sont **insuffisantes** pour calibrer des modèles robustes
- On souhaite une **cartographie exploratoire** rapide des métriques LiDAR
- On veut produire des cartes à **haute résolution** avec des fenêtres de calcul plus grandes

**Différences clés avec l'ABA classique :**

| Aspect | ABA classique (sections 6-8) | BABA |
|--------|------------------------------|------|
| Calibration | Modèles statistiques sur placettes | Pas de calibration |
| Sortie | Variables forestières (G, V, N) | Métriques LiDAR brutes |
| Résolution | Dépend de la densité de placettes | Libre (pixels fins possibles) |
| Fenêtre | Surface de la placette | Paramétrable indépendamment |

### Exercice 9.1 : Métriques BABA avec lasR

Le paramètre `res = c(pixel, fenêtre)` de lasR permet de **décorréler** la résolution de sortie et la fenêtre de calcul :

- `res = c(10, 30)` : pixels de 10m, métriques calculées sur fenêtres de 30×30m (900 m²)
- Fenêtre 900 m² ≈ placette de rayon 17m (comparable aux ~707 m² des placettes de 15m)

```{r ex-9-1-setup}
# Répertoire des données
data_dir <- normalizePath(file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data"), mustWork = FALSE)

# LAZ normalisés (données utilisateur)
laz_dir <- file.path(data_dir, "result_laz_normalized")

# Répertoire de sortie
if (requireNamespace("rappdirs", quietly = TRUE)) {
  output_dir <- normalizePath(file.path(rappdirs::user_data_dir("nemeton"), "tutorial_data"), mustWork = FALSE)
} else {
  output_dir <- normalizePath(file.path(path.expand("~"), "nemeton_tutorial_data"), mustWork = FALSE)
}
dir.create(output_dir, recursive = TRUE, showWarnings = FALSE)
```

```{r ex-9-1, exercise=TRUE, exercise.timelimit=300, exercise.setup="ex-9-1-setup"}
cat("=== BABA (Buffered Area-Based Approach) avec lasR ===\n\n")

cat("AVANTAGES DU BABA:\n")
cat("─────────────────────────────────────────────────────\n")
cat("1. Résolution ≠ fenêtre : pixels 10m, calcul sur 30m\n")
cat("2. Compatible placettes : fenêtre ~900m² ≈ placettes ~707m²\n")
cat("3. Lissage + précision : métriques stables, cartes fines\n")
cat("4. Pas d'effets de bord : fenêtres chevauchantes\n")
cat("5. Ultra-rapide : lasR en C++ avec parallélisation\n")
cat("6. Pas besoin de placettes terrain pour l'exploration\n\n")

if (!requireNamespace("lasR", quietly = TRUE)) {
  cat("lasR n'est pas installé. Installez-le avec:\n")
  cat("install.packages('lasR', repos = 'https://r-lidar.r-universe.dev')\n")
} else {
  library(lasR)

  # Lister tous les fichiers LAZ normalisés
  laz_files <- dir(laz_dir,
                   pattern = "\\.laz$",
                   full.names = TRUE)
  cat("Fichiers LAZ:", length(laz_files), "\n")
  if (length(laz_files) == 0) {
    cat("ERREUR: Aucun fichier LAZ trouvé dans:", laz_dir, "\n")
    stop("Fichiers LAZ manquants")
  }
  cat("Premier fichier:", basename(laz_files[1]), "\n\n")

  # ==========================================================================
  # COMPARAISON ABA vs BABA
  # ==========================================================================
  cat("--- Comparaison ABA classique vs BABA ---\n\n")

  cat("ABA classique (sections 6-8):\n")
  cat("  - Métriques extraites aux placettes → modèles → prédiction\n")
  cat("  - Sortie: variables forestières (G, V, N en m²/ha, m³/ha, N/ha)\n\n")

  cat("BABA (cet exercice):\n")
  cat("  - Métriques rasterisées directement avec fenêtre glissante\n")
  cat("  - Sortie: métriques LiDAR brutes (zmax, zmean, p95, etc.)\n")
  cat("  - res = c(10, 30) : pixel 10m, fenêtre 30m\n\n")

  # Pipeline BABA
  dir.create(output_dir, recursive = TRUE, showWarnings = FALSE)
  output_file <- file.path(output_dir, "metriques_baba.tif")

  pipeline_baba <- reader_las() +
    rasterize(
      res = c(10, 30),  # 10m sortie, 30m fenêtre (~900 m²)
      operators = c("max", "mean", "sd", "p95", "above2"),
      ofile = output_file
    )

  cat("Pipeline lasR:\n")
  print(pipeline_baba)

  # Exécution
  cat("\n--- Exécution BABA ---\n")
  N_CORES <- min(4L, parallel::detectCores() - 1L)
  cat("Cores:", N_CORES, "\n")

  t0 <- Sys.time()
  ans <- exec(pipeline_baba, on = laz_files, ncores = N_CORES, progress = TRUE)
  t1 <- Sys.time()

  cat("\nTemps d'exécution:", round(difftime(t1, t0, units = "secs"), 1), "secondes\n")
  cat("Fichier créé:", output_file, "\n")

  # Charger et afficher le résultat
  if (file.exists(output_file)) {
    baba <- terra::rast(output_file)
    cat("\nRésultat BABA:\n")
    cat("  Dimensions:", terra::ncol(baba), "×", terra::nrow(baba), "pixels\n")
    cat("  Résolution:", terra::res(baba)[1], "m\n")
    cat("  Nombre de couches:", terra::nlyr(baba), "\n")
    cat("  Couches:", paste(names(baba), collapse = ", "), "\n")

    # Visualisation (si couches valides)
    if (terra::nlyr(baba) >= 5) {
      par(mfrow = c(2, 2), mar = c(2, 2, 3, 1))
      terra::plot(baba[[1]], main = "Zmax (m)", col = grDevices::hcl.colors(50, "Greens", rev = TRUE))
      terra::plot(baba[[2]], main = "Zmean (m)", col = grDevices::hcl.colors(50, "Greens", rev = TRUE))
      terra::plot(baba[[4]], main = "Zp95 (m)", col = grDevices::hcl.colors(50, "Greens", rev = TRUE))
      terra::plot(baba[[5]], main = "Couverture > 2m", col = grDevices::hcl.colors(50, "YlGn", rev = TRUE))
    } else {
      cat("Attention: moins de 5 couches produites\n")
    }

    cat("\nConclusion:\n")
    cat("- BABA produit directement des cartes raster de métriques LiDAR\n")
    cat("- Utile pour l'exploration ou quand les placettes sont limitées\n")
    cat("- Pour des variables forestières (G, V), préférez l'ABA avec calibration\n")
  } else {
    cat("\nERREUR: fichier non créé:", output_file, "\n")
  }
}
```

### Quiz BABA

```{r quiz-baba, echo=FALSE}
quiz(
  question("Quand utiliser BABA plutôt qu'ABA classique ?",
    answer("Toujours, c'est plus précis"),
    answer("Quand on a peu de placettes terrain ou pour l'exploration", correct = TRUE),
    answer("Uniquement pour les forêts tropicales"),
    answer("Jamais, l'ABA est toujours meilleur"),
    allow_retry = TRUE
  ),
  question("Que signifie res = c(10, 30) dans lasR ?",
    answer("10 fichiers, 30 tuiles"),
    answer("Résolution 10m en sortie, fenêtre 30m pour le calcul", correct = TRUE),
    answer("10% de décimation, 30m de buffer"),
    answer("10 bandes, 30 bits"),
    allow_retry = TRUE
  ),
  question("Quelle est la principale limite du BABA ?",
    answer("Il est trop lent"),
    answer("Il produit des métriques LiDAR brutes, pas des variables forestières calibrées", correct = TRUE),
    answer("Il ne fonctionne qu'avec lidR"),
    answer("Il nécessite plus de placettes terrain"),
    allow_retry = TRUE
  )
)
```

## Section 10 : Quiz Final

### Quiz de validation

```{r quiz-final, echo=FALSE}
quiz(
  caption = "Quiz Final - LiDAR Avancé",

  question("Quelle est la fonction principale d'un LAScatalog ?",
    answer("Compresser les fichiers LiDAR"),
    answer("Référencer plusieurs fichiers sans les charger en mémoire", correct = TRUE),
    answer("Convertir les fichiers en format .las"),
    answer("Visualiser les nuages de points en 3D"),
    allow_retry = TRUE
  ),

  question("Dans BABA, que signifie res = c(10, 20) ?",
    answer("10 bandes, 20 bits"),
    answer("Résolution 10m en sortie, fenêtre 20m pour le calcul", correct = TRUE),
    answer("10% de décimation, 20m de buffer"),
    answer("10 fichiers, 20 tuiles"),
    allow_retry = TRUE
  ),

  question("Quel algorithme est utilisé pour détecter les cimes d'arbres ?",
    answer("Random Forest"),
    answer("K-means"),
    answer("Local Maximum Filter (lmf)", correct = TRUE),
    answer("Principal Component Analysis"),
    allow_retry = TRUE
  ),

  question("Pourquoi la coregistration est-elle importante ?",
    answer("Pour compresser les données"),
    answer("Pour aligner les placettes terrain avec les données LiDAR", correct = TRUE),
    answer("Pour accélérer le traitement"),
    answer("Pour convertir les coordonnées"),
    allow_retry = TRUE
  ),

  question("Quelle métrique LiDAR est la plus utile pour estimer le volume de bois ?",
    answer("zentropy"),
    answer("pzabove2"),
    answer("zq95 (percentile 95 des hauteurs)", correct = TRUE),
    answer("strata_0_2"),
    allow_retry = TRUE
  ),

  question("Quel indicateur nemeton utilise les trouées forestières ?",
    answer("C1 - Carbone"),
    answer("B2 - Structure biodiversité", correct = TRUE),
    answer("P1 - Volume"),
    answer("W1 - TWI"),
    allow_retry = TRUE
  ),

  question("Quel est l'avantage principal de lasR par rapport à lidR ?",
    answer("Plus de fonctionnalités"),
    answer("Interface graphique"),
    answer("Traitement plus rapide et moins de mémoire", correct = TRUE),
    answer("Support de plus de formats"),
    allow_retry = TRUE
  ),

  question("Quelle résolution BABA est recommandée pour nemeton ?",
    answer("1m sortie, 5m fenêtre"),
    answer("10m sortie, 20m fenêtre", correct = TRUE),
    answer("50m sortie, 100m fenêtre"),
    answer("100m sortie, 200m fenêtre"),
    allow_retry = TRUE
  )
)
```

## Synthèse

### Récapitulatif des méthodes lidaRtRee

Ce tutorial a couvert les principales méthodes d'analyse LiDAR forestière de lidaRtRee :

```
            Workflow LiDAR Avancé - lidaRtRee

  ┌─────────────────────────────────────────────────────────┐
  │ Section 3 : Segmentation d'Arbres Individuels           │
  │   - tree_segmentation() : détection + segmentation      │
  │   - tree_extraction() : extraction des attributs        │
  │   → Produits : arbres.gpkg (P1, P3, E1)                 │
  └─────────────────────────────────────────────────────────┘
                          │
  ┌─────────────────────────────────────────────────────────┐
  │ Section 4 : Trouées et Lisières                         │
  │   - gap_detection() : identification des trouées        │
  │   - edge_detection() : lisières par morphologie         │
  │   → Produits : gaps.gpkg, edges.gpkg (B2, L1)           │
  └─────────────────────────────────────────────────────────┘
                          │
  ┌─────────────────────────────────────────────────────────┐
  │ Section 5 : Métriques de Structure                      │
  │   - aba_metrics() : métriques du nuage de points        │
  │   - std_tree_metrics() : métriques d'arbres             │
  │   → Produits : métriques par placette/pixel             │
  └─────────────────────────────────────────────────────────┘
                          │
  ┌─────────────────────────────────────────────────────────┐
  │ Section 6 : Préparation des Données ABA                 │
  │   - terrain_points_metrics() : métriques terrain        │
  │   - polar2Projected() : coordonnées arbres              │
  │   → Produits : plots, llas_height, metrics_terrain      │
  └─────────────────────────────────────────────────────────┘
                          │
  ┌─────────────────────────────────────────────────────────┐
  │ Section 7 : Calibration des Modèles ABA                 │
  │   - clouds_metrics() : extraction sur placettes         │
  │   - aba_build_model() : calibration Box-Cox + stepwise  │
  │   - aba_combine_strata() : modèles stratifiés           │
  │   → Produits : modèles calibrés (G, N, D)               │
  └─────────────────────────────────────────────────────────┘
                          │
  ┌─────────────────────────────────────────────────────────┐
  │ Section 8 : Cartographie et Inférence                   │
  │   - pixel_metrics() : métriques raster                  │
  │   - aba_predict() : prédiction wall-to-wall             │
  │   - clean_raster() : seuils + masquage forêt            │
  │   → Produits : predictions_aba.tif (C1, P1, P3)         │
  └─────────────────────────────────────────────────────────┘
                          │
  ┌─────────────────────────────────────────────────────────┐
  │ Section 9 : Approche BABA (Alternative)                 │
  │   - lasR : rasterize avec res = c(pixel, fenêtre)       │
  │   → Produits : métriques LiDAR brutes sans calibration  │
  └─────────────────────────────────────────────────────────┘
```

### Produits pour indicateurs nemeton

| Produit               | Fonction lidaRtRee     | Indicateurs       |
|-----------------------|------------------------|-------------------|
| arbres.gpkg           | tree_extraction()      | P1, P3, E1        |
| gaps.gpkg             | gap_detection()        | B2, L1            |
| edges.gpkg            | edge_detection()       | L1                |
| metriques_baba.tif    | lasR BABA              | C1, P1, A1, B2    |
| predictions_G.tif     | aba_predict()          | P1                |
| predictions_V.tif     | aba_predict()          | P1, C1            |
| predictions_N.tif     | aba_predict()          | E1                |

### Optimisation avec lasR

Pour les gros volumes de données, lasR offre des alternatives performantes :

- **Normalisation** : `transform_with(triangulate())`
- **BABA** : `rasterize(res = c(10, 30), ...)`
- **Segmentation** : `local_maximum_raster()` + `region_growing()`

### Ressources

**Documentation lidaRtRee :**

- [Segmentation d'arbres](https://lidar.pages-forge.inrae.fr/lidaRtRee/articles/tree.segmentation.html)
- [Trouées et lisières](https://lidar.pages-forge.inrae.fr/lidaRtRee/articles/gaps.and.edges.detection.html)
- [Métriques de structure](https://lidar.pages-forge.inrae.fr/lidaRtRee/articles/forest.structure.metrics.html)
- [ABA 1: Préparation](https://lidar.pages-forge.inrae.fr/lidaRtRee/articles/area-based.1.data.preparation.html)
- [ABA 2: Calibration](https://lidar.pages-forge.inrae.fr/lidaRtRee/articles/area-based.2.model.calibration.html)
- [ABA 3: Cartographie](https://lidar.pages-forge.inrae.fr/lidaRtRee/articles/area-based.3.mapping.and.inference.html)

**Autres ressources :**

- [lasR documentation](https://r-lidar.github.io/lasR/)
- [lidR book](https://r-lidar.github.io/lidRbook/)
- [BABA article](https://r-lidar.github.io/lasR/articles/baba.html)

### Prochaines étapes

1. **Tutorial 05** : Assembler tous les indicateurs et normaliser
2. **Tutorial 06** : Analyse multi-critères, radar, Pareto, export

**Félicitations !** Vous avez terminé le Tutorial 07 sur le traitement LiDAR avancé avec lidaRtRee.
